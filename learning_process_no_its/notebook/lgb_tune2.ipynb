{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "project = 'openstack'\n",
    "with open('../resource/'+project+'_train.pkl', 'rb') as f_train, open('../resource/'+project+'_test.pkl', 'rb') as f_test:\n",
    "        tr_data = pickle.load(f_train)\n",
    "        te_data = pickle.load(f_test)\n",
    "pred_list = []\n",
    "kinds = ['train', 'test']\n",
    "models = ['lgb', 'code_cnn', 'msg_tf']\n",
    "for kind in kinds:\n",
    "    for model in models:\n",
    "        with open('../pred/'+project+'-'+model+'-'+'random'+'-'+kind+'.pkl', 'rb') as f:\n",
    "            pred_list.append(pickle.load(f))\n",
    "tr_pred = [[pred_list[0][j], pred_list[1][j], pred_list[2][j]] for j in range(len(pred_list[0]))]\n",
    "te_pred = [[pred_list[3][j], pred_list[4][j], pred_list[5][j]] for j in range(len(pred_list[3]))]                \n",
    "tr_data = [tr_pred, tr_data[5]]\n",
    "te_data = [te_pred, te_data[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.16092745326840102, 0.021402199, 0.509486],\n",
       " [0.3193696255443434, 0.07866127, 0.12485164],\n",
       " [0.8729744960587329, 0.91129243, 0.28266403],\n",
       " [0.3231291645480817, 0.24457371, 0.5229826],\n",
       " [0.281422419653164, 0.8578265, 0.043312617],\n",
       " [0.8073646044152452, 0.8830279, 0.37239048],\n",
       " [0.5349141448498056, 0.7582897, 0.10247494],\n",
       " [0.674647812381105, 0.84463984, 0.030646747],\n",
       " [0.2248353561809572, 0.33007056, 0.015908524],\n",
       " [0.5057495434834242, 0.5791738, 0.056447506],\n",
       " [0.7086046771656842, 0.5558742, 0.80761737],\n",
       " [0.8597510138769027, 0.8156691, 0.807817],\n",
       " [0.5618877600072832, 0.889421, 0.70573884],\n",
       " [0.39595586424323964, 0.54397607, 0.64133734],\n",
       " [0.5027521829807249, 0.79465795, 0.11872009],\n",
       " [0.4199598667761703, 0.71378154, 0.096476026],\n",
       " [0.27730186310120186, 0.25220284, 0.6098979],\n",
       " [0.16946049755327852, 0.41079703, 0.015940268],\n",
       " [0.790287072381172, 0.89598703, 0.68607515],\n",
       " [0.10430006261034865, 0.09597076, 0.03436511],\n",
       " [0.39989704769619694, 0.27365875, 0.5214928],\n",
       " [0.5435283679784377, 0.27815065, 0.3538111],\n",
       " [0.09157316292837542, 0.10502892, 0.025663557],\n",
       " [0.2706849508900603, 0.11200283, 0.015608693],\n",
       " [0.49908564359465785, 0.11445505, 0.05313304],\n",
       " [0.5291963071657828, 0.49372137, 0.7341847],\n",
       " [0.5860257970074979, 0.91667104, 0.79438627],\n",
       " [0.7194640505431461, 0.55121434, 0.058214307],\n",
       " [0.5607817406744482, 0.7050526, 0.5273521],\n",
       " [0.6104137333733324, 0.5460492, 0.087511465],\n",
       " [0.1951422266339679, 0.15344748, 0.070733145],\n",
       " [0.11892291531063501, 0.032305907, 0.10447496],\n",
       " [0.2601776046434149, 0.18670921, 0.44868106],\n",
       " [0.8439475730254746, 0.91665083, 0.8531795],\n",
       " [0.2563604298469104, 0.4259288, 0.8093705],\n",
       " [0.3913762691851009, 0.7956339, 0.054158363],\n",
       " [0.5957911779774645, 0.85520357, 0.14425981],\n",
       " [0.6821261891352783, 0.8717545, 0.052697547],\n",
       " [0.16624018753265135, 0.043061584, 0.19181263],\n",
       " [0.1618422791183395, 0.8202378, 0.11478049],\n",
       " [0.13779326873270387, 0.21685162, 0.39954737],\n",
       " [0.2565342665234143, 0.031084483, 0.31962693],\n",
       " [0.13198580068987892, 0.048393063, 0.078229606],\n",
       " [0.8412117318960936, 0.92700356, 0.81977546],\n",
       " [0.7440664878699496, 0.7614355, 0.043936815],\n",
       " [0.8403743976526045, 0.76054394, 0.6719924],\n",
       " [0.650350403900111, 0.8260216, 0.63440657],\n",
       " [0.7276424798688699, 0.90506387, 0.9078992],\n",
       " [0.17183100802887205, 0.071271025, 0.8835323],\n",
       " [0.08501778117716374, 0.060272004, 0.45215523],\n",
       " [0.23565794481728009, 0.1145786, 0.13177653],\n",
       " [0.21735253677544908, 0.6732514, 0.3489044],\n",
       " [0.7640793140767359, 0.8714912, 0.4665083],\n",
       " [0.12755538056258905, 0.098401465, 0.30651292],\n",
       " [0.5059408186998411, 0.5478065, 0.24625182],\n",
       " [0.7946852380089685, 0.8594135, 0.035026245],\n",
       " [0.5857171320906484, 0.21246791, 0.30765828],\n",
       " [0.2639406417934708, 0.69906545, 0.07599155],\n",
       " [0.5705158697038004, 0.9282808, 0.97334385],\n",
       " [0.38035200189319734, 0.6913336, 0.69910103],\n",
       " [0.2522050124881985, 0.073158324, 0.09677004],\n",
       " [0.38992695534510646, 0.24319038, 0.05196108],\n",
       " [0.5478083368420941, 0.7597661, 0.9181804],\n",
       " [0.18292942706423018, 0.049436178, 0.3610608],\n",
       " [0.8099037773380703, 0.8447259, 0.68460876],\n",
       " [0.607222451055866, 0.8824026, 0.4915923],\n",
       " [0.7600339353137544, 0.86658585, 0.637614],\n",
       " [0.7724220722310132, 0.77552915, 0.18161976],\n",
       " [0.31202514126547737, 0.8602728, 0.7956447],\n",
       " [0.10090725426744325, 0.04546962, 0.312335],\n",
       " [0.08243904058959423, 0.021069193, 0.09352896],\n",
       " [0.6246756341106405, 0.05145646, 0.3504925],\n",
       " [0.2228193048316693, 0.15768604, 0.43317804],\n",
       " [0.3265014506727357, 0.1695144, 0.18127955],\n",
       " [0.820489627319248, 0.98252696, 0.8863767],\n",
       " [0.2801554610038276, 0.0060827667, 0.012415762],\n",
       " [0.2671020607214145, 0.05809396, 0.08538388],\n",
       " [0.7993183001068837, 0.7162654, 0.6769768],\n",
       " [0.019591962419515725, 0.088518165, 0.705175],\n",
       " [0.6395223832867867, 0.66483456, 0.015912917],\n",
       " [0.1588202205365299, 0.04411728, 0.74263066],\n",
       " [0.07699004575166007, 0.14842235, 0.004215622],\n",
       " [0.8519897424198298, 0.7345354, 0.4517833],\n",
       " [0.47106236029770965, 0.93958414, 0.6284785],\n",
       " [0.38405938458569133, 0.85341835, 0.020168506],\n",
       " [0.17991880192916218, 0.4462273, 0.2219752],\n",
       " [0.49755436912456635, 0.22297621, 0.8497871],\n",
       " [0.32751275188139684, 0.5726104, 0.015885513],\n",
       " [0.31262703775325784, 0.47044462, 0.20533627],\n",
       " [0.2692054984508294, 0.18633415, 0.029429948],\n",
       " [0.767097955377289, 0.8944359, 0.26385206],\n",
       " [0.3220326099944724, 0.76496226, 0.63814443],\n",
       " [0.4379478150390804, 0.1289186, 0.21081024],\n",
       " [0.17389228856041034, 0.08699841, 0.6326777],\n",
       " [0.2587313330864715, 0.42128402, 0.34089395],\n",
       " [0.790022042857199, 0.7008555, 0.6322143],\n",
       " [0.7233056492229029, 0.8873639, 0.9280161],\n",
       " [0.6476037453373378, 0.9001056, 0.22066239],\n",
       " [0.15868944103733917, 0.020569114, 0.014099388],\n",
       " [0.712874579103384, 0.49701628, 0.09897752],\n",
       " [0.5053256228039004, 0.67613214, 0.31030926],\n",
       " [0.8104250409706201, 0.7707787, 0.7537075],\n",
       " [0.18246884284734013, 0.13859479, 0.1440948],\n",
       " [0.731399389720626, 0.8652244, 0.8112113],\n",
       " [0.5608610330957767, 0.16412415, 0.54382044],\n",
       " [0.22689385228117312, 0.103065625, 0.7469322],\n",
       " [0.1356655872942848, 0.13184145, 0.28650275],\n",
       " [0.8053402936580613, 0.7654894, 0.88933784],\n",
       " [0.7618504351708926, 0.24406232, 0.44494426],\n",
       " [0.5793857909272802, 0.31588963, 0.26561916],\n",
       " [0.43563609328534214, 0.6868445, 0.5981255],\n",
       " [0.5027936644672832, 0.8506628, 0.23279665],\n",
       " [0.5725538065163057, 0.8252686, 0.48257983],\n",
       " [0.5980330028935036, 0.61895424, 0.08885129],\n",
       " [0.7891643698526255, 0.6764575, 0.13562396],\n",
       " [0.43121593020701027, 0.23581055, 0.06660588],\n",
       " [0.6417707256034516, 0.65082747, 0.041217845],\n",
       " [0.04148616277953281, 0.03905973, 0.475041],\n",
       " [0.7261089927913478, 0.51826954, 0.16081479],\n",
       " [0.7930182784524827, 0.8070622, 0.89064646],\n",
       " [0.06706810711627909, 0.028027624, 0.20378518],\n",
       " [0.7681023962927279, 0.8368395, 0.6732433],\n",
       " [0.775082877190334, 0.8604174, 0.45010123],\n",
       " [0.7465646151174822, 0.7487486, 0.11761877],\n",
       " [0.7903283188183107, 0.1137505, 0.11981323],\n",
       " [0.0798561515570378, 0.023802176, 0.015272828],\n",
       " [0.44846488221034525, 0.77411366, 0.07278112],\n",
       " [0.6331478935440319, 0.40051186, 0.29601896],\n",
       " [0.3230651033751289, 0.08220613, 0.10014568],\n",
       " [0.8038354396120121, 0.93397254, 0.8049922],\n",
       " [0.36547374070564015, 0.18491212, 0.06868976],\n",
       " [0.6077228983663484, 0.5408965, 0.2168749],\n",
       " [0.7002233693311065, 0.6321474, 0.6001671],\n",
       " [0.6718178627986341, 0.4927219, 0.7523148],\n",
       " [0.3640946365182592, 0.5804165, 0.3726871],\n",
       " [0.45951682228575347, 0.046024144, 0.52480054],\n",
       " [0.8316840313727507, 0.86235774, 0.76813936],\n",
       " [0.8475501161154751, 0.8163692, 0.28647816],\n",
       " [0.45857281450273635, 0.61327046, 0.036035925],\n",
       " [0.7335994329731482, 0.7704274, 0.35601857],\n",
       " [0.8043656656568656, 0.9104059, 0.50315857],\n",
       " [0.7286985349781605, 0.88211423, 0.4248387],\n",
       " [0.04494957646285145, 0.017962314, 0.07760916],\n",
       " [0.5074078846144026, 0.94347525, 0.33757058],\n",
       " [0.8124234553511309, 0.8971708, 0.1561797],\n",
       " [0.5885888965004954, 0.9290072, 0.29340464],\n",
       " [0.07593867480015151, 0.24615318, 0.2539279],\n",
       " [0.42716968485619544, 0.13466956, 0.044423435],\n",
       " [0.6417648076166835, 0.80583155, 0.816366],\n",
       " [0.9140654331543361, 0.70810837, 0.62609637],\n",
       " [0.7705596591432979, 0.8200663, 0.33401108],\n",
       " [0.6849036149637722, 0.8811569, 0.70567816],\n",
       " [0.6261578380901401, 0.8013201, 0.76410204],\n",
       " [0.18518399502738156, 0.40339187, 0.057356305],\n",
       " [0.2650501492451356, 0.31823498, 0.28956157],\n",
       " [0.6531952919649733, 0.6957221, 0.2799314],\n",
       " [0.5572344618718681, 0.7642611, 0.35259542],\n",
       " [0.5473776316635841, 0.7666784, 0.76230687],\n",
       " [0.8511002048440202, 0.91055906, 0.878717],\n",
       " [0.20192921578535852, 0.11632787, 0.30212283],\n",
       " [0.2547897897612648, 0.65442795, 0.5011136],\n",
       " [0.03396804826732621, 0.19592659, 0.041032393],\n",
       " [0.483047026932481, 0.1359322, 0.3859315],\n",
       " [0.6826082335848652, 0.7571589, 0.5564467],\n",
       " [0.6848017909472693, 0.29737642, 0.47483158],\n",
       " [0.22629735993985986, 0.052823447, 0.043006964],\n",
       " [0.4404419328815738, 0.8712912, 0.78024495],\n",
       " [0.5208588028163063, 0.079816364, 0.2893226],\n",
       " [0.6529944701250218, 0.9383029, 0.7272236],\n",
       " [0.33675422244295694, 0.059273835, 0.152009],\n",
       " [0.27791526006137696, 0.789032, 0.2560883],\n",
       " [0.7596551979480787, 0.7350665, 0.6880808],\n",
       " [0.717619731839566, 0.92185354, 0.26192778],\n",
       " [0.2963106285659944, 0.13570176, 0.23252806],\n",
       " [0.5559619870211184, 0.8727945, 0.2823658],\n",
       " [0.4977740820336537, 0.12745777, 0.35725763],\n",
       " [0.36957801314367766, 0.090104, 0.8175651],\n",
       " [0.3685374021680755, 0.43372217, 0.8343497],\n",
       " [0.564095559722638, 0.071618274, 0.8759932],\n",
       " [0.2938945513309567, 0.44142348, 0.1588898],\n",
       " [0.28048203552187506, 0.1698128, 0.21771604],\n",
       " [0.3955439504664673, 0.032799482, 0.1430504],\n",
       " [0.5432790553840297, 0.39418843, 0.51975876],\n",
       " [0.2508740271101032, 0.1434978, 0.38699585],\n",
       " [0.3281112819974924, 0.40034965, 0.01843014],\n",
       " [0.10808125860643947, 0.105708, 0.86909425],\n",
       " [0.15014290697359134, 0.124676645, 0.12772876],\n",
       " [0.5955681758478221, 0.9307395, 0.8740475],\n",
       " [0.6632276586514514, 0.8859762, 0.6500558],\n",
       " [0.021207256953946416, 0.6190344, 0.034398064],\n",
       " [0.764747581441217, 0.788677, 0.28721765],\n",
       " [0.48863537863011, 0.29466307, 0.3801373],\n",
       " [0.2667431537331005, 0.044542033, 0.4350546],\n",
       " [0.7705230285594953, 0.7530366, 0.18446454],\n",
       " [0.507041514624177, 0.9086307, 0.28927168],\n",
       " [0.5360278220862478, 0.9694313, 0.45581394],\n",
       " [0.1376912294557307, 0.00603804, 0.20229205],\n",
       " [0.6755196753580551, 0.69056636, 0.75502044],\n",
       " [0.14082617939834657, 0.10482032, 0.5602045],\n",
       " [0.39088983872577826, 0.15393467, 0.078637466],\n",
       " [0.1236226878931811, 0.055872146, 0.011691566],\n",
       " [0.24407178699946122, 0.43822852, 0.1356473],\n",
       " [0.19500166081456258, 0.2822884, 0.29673284],\n",
       " [0.28502073880863016, 0.92658395, 0.18708396],\n",
       " [0.26022505395516005, 0.30292657, 0.3497471],\n",
       " [0.18151679355606207, 0.021662192, 0.005663269],\n",
       " [0.5692775659370838, 0.7304324, 0.034734163],\n",
       " [0.13364846797989818, 0.060855336, 0.015951058],\n",
       " [0.262923049615724, 0.078685574, 0.41877067],\n",
       " [0.3354910887145312, 0.104719244, 0.30514988],\n",
       " [0.5050419109887639, 0.531997, 0.16915412],\n",
       " [0.00027314318221482905, 0.06531874, 0.0039578034],\n",
       " [0.009122423884226263, 0.04866079, 0.16959116],\n",
       " [0.5680176036528256, 0.58070993, 0.4387588],\n",
       " [0.42507356215965825, 0.37576473, 0.013568844],\n",
       " [0.46123559623837856, 0.107580386, 0.34006694],\n",
       " [0.7549274346278122, 0.4703104, 0.2493188],\n",
       " [0.7099812617857131, 0.8808052, 0.8830201],\n",
       " [0.6660382489434968, 0.62639993, 0.11942733],\n",
       " [0.47063501171442534, 0.6511289, 0.022036128],\n",
       " [0.8402870502784349, 0.78094554, 0.86752987],\n",
       " [0.17948965524992205, 0.26634684, 0.054038998],\n",
       " [0.6111959109841546, 0.8391178, 0.23434381],\n",
       " [0.6194736633725477, 0.73868114, 0.39634994],\n",
       " [0.8254747083857386, 0.8949453, 0.9744762],\n",
       " [0.29529952841864976, 0.08219479, 0.041300245],\n",
       " [0.11554008055604587, 0.20588987, 0.094882585],\n",
       " [0.08536887280721758, 0.10930157, 0.03011128],\n",
       " [0.4749723424309325, 0.9165369, 0.43556565],\n",
       " [0.17104199560767305, 0.6825267, 0.027712798],\n",
       " [0.07487112057469891, 0.02754126, 0.20750362],\n",
       " [0.3774744850957595, 0.04702919, 0.34650865],\n",
       " [0.3598996398487987, 0.39727476, 0.4133847],\n",
       " [0.5166549419951142, 0.43690395, 0.30370125],\n",
       " [0.1205582459762148, 0.09329165, 0.20818676],\n",
       " [0.5445885212172596, 0.18349054, 0.22980464],\n",
       " [0.3973106010197563, 0.4757127, 0.6486606],\n",
       " [0.13496953756702154, 0.08561345, 0.726054],\n",
       " [0.4674374646586389, 0.43660918, 0.81502056],\n",
       " [0.6137414619284731, 0.7481226, 0.024695119],\n",
       " [0.21014803625531112, 0.109226994, 0.07044954],\n",
       " [0.17154171907296678, 0.1577425, 0.65441173],\n",
       " [0.6482076592432289, 0.47073773, 0.31342712],\n",
       " [0.14128015662984045, 0.1754289, 0.101098195],\n",
       " [0.7097862789125338, 0.89185625, 0.8818054],\n",
       " [0.47724758364811776, 0.6406304, 0.058789693],\n",
       " [0.7558219749658922, 0.8955806, 0.7815185],\n",
       " [0.0003202825682549273, 0.14651737, 0.002327427],\n",
       " [0.047730142654367105, 0.07273551, 0.02227851],\n",
       " [0.6407506999328162, 0.8723168, 0.05142839],\n",
       " [0.6639155434326944, 0.9283485, 0.13948515],\n",
       " [0.2642812461241487, 0.07993261, 0.03988847],\n",
       " [0.7097651867843888, 0.876078, 0.06382724],\n",
       " [0.7489617866224074, 0.945751, 0.4436301],\n",
       " [0.11613137268332734, 0.063551575, 0.04261238],\n",
       " [0.2623414651429013, 0.23881634, 0.12614639],\n",
       " [0.3028549773120475, 0.11844267, 0.36967197],\n",
       " [0.27675225772353845, 0.2978686, 0.0055023553],\n",
       " [0.3697604450912148, 0.1557517, 0.7254127],\n",
       " [0.3964991072759212, 0.5571601, 0.019021794],\n",
       " [0.7121359211068049, 0.87682146, 0.9024395],\n",
       " [0.32557459565956515, 0.2737195, 0.048212968],\n",
       " [0.6021085240277126, 0.58427656, 0.45508307],\n",
       " [0.5980871662999111, 0.12692852, 0.25911757],\n",
       " [0.7254544895345975, 0.79052746, 0.49199677],\n",
       " [0.6569662541341164, 0.9268994, 0.580684],\n",
       " [0.6953994776183794, 0.47498488, 0.037505064],\n",
       " [0.4508324771132908, 0.35640666, 0.5307943],\n",
       " [0.2272337883683834, 0.20005281, 0.8475927],\n",
       " [0.0012025743250875444, 0.7523577, 0.008009368],\n",
       " [0.3088767719498693, 0.08425384, 0.07509459],\n",
       " [0.3764519049711538, 0.8675007, 0.9724727],\n",
       " [0.44073970904190046, 0.14412151, 0.104594804],\n",
       " [0.0818758863980347, 0.0450406, 0.028828047],\n",
       " [0.3477476506123915, 0.7809358, 0.02823431],\n",
       " [0.7792425745948475, 0.91088384, 0.6290196],\n",
       " [0.17944630550206872, 0.13833636, 0.13612998],\n",
       " [0.37589660596114305, 0.036825918, 0.13836904],\n",
       " [0.8092567295169547, 0.77898127, 0.21279147],\n",
       " [0.6549587222724843, 0.9395051, 0.041470915],\n",
       " [0.36176877769456983, 0.6144203, 0.06575419],\n",
       " [0.26335180985386075, 0.058864437, 0.037835207],\n",
       " [0.6482912016605206, 0.33205143, 0.3623338],\n",
       " [0.12137654595610488, 0.04693714, 0.47264913],\n",
       " [0.5207331288525933, 0.62729126, 0.36519647],\n",
       " [0.808467211249454, 0.77394295, 0.23832498],\n",
       " [0.4081392403263772, 0.0744872, 0.07003889],\n",
       " [0.22206965841275883, 0.088144965, 0.033922818],\n",
       " [0.251035933167747, 0.31197542, 0.5951738],\n",
       " [0.5964898478385272, 0.066536985, 0.7543844],\n",
       " [0.6883426077390391, 0.8886832, 0.18404166],\n",
       " [0.04582464683142511, 0.04352953, 0.28235015],\n",
       " [0.6841477336098869, 0.4990015, 0.92962253],\n",
       " [0.0961380276749017, 0.14344603, 0.009974695],\n",
       " [0.3528190867280045, 0.11267118, 0.059555016],\n",
       " [0.6541102619474809, 0.87288773, 0.17227879],\n",
       " [0.5553997995500838, 0.8860257, 0.4630731],\n",
       " [0.6150577580829902, 0.7558361, 0.23758511],\n",
       " [0.8034762234222027, 0.7802822, 0.63624567],\n",
       " [0.7254699956201209, 0.93657374, 0.87893707],\n",
       " [0.1718729336451391, 0.071074195, 0.03831682],\n",
       " [0.71048553110846, 0.7531478, 0.16919513],\n",
       " [0.5239463242523557, 0.19707842, 0.15932573],\n",
       " [0.36289556667800266, 0.79726964, 0.3264015],\n",
       " [0.5576255877619676, 0.622443, 0.23861532],\n",
       " [0.5338132386626555, 0.3491376, 0.4133381],\n",
       " [0.6788226944177193, 0.8169661, 0.19142891],\n",
       " [0.7007100688286746, 0.5280488, 0.17655793],\n",
       " [0.36842996664950056, 0.33495712, 0.1205114],\n",
       " [0.1704758819539718, 0.15793005, 0.6016637],\n",
       " [0.14609556984578786, 0.06783835, 0.012849889],\n",
       " [0.0662393234255226, 0.037254374, 0.80482507],\n",
       " [0.7204748222479775, 0.7462401, 0.46719164],\n",
       " [0.02101263003911402, 0.02488624, 0.21626279],\n",
       " [0.8448019369412822, 0.9497277, 0.9558352],\n",
       " [0.7222084596163842, 0.65816516, 0.075816],\n",
       " [0.2940865346997496, 0.5460492, 0.16493943],\n",
       " [0.6424920510175999, 0.4608926, 0.6147899],\n",
       " [0.14616007139662984, 0.0335342, 0.00816779],\n",
       " [0.0020715549990250773, 0.20177563, 0.06129113],\n",
       " [0.3271759909727572, 0.78900975, 0.19323896],\n",
       " [0.24555712275181568, 0.13162333, 0.32712102],\n",
       " [0.13736316227926712, 0.059209827, 0.010464463],\n",
       " [0.7858990610477632, 0.8252807, 0.18773101],\n",
       " [0.3242772443931485, 0.14410007, 0.14148784],\n",
       " [0.06391281371274789, 0.095316075, 0.25155583],\n",
       " [0.5212430369829577, 0.4694074, 0.01929461],\n",
       " [0.6446061166526704, 0.90615994, 0.2217777],\n",
       " [0.8293879983438863, 0.8674626, 0.7076783],\n",
       " [0.3455251043708428, 0.057557363, 0.033937067],\n",
       " [0.41378900279675873, 0.5543429, 0.58003527],\n",
       " [0.09246538788455652, 0.06418827, 0.046657432],\n",
       " [0.09194463880217986, 0.081025936, 0.26262847],\n",
       " [0.18532063969022128, 0.07677152, 0.030941054],\n",
       " [0.89619648827774, 0.92148423, 0.818013],\n",
       " [0.12709122092550276, 0.0553167, 0.1708639],\n",
       " [0.6835308147591082, 0.8776065, 0.28645843],\n",
       " [0.5593189007664651, 0.81560224, 0.41580003],\n",
       " [0.12464069095935755, 0.10492139, 0.039778307],\n",
       " [0.0002455751748207677, 0.901857, 0.101297446],\n",
       " [0.48845137779304004, 0.78015304, 0.11381445],\n",
       " [0.4116812988984093, 0.76937556, 0.035275802],\n",
       " [0.1509944648543936, 0.07226982, 0.09825905],\n",
       " [0.30110377316482667, 0.2726337, 0.04857838],\n",
       " [0.5937700743198527, 0.7893787, 0.2395835],\n",
       " [0.5932096922992582, 0.9225132, 0.23832002],\n",
       " [0.6118536404106117, 0.29505047, 0.09461302],\n",
       " [0.7300369195045088, 0.86143327, 0.8406609],\n",
       " [0.37961281826573673, 0.8043722, 0.4145391],\n",
       " [0.6988611171707566, 0.8768473, 0.8029156],\n",
       " [0.1526966756455525, 0.7593715, 0.02399312],\n",
       " [0.8129385455583166, 0.91386795, 0.5806164],\n",
       " [0.6785081645469506, 0.6737263, 0.13841748],\n",
       " [0.7411618816509709, 0.43565276, 0.067908525],\n",
       " [0.5239475543756281, 0.38918054, 0.43061084],\n",
       " [0.8430591881904062, 0.8268906, 0.08825925],\n",
       " [0.2918038541432229, 0.26125965, 0.9011926],\n",
       " [0.12353937963711399, 0.062325772, 0.4370286],\n",
       " [0.35461713525997945, 0.71780145, 0.46932214],\n",
       " [0.6668625824303744, 0.8365364, 0.6291391],\n",
       " [0.18355060761135078, 0.10745546, 0.22135043],\n",
       " [0.3258211126193022, 0.13143666, 0.53909385],\n",
       " [0.18292658606530912, 0.05332767, 0.45777437],\n",
       " [0.3809965705155233, 0.26418266, 0.46505725],\n",
       " [0.47283539039470396, 0.6716926, 0.34024465],\n",
       " [0.7997842939570968, 0.7949797, 0.6600937],\n",
       " [0.2050718930467025, 0.44775409, 0.5221442],\n",
       " [0.5841001192961958, 0.587331, 0.5530504],\n",
       " [0.34411532749189383, 0.06589701, 0.19897985],\n",
       " [0.34801270168927306, 0.45643982, 0.15357676],\n",
       " [0.0903795505917671, 0.05108098, 0.20173499],\n",
       " [0.07505366326356255, 0.015206663, 0.004482602],\n",
       " [0.5257065311352714, 0.5531666, 0.035795778],\n",
       " [0.7160273856466647, 0.96962386, 0.63511753],\n",
       " [0.12134788523854229, 0.6553172, 0.5480609],\n",
       " [0.7992458476594352, 0.6796311, 0.07732947],\n",
       " [0.6832646221160527, 0.8187554, 0.34709752],\n",
       " [0.37822441110218097, 0.7208087, 0.23414429],\n",
       " [0.548578195566016, 0.49627516, 0.4411326],\n",
       " [0.5610174589894054, 0.97406244, 0.6156355],\n",
       " [0.7362534709079488, 0.9165773, 0.8481928],\n",
       " [0.6849243304388036, 0.7773748, 0.70618],\n",
       " [0.5898831906690173, 0.7687587, 0.6943002],\n",
       " [0.07294195214928241, 0.021420104, 0.048988234],\n",
       " [0.7029370330933665, 0.9079291, 0.6699491],\n",
       " [0.23003119852787782, 0.07964451, 0.18567471],\n",
       " [0.4251595683705581, 0.37213796, 0.13559273],\n",
       " [0.6456928100860938, 0.666277, 0.029146487],\n",
       " [0.24012789673789312, 0.096163444, 0.3521485],\n",
       " [0.22280814659982, 0.06128745, 0.11349148],\n",
       " [0.2934319746468088, 0.6843549, 0.25477272],\n",
       " [0.65551586009298, 0.8397332, 0.5780217],\n",
       " [0.834543756085644, 0.8609895, 0.9871884],\n",
       " [0.7223347397922987, 0.8201302, 0.6707949],\n",
       " [0.45559820379224714, 0.21116549, 0.058741163],\n",
       " [0.7586989109714937, 0.6969641, 0.8958043],\n",
       " [0.06777681438162983, 0.05343201, 0.16674042],\n",
       " [0.4856494480024128, 0.88560295, 0.36316586],\n",
       " [0.050046880021032684, 0.010292478, 0.35187295],\n",
       " [0.21697953195308337, 0.114670545, 0.25326982],\n",
       " [0.8574113376603819, 0.89525247, 0.594468],\n",
       " [0.789287886231009, 0.9423826, 0.8336438],\n",
       " [0.4196266561072044, 0.0667071, 0.2925189],\n",
       " [0.553441005140849, 0.81922233, 0.6505008],\n",
       " [0.9273357134884068, 0.9079204, 0.9342636],\n",
       " [0.0009365870702456003, 0.72667044, 0.0043805125],\n",
       " [0.7581412480569135, 0.9259335, 0.7767065],\n",
       " [0.12269467307942554, 0.042233635, 0.05070851],\n",
       " [0.4789396099501026, 0.49850002, 0.28746155],\n",
       " [0.37961544587955187, 0.72559285, 0.16434439],\n",
       " [0.44881685719294906, 0.7665704, 0.35185733],\n",
       " [0.2871560573888708, 0.2328619, 0.052197207],\n",
       " [0.24449751798168415, 0.08018057, 0.2797353],\n",
       " [0.3399627036135291, 0.84290385, 0.03935588],\n",
       " [0.35836904607013126, 0.1737115, 0.56289333],\n",
       " [0.0005092344066863157, 0.7103573, 0.0026900328],\n",
       " [0.11326491216434081, 0.13653773, 0.029725088],\n",
       " [0.26592774929161206, 0.09425477, 0.50586814],\n",
       " [0.5069626313369459, 0.0648114, 0.7086681],\n",
       " [0.6281939556424585, 0.7781251, 0.2702824],\n",
       " [0.5715856739591134, 0.65794307, 0.33836418],\n",
       " [0.31562236364898116, 0.028658643, 0.08745726],\n",
       " [0.15042441865065342, 0.13900645, 0.47751173],\n",
       " [0.15512174297216716, 0.024479399, 0.5892529],\n",
       " [0.661427282472072, 0.8033697, 0.37041757],\n",
       " [0.7594252723379565, 0.85418254, 0.07371719],\n",
       " [0.5086537561034913, 0.4609674, 0.40252128],\n",
       " [0.08913993059192751, 0.020862443, 0.016302403],\n",
       " [0.1255978089488773, 0.048910964, 0.16446853],\n",
       " [0.4786962542706514, 0.7600722, 0.4088267],\n",
       " [0.19963449680092732, 0.10355803, 0.08724271],\n",
       " [0.8647486271650866, 0.469058, 0.13580874],\n",
       " [0.9186953118799823, 0.9413443, 0.37156287],\n",
       " [0.6452975211196702, 0.23987415, 0.35391074],\n",
       " [0.7458192257331915, 0.8894541, 0.421093],\n",
       " [0.0699390167481449, 0.12994452, 0.019229528],\n",
       " [0.0009344862978669008, 0.12291243, 0.08114881],\n",
       " [0.10577104829929443, 0.62257046, 0.13380818],\n",
       " [0.09631737328280404, 0.48581713, 0.027996095],\n",
       " [0.7394016390720314, 0.8504592, 0.15549356],\n",
       " [0.2080237576665174, 0.39752242, 0.23116677],\n",
       " [0.44772664576923255, 0.02422173, 0.13667463],\n",
       " [0.8388047629075, 0.7926802, 0.8273338],\n",
       " [0.5544702222201382, 0.9435371, 0.7370674],\n",
       " [0.04528071558844939, 0.021951122, 0.03920776],\n",
       " [0.05930306757164335, 0.082088195, 0.49414256],\n",
       " [0.7983431893689806, 0.8170662, 0.36572835],\n",
       " [0.016922725025714548, 0.09923401, 0.15188201],\n",
       " [0.4572479911041533, 0.08402416, 0.041252352],\n",
       " [0.40446167917275677, 0.79760563, 0.14780782],\n",
       " [0.3610774082165616, 0.604909, 0.34880388],\n",
       " [0.11221720901594208, 0.06627403, 0.035354696],\n",
       " [0.17495449989662332, 0.0018118109, 0.04221337],\n",
       " [0.40665918269210977, 0.14093858, 0.45953706],\n",
       " [0.5591830752133058, 0.8891101, 0.7939902],\n",
       " [0.2115457141044077, 0.09043838, 0.06147918],\n",
       " [0.7276424798688699, 0.92437255, 0.8353363],\n",
       " [0.2425418716264264, 0.16807637, 0.07997266],\n",
       " [0.5622833905384866, 0.8476768, 0.67535555],\n",
       " [0.4043770020287993, 0.20693965, 0.016292183],\n",
       " [0.31106659514162394, 0.25291297, 0.5427778],\n",
       " [0.5517104176306394, 0.022492463, 0.06841771],\n",
       " [0.0978780945498992, 0.021155477, 0.40581417],\n",
       " [0.5479202178407809, 0.54154354, 0.28835687],\n",
       " [0.6273283168960367, 0.9832985, 0.6930605],\n",
       " [0.3225965074947654, 0.45793033, 0.44292602],\n",
       " [0.7372130085774009, 0.75734043, 0.95532143],\n",
       " [0.07418862433558045, 0.06208198, 0.058618348],\n",
       " [0.15020350086949888, 0.18380862, 0.13842571],\n",
       " [0.14442462297178688, 0.023633143, 0.17442793],\n",
       " [0.35662533279068076, 0.84595376, 0.30319056],\n",
       " [0.45208413327696073, 0.86067903, 0.48558986],\n",
       " [0.5506823689025642, 0.73863804, 0.25051603],\n",
       " [0.6798007498655982, 0.07917343, 0.1556039],\n",
       " [0.17861317769487617, 0.15905067, 0.054448027],\n",
       " [0.5262556740102132, 0.73018414, 0.04395208],\n",
       " [0.27841992627784456, 0.30308613, 0.057159934],\n",
       " [0.3097314640554155, 0.37498844, 0.17764735],\n",
       " [0.5884458870562553, 0.76777476, 0.9081114],\n",
       " [0.5906389388800809, 0.7242146, 0.22220793],\n",
       " [0.6665540909819307, 0.2242451, 0.2782181],\n",
       " [0.820761387789362, 0.9375471, 0.82544076],\n",
       " [0.7067588312431105, 0.9119888, 0.38728827],\n",
       " [0.533243936099609, 0.7868767, 0.29525116],\n",
       " [0.6456712087611276, 0.49532995, 0.23358782],\n",
       " [0.5339067925085983, 0.82194686, 0.17356944],\n",
       " [0.4075482958646216, 0.5504617, 0.39821255],\n",
       " [0.5600469170766884, 0.16819263, 0.15957586],\n",
       " [0.6726295042881975, 0.60251004, 0.55807734],\n",
       " [0.5267557641740364, 0.61439836, 0.555205],\n",
       " [0.1055274734070348, 0.017868092, 0.18316676],\n",
       " [0.8596929294182706, 0.8304615, 0.7597044],\n",
       " [0.7680115256157366, 0.7341651, 0.81285],\n",
       " [0.4990518001084979, 0.10907729, 0.051828556],\n",
       " [0.8721648301414827, 0.88280237, 0.7954423],\n",
       " [0.23335353880694834, 0.3850055, 0.14067324],\n",
       " [0.3534963296187438, 0.14514707, 0.08079208],\n",
       " [0.7293040761043164, 0.9375457, 0.19392793],\n",
       " [0.4021516125542258, 0.33058548, 0.009845058],\n",
       " [0.5037460145070681, 0.437866, 0.20109905],\n",
       " [0.3562290727435739, 0.85749996, 0.47955695],\n",
       " [0.5866478341949956, 0.2798304, 0.07834314],\n",
       " [0.20997991971333183, 0.04022583, 0.18587254],\n",
       " [0.33122152038317343, 0.23715635, 0.13941793],\n",
       " [0.7078207247494438, 0.8194816, 0.58439916],\n",
       " [0.6354722071937116, 0.94664407, 0.7738077],\n",
       " [0.16651125465281005, 0.04822591, 0.48600757],\n",
       " [0.6945442860359684, 0.7484618, 0.23668101],\n",
       " [0.7936639588743247, 0.84547484, 0.39510816],\n",
       " [0.5513135371360031, 0.19834383, 0.11199253],\n",
       " [0.1237177517322339, 0.026036961, 0.13434619],\n",
       " [0.159424610351292, 0.09268096, 0.051445264],\n",
       " [0.561823828115465, 0.07329579, 0.21105489],\n",
       " [0.19669157885213165, 0.26306695, 0.09933595],\n",
       " [0.1832493330531526, 0.18360922, 0.24246566],\n",
       " [0.3383099572971933, 0.09886439, 0.22116926],\n",
       " [0.2914546763337316, 0.9127509, 0.19844964],\n",
       " [0.1503345731175916, 0.07661947, 0.11419981],\n",
       " [0.08417161891787807, 0.02670792, 0.37932152],\n",
       " [0.6251031321961161, 0.8967511, 0.7509698],\n",
       " [0.2763917006741736, 0.032191608, 0.14012702],\n",
       " [0.2700591466538212, 0.92638326, 0.64860374],\n",
       " [0.7462756605300143, 0.84086347, 0.41366225],\n",
       " [0.7354386813401952, 0.74385965, 0.6426682],\n",
       " [0.08126739456117701, 0.03572217, 0.7813471],\n",
       " [0.666650029673404, 0.8766403, 0.09706893],\n",
       " [0.16026593971031583, 0.097841494, 0.07682294],\n",
       " [0.12626751596563016, 0.074840225, 0.26447937],\n",
       " [0.131836771403623, 0.0904158, 0.06481844],\n",
       " [0.09799402053163357, 0.11252652, 0.025659325],\n",
       " [0.6556696722008728, 0.5466085, 0.78559124],\n",
       " [0.4144758928193175, 0.28079855, 0.19775712],\n",
       " [0.08264067706575005, 0.033731516, 0.09676516],\n",
       " [0.8598317395015922, 0.8747393, 0.83157444],\n",
       " [0.17558553221560735, 0.90120363, 0.1415523],\n",
       " [0.15157221374937738, 0.34115762, 0.20406626],\n",
       " [0.22713773444210664, 0.37146065, 0.1660534],\n",
       " [0.40960143601479293, 0.38204297, 0.50227463],\n",
       " [0.5981895806922992, 0.98893774, 0.20944913],\n",
       " [0.3179257884631761, 0.46286207, 0.062199343],\n",
       " [0.5963076947304621, 0.8734471, 0.17871466],\n",
       " [0.5583638444877895, 0.13035826, 0.16912161],\n",
       " [0.8263220708450892, 0.8318267, 0.9023967],\n",
       " [0.00047473804201734413, 0.8225277, 0.0020495532],\n",
       " [0.736134733479299, 0.9119245, 0.86049116],\n",
       " [0.6576978146048483, 0.70561963, 0.55178267],\n",
       " [0.525318746147702, 0.86270314, 0.8614106],\n",
       " [0.7305615372185839, 0.9210272, 0.45684415],\n",
       " [0.6835075150955868, 0.91213083, 0.23244686],\n",
       " [0.35853603912569143, 0.12232128, 0.7601952],\n",
       " [0.26721427768475997, 0.45679116, 0.38074467],\n",
       " [0.4917666218046561, 0.86718404, 0.36276037],\n",
       " [0.141573654736115, 0.17969163, 0.11088052],\n",
       " [0.3849711079277808, 0.69973755, 0.23808467],\n",
       " [0.7538882662220363, 0.86925596, 0.4179194],\n",
       " [0.3833374968535324, 0.14982438, 0.5797239],\n",
       " [0.5350724549951495, 0.23194149, 0.09053232],\n",
       " [0.31159851012941125, 0.7067132, 0.77145827],\n",
       " [0.6636634504422969, 0.76681685, 0.4838539],\n",
       " [0.5127493525468769, 0.8845246, 0.3153826],\n",
       " [0.31669111275726486, 0.7498385, 0.49488306],\n",
       " [0.5767050706005165, 0.9836484, 0.7180569],\n",
       " [0.6163576799647151, 0.4841203, 0.8544908],\n",
       " [0.3069990964500214, 0.11351187, 0.0682466],\n",
       " [0.3161577252703235, 0.045884684, 0.036627546],\n",
       " [0.3704173665429454, 0.47377554, 0.5681402],\n",
       " [0.6111352789883568, 0.94357616, 0.33725756],\n",
       " [0.23221473587531427, 0.21549827, 0.2527945],\n",
       " [0.22008737651533555, 0.12272608, 0.53087246],\n",
       " [0.5917823382324436, 0.7619065, 0.72381955],\n",
       " [0.6074093912385269, 0.89630306, 0.7451736],\n",
       " [0.40323018829239493, 0.18490355, 0.32712495],\n",
       " [0.8193489819087545, 0.96276665, 0.59616673],\n",
       " [0.6925982207868605, 0.74611044, 0.10182633],\n",
       " [0.12483077771889965, 0.3268771, 0.040463265],\n",
       " [0.6042937670483152, 0.52305615, 0.59457386],\n",
       " [0.6265459957011934, 0.6402285, 0.21020287],\n",
       " [0.551860176583249, 0.71426827, 0.037955374],\n",
       " [0.8354734905073948, 0.8248868, 0.964856],\n",
       " [0.5059314656736384, 0.19920534, 0.58373076],\n",
       " [0.1377797758143409, 0.048927028, 0.14774974],\n",
       " [0.12501656844200715, 0.101958066, 0.57958096],\n",
       " [0.7244946344922535, 0.7857568, 0.54031867],\n",
       " [0.10299612567553815, 0.38051537, 0.10954394],\n",
       " [0.024126343612119516, 0.013366477, 0.25714344],\n",
       " [0.7345510127950016, 0.92805904, 0.06714506],\n",
       " [0.8491621534047901, 0.8744526, 0.6639142],\n",
       " [0.07720334809876575, 0.08182031, 0.21335416],\n",
       " [0.6775259449559901, 0.8669612, 0.82574475],\n",
       " [0.033153245603898054, 0.0048713456, 0.09915902],\n",
       " [0.8166341767674915, 0.7243777, 0.29977745],\n",
       " [0.3512858560465101, 0.44338346, 0.29430392],\n",
       " [0.8100022366793868, 0.45191202, 0.39708742],\n",
       " [0.6525078619446414, 0.22192496, 0.14117417],\n",
       " [0.18190274644880797, 0.050486755, 0.053035587],\n",
       " [0.7301678871852333, 0.9463782, 0.60349035],\n",
       " [0.688026004313672, 0.85721934, 0.47888148],\n",
       " [0.0002455751748207677, 0.5852305, 0.006526063],\n",
       " [0.3008246900210337, 0.07395275, 0.3186577],\n",
       " [0.7535373412735229, 0.9095474, 0.58347255],\n",
       " [0.8575147418495797, 0.63794667, 0.40043643],\n",
       " [0.654294152452037, 0.36279452, 0.31382063],\n",
       " [0.4798877955529153, 0.047752827, 0.0031207043],\n",
       " [0.00492252119211226, 0.87035316, 0.043177474],\n",
       " [0.8347241985518591, 0.9462007, 0.7453457],\n",
       " [0.5088434625201126, 0.036197525, 0.04826641],\n",
       " [0.11485582314602549, 0.040643115, 0.097307935],\n",
       " [0.2625093708895607, 0.17241515, 0.6216115],\n",
       " [0.4059860418739729, 0.10897044, 0.31464636],\n",
       " [0.20637420251082345, 0.10862369, 0.6497804],\n",
       " [0.289232650055765, 0.2566394, 0.08414106],\n",
       " [0.27861864335323655, 0.30670315, 0.21709721],\n",
       " [0.2670240323296919, 0.1430034, 0.06265065],\n",
       " [0.7367189874633981, 0.78641135, 0.9392859],\n",
       " [0.6821538991025505, 0.9572507, 0.60734564],\n",
       " [0.858147454829934, 0.7964045, 0.2990641],\n",
       " [0.5360221091051472, 0.8565918, 0.55867666],\n",
       " [0.662436839921834, 0.57659036, 0.066195704],\n",
       " [0.7367424989712219, 0.9231045, 0.34421575],\n",
       " [0.5011891191993856, 0.7225637, 0.14949445],\n",
       " [0.10515561197645092, 0.028208435, 0.048196606],\n",
       " [0.6723420760272766, 0.8879257, 0.46325642],\n",
       " [0.49268068808443805, 0.41613021, 0.106454246],\n",
       " [0.5255991462151733, 0.7011776, 0.27260944],\n",
       " [0.05859489009521387, 0.091784135, 0.06768365],\n",
       " [0.7395416381388844, 0.45922282, 0.4217191],\n",
       " [0.2721391992624634, 0.15994261, 0.024225008],\n",
       " [0.22241597909691135, 0.05995397, 0.006286422],\n",
       " [0.5019599867231299, 0.34933308, 0.37215233],\n",
       " [0.25083215942664483, 0.2196905, 0.57153416],\n",
       " [0.6559755444477763, 0.8055498, 0.23371649],\n",
       " [0.46184942456101674, 0.3173197, 0.15910076],\n",
       " [0.6192791334455383, 0.5712797, 0.7315314],\n",
       " [0.42833686504150503, 0.0969259, 0.12816273],\n",
       " [0.05109789681402429, 0.1891403, 0.5081301],\n",
       " [0.7845303697422918, 0.9127948, 0.70371366],\n",
       " [0.7689660925679022, 0.80151576, 0.540227],\n",
       " [0.07641429981864746, 0.09135523, 0.018592892],\n",
       " [0.11445776346717083, 0.11784767, 0.03759423],\n",
       " [0.31570305171591806, 0.8482899, 0.4339011],\n",
       " [0.5095053290673038, 0.18724698, 0.8075286],\n",
       " [0.3147955861716783, 0.47408876, 0.4678681],\n",
       " [0.3336619231773792, 0.7317294, 0.43585062],\n",
       " [0.04385989317784303, 0.06885501, 0.0022012303],\n",
       " [0.14754071080217093, 0.049812343, 0.019652614],\n",
       " [0.3736090492331508, 0.88399434, 0.6426192],\n",
       " [0.09696972809738587, 0.03882669, 0.22632684],\n",
       " [0.6173067225371616, 0.86067903, 0.48253247],\n",
       " [0.2539562938067561, 0.40046808, 0.0698086],\n",
       " [0.4885203453109646, 0.8382696, 0.58959526],\n",
       " [0.13867307716587654, 0.66646934, 0.5762945],\n",
       " [0.43110722695692333, 0.19577315, 0.26110914],\n",
       " [0.3922959082005454, 0.23200329, 0.20302485],\n",
       " [0.37183303946458257, 0.029942213, 0.48974258],\n",
       " [0.3572618502375714, 0.6656027, 0.18025216],\n",
       " [0.6196513803772319, 0.42301267, 0.43053707],\n",
       " [0.8026458888674346, 0.8997105, 0.5845467],\n",
       " [0.61874455603087, 0.80577487, 0.58275604],\n",
       " [0.06778733362446406, 0.027534343, 0.044699457],\n",
       " [0.47088158124186036, 0.9331602, 0.77795136],\n",
       " [0.6587525688940512, 0.7245979, 0.14098863],\n",
       " [0.4405789586644586, 0.6981462, 0.072415136],\n",
       " [0.7299434400158601, 0.16432145, 0.083986394],\n",
       " [0.39676478336530513, 0.18983306, 0.05410627],\n",
       " [0.6476299322963556, 0.85931844, 0.29336542],\n",
       " [0.5674651541821459, 0.3029713, 0.53549033],\n",
       " [0.3697604450912148, 0.9205849, 0.36028865],\n",
       " [0.7644919557173135, 0.9193136, 0.7755421],\n",
       " [0.39353367924118327, 0.19682145, 0.19133064],\n",
       " [0.07713041740249736, 0.0147839775, 0.104547165],\n",
       " [0.7923597629636422, 0.91549987, 0.9562514],\n",
       " [0.23133899256901616, 0.9159013, 0.089614205],\n",
       " [0.23922114881889273, 0.08241802, 0.7845406],\n",
       " [0.772708662367778, 0.819553, 0.7684375],\n",
       " [0.37518485538913, 0.1888516, 0.08599556],\n",
       " [0.6840654744218452, 0.6343697, 0.103681654],\n",
       " [0.5593277092873166, 0.76228136, 0.960615],\n",
       " [0.21037483792508968, 0.17824079, 0.7648406],\n",
       " [0.5935110028843806, 0.8290302, 0.6508046],\n",
       " [0.27342209921533256, 0.120467365, 0.21441825],\n",
       " [0.1512447098539973, 0.18518479, 0.5650912],\n",
       " [0.7812395266155746, 0.8605051, 0.88539916],\n",
       " [0.5951020390479532, 0.9727563, 0.7973236],\n",
       " [0.27507767385995574, 0.18587744, 0.58089286],\n",
       " [0.20323028856449604, 0.14995278, 0.05945921],\n",
       " [0.06316917609504738, 0.17392673, 0.21421053],\n",
       " [0.6760627108270313, 0.67275786, 0.16228473],\n",
       " [0.26031523249653454, 0.12343485, 0.042659994],\n",
       " [0.1621551940362815, 0.030720068, 0.0041996203],\n",
       " [0.8582723705256798, 0.7969421, 0.2948871],\n",
       " [0.07698677430856521, 0.25817457, 0.35149866],\n",
       " [0.32040510906123526, 0.073502466, 0.07429946],\n",
       " [0.1746709234299289, 0.72914475, 0.40934792],\n",
       " [0.7850863686487769, 0.69671106, 0.31739348],\n",
       " [0.3427049741262613, 0.12837292, 0.103918426],\n",
       " [0.44307842367680617, 0.2769531, 0.5661346],\n",
       " [0.35129781577546293, 0.2257145, 0.079332635],\n",
       " [0.21758055508228963, 0.07168998, 0.016539311],\n",
       " [0.0003202825682549273, 0.91346437, 0.0043804767],\n",
       " [0.6338181124286786, 0.90626556, 0.08937936],\n",
       " [0.24040236339604015, 0.22719204, 0.15566015],\n",
       " [0.4032951493795341, 0.36587206, 0.2191814],\n",
       " [0.7526221529255781, 0.68713707, 0.72669184],\n",
       " [0.13791755086985502, 0.062431913, 0.007105677],\n",
       " [0.08699487161190743, 0.09440821, 0.0034849078],\n",
       " [0.00254855973884388, 0.24008055, 0.13414904],\n",
       " [0.19461332865078898, 0.30544728, 0.8206499],\n",
       " [0.1301508378956244, 0.2731997, 0.2545859],\n",
       " [0.2073471222026348, 0.3639521, 0.9025542],\n",
       " [0.36385193935558435, 0.41167894, 0.38827685],\n",
       " [0.09099216173758087, 0.046432152, 0.04878811],\n",
       " [0.20954886173783302, 0.04407082, 0.37389976],\n",
       " [0.23764843840381464, 0.043211203, 0.13968757],\n",
       " [0.5371343662677046, 0.095651604, 0.10855597],\n",
       " [0.3760302010758944, 0.31992215, 0.324872],\n",
       " [0.3962742199514912, 0.7255615, 0.3503421],\n",
       " [0.4444078533302221, 0.520455, 0.20241274],\n",
       " [0.060890619713035866, 0.080144525, 0.10890818],\n",
       " [0.5877990387327645, 0.159847, 0.48132512],\n",
       " [0.19392891079967817, 0.09887064, 0.15307894],\n",
       " [0.174776181689393, 0.14876734, 0.06296321],\n",
       " [0.4275835388928414, 0.76351273, 0.12423421],\n",
       " [0.18368776466176084, 0.0885936, 0.013594978],\n",
       " [0.8051001796087276, 0.7334407, 0.3112055],\n",
       " [0.14931294373491125, 0.6695666, 0.028790332],\n",
       " [0.4916525284804237, 0.13152233, 0.39613658],\n",
       " [0.8390175658406066, 0.93831086, 0.61976105],\n",
       " [0.4570913237987991, 0.8319203, 0.161046],\n",
       " [0.7352873512230363, 0.8728623, 0.953483],\n",
       " [0.7691164199288756, 0.53861654, 0.50401753],\n",
       " [0.13656364588805014, 0.06181346, 0.027265713],\n",
       " [0.03881793251927565, 0.2413644, 0.22382556],\n",
       " [0.5312068493010178, 0.7658108, 0.16480777],\n",
       " [0.3331216445187892, 0.6847799, 0.19066806],\n",
       " [0.4841621749802178, 0.39498934, 0.007287773],\n",
       " [0.6816524428612127, 0.76943445, 0.39814478],\n",
       " [0.12920829933732098, 0.034919016, 0.31616867],\n",
       " [0.27025927752298345, 0.16608912, 0.083302386],\n",
       " [0.4079418046517828, 0.29513747, 0.6695365],\n",
       " [0.012711909033748728, 0.025714507, 0.0052862912],\n",
       " [0.8477194044397254, 0.920894, 0.93365216],\n",
       " [0.881270652646683, 0.8332839, 0.88303626],\n",
       " [0.6196213081027258, 0.6496671, 0.12328136],\n",
       " [0.2010490014083778, 0.11804417, 0.28413358],\n",
       " [0.6499719928023452, 0.68580824, 0.4837394],\n",
       " [0.5861883649648183, 0.56417656, 0.21082842],\n",
       " [0.06464626728063973, 0.016369378, 0.017884526],\n",
       " [0.32567038606467613, 0.89742017, 0.66159797],\n",
       " [0.5329587894966126, 0.7984137, 0.021858266],\n",
       " [0.2504003512941506, 0.12091764, 0.04753272],\n",
       " [0.5500461442998312, 0.7024912, 0.47195992],\n",
       " [0.6594141209910663, 0.7746177, 0.38328123],\n",
       " [0.41988934676761624, 0.75797445, 0.044386405],\n",
       " [0.28143085149557107, 0.6853427, 0.05064205],\n",
       " [0.7096881738197128, 0.50444007, 0.05743865],\n",
       " [0.30127029386053433, 0.10414045, 0.25467062],\n",
       " [0.16591048120518206, 0.082936734, 0.06868779],\n",
       " [0.8603876876130411, 0.93799996, 0.49336553],\n",
       " [0.48082060835690027, 0.30274087, 0.17609766],\n",
       " [0.5317284172367989, 0.8462243, 0.128458],\n",
       " [0.807036482684566, 0.71274644, 0.11342139],\n",
       " [0.7866172190293755, 0.6449943, 0.15113136],\n",
       " [0.7790662943542911, 0.8563112, 0.612766],\n",
       " [0.40171652403103203, 0.4465011, 0.078818806],\n",
       " [0.2530517981987145, 0.107363924, 0.057251457],\n",
       " [0.20797110993450676, 0.55297506, 0.2968698],\n",
       " [0.3891214055232282, 0.89981693, 0.6564202],\n",
       " [0.6680603112621767, 0.23292935, 0.53379786],\n",
       " [0.35709927564422056, 0.26422518, 0.24062215],\n",
       " [0.11225912945281345, 0.11828874, 0.29088238],\n",
       " [0.856014780534687, 0.77023363, 0.14905594],\n",
       " [0.614180610059411, 0.90389585, 0.13237317],\n",
       " [0.41300544434169656, 0.12139484, 0.11998575],\n",
       " [0.6191963097206198, 0.7266138, 0.031158322],\n",
       " [0.3864247900276121, 0.08827044, 0.56110346],\n",
       " [0.8369840323658192, 0.85779375, 0.76799816],\n",
       " [0.5685316160438528, 0.85112697, 0.6124001],\n",
       " [0.4147337937220386, 0.75025797, 0.7766975],\n",
       " [0.7742036093140964, 0.8140317, 0.63672245],\n",
       " [0.6939678198786013, 0.7837954, 0.10892107],\n",
       " [0.45745481522039455, 0.2349949, 0.08472616],\n",
       " [0.12937772853132595, 0.04823419, 0.21203516],\n",
       " [0.6604365581346802, 0.5610306, 0.45894858],\n",
       " [0.20520588646827417, 0.58347243, 0.18908878],\n",
       " [0.03795199722941272, 0.07403731, 0.36089018],\n",
       " [0.7508513414697896, 0.8354743, 0.012363186],\n",
       " [0.7887675804044793, 0.9060334, 0.69661564],\n",
       " [0.6034713844016003, 0.49296743, 0.4256958],\n",
       " [0.16321293801612574, 0.011416778, 0.80776495],\n",
       " [0.21252200595508328, 0.13045838, 0.004422678],\n",
       " [0.36159854888534987, 0.50639135, 0.018111166],\n",
       " [0.7151916461144784, 0.30776274, 0.8603418],\n",
       " [0.4078993256650901, 0.8873529, 0.8390002],\n",
       " [0.8584145539362407, 0.8570927, 0.6934384],\n",
       " [0.365910902460978, 0.089667365, 0.013101416],\n",
       " [0.6313255435537161, 0.8217506, 0.21276917],\n",
       " [0.4396321522987543, 0.1282273, 0.101785496],\n",
       " [0.6228015210337656, 0.45908412, 0.25333372],\n",
       " [0.20189001019616218, 0.073947236, 0.06649862],\n",
       " [0.0648977913987744, 0.058371753, 0.27134588],\n",
       " [0.3019611267287454, 0.18764511, 0.007324397],\n",
       " [0.588376173604153, 0.51133996, 0.17098686],\n",
       " [0.04266094147989436, 0.11415379, 0.024197977],\n",
       " [0.1680471747333465, 0.01657086, 0.026342954],\n",
       " [0.2469468245184008, 0.3443033, 0.41241163],\n",
       " [0.8353340202625228, 0.8776462, 0.5871291],\n",
       " [0.0009410305750107625, 0.7730063, 0.0022755251],\n",
       " [0.496461365413323, 0.10127111, 0.078116536],\n",
       " [0.22356418269830503, 0.051187214, 0.0479153],\n",
       " [0.31806034705281155, 0.7603167, 0.035194244],\n",
       " [0.7632201782081448, 0.8238119, 0.3007935],\n",
       " [0.1089982119718851, 0.06013613, 0.032471307],\n",
       " [0.5873554110546568, 0.6536674, 0.6255291],\n",
       " [0.9186057352146303, 0.6966044, 0.6486582],\n",
       " [0.5856664562161116, 0.35348588, 0.17746721],\n",
       " [0.09268021957548882, 0.02774472, 0.031471144],\n",
       " [0.433420493368445, 0.67970455, 0.34003878],\n",
       " [0.25333591889568113, 0.8598579, 0.28446412],\n",
       " [0.1888290715596552, 0.0142670795, 0.02192234],\n",
       " [0.04171005276045375, 0.017265005, 0.014158581],\n",
       " [0.8461763506518524, 0.62287724, 0.28938383],\n",
       " [0.4921679248808617, 0.3539826, 0.02144103],\n",
       " [0.3478410815511198, 0.9616169, 0.0649204],\n",
       " [0.7806931894316678, 0.92202353, 0.7734011],\n",
       " [0.03368270364343741, 0.062690444, 0.015809558],\n",
       " [0.9593530906195029, 0.9716241, 0.90281415],\n",
       " [0.5103262582015718, 0.35896596, 0.8261331],\n",
       " [0.34257410243310504, 0.15792792, 0.07038121],\n",
       " [0.809854289791396, 0.85668594, 0.1138175],\n",
       " [0.11284750085034304, 0.031615335, 0.73716736],\n",
       " [0.50338128057881, 0.05193331, 0.053693667],\n",
       " [0.592891861654728, 0.3260135, 0.24848947],\n",
       " [0.37578948902174714, 0.77003366, 0.08496951],\n",
       " [0.7584750845174132, 0.891694, 0.035305787],\n",
       " [0.13330205446526433, 0.033817247, 0.29325217],\n",
       " [0.2834638793969619, 0.038854495, 0.031375542],\n",
       " [0.07856581242171196, 0.074888684, 0.07017792],\n",
       " [0.7359052154166803, 0.86648387, 0.742999],\n",
       " [0.6381045122187353, 0.90322596, 0.75235975],\n",
       " [0.1775695824499989, 0.07804199, 0.018790407],\n",
       " [0.17456324382576505, 0.23390661, 0.35814345],\n",
       " [0.17314718597165385, 0.2841346, 0.06875262],\n",
       " [0.47352274420730556, 0.7461078, 0.04675651],\n",
       " [0.8060457631814106, 0.88672507, 0.8131508],\n",
       " [0.8056421578452857, 0.98267406, 0.7456053],\n",
       " [0.5139571183983775, 0.5541646, 0.47114423],\n",
       " [0.5561645017511223, 0.9321249, 0.521065],\n",
       " [0.27040813382917106, 0.06904988, 0.42857176],\n",
       " [0.8332105707746986, 0.9434043, 0.5194289],\n",
       " [0.4363335001228239, 0.9030277, 0.8672386],\n",
       " [0.5192316959334516, 0.44250944, 0.7623107],\n",
       " [0.7219162880586972, 0.8962287, 0.4629012],\n",
       " [0.6539741651074137, 0.71341914, 0.80695367],\n",
       " [0.664707859049528, 0.8625391, 0.3439159],\n",
       " [0.45199350924386156, 0.7095728, 0.79844207],\n",
       " [0.30614709876928914, 0.1901515, 0.4237453],\n",
       " [0.0002455751748207677, 0.9242353, 0.0144518055],\n",
       " [0.43213563563193264, 0.53933007, 0.1282982],\n",
       " [0.6841190658151136, 0.93261975, 0.4698393],\n",
       " [0.7904631217218929, 0.89810014, 0.7987098],\n",
       " [0.47983728419188926, 0.54113805, 0.26909596],\n",
       " [0.4689804778842085, 0.6414081, 0.08227157],\n",
       " [0.9247638678331147, 0.93944156, 0.30716848],\n",
       " [0.22108843496620884, 0.7751032, 0.77365047],\n",
       " [0.5108413126926767, 0.87722796, 0.22955786],\n",
       " [0.761911797728369, 0.8596247, 0.40867162],\n",
       " [0.3485097840920074, 0.46243116, 0.4852986],\n",
       " [0.40394898973213594, 0.8250924, 0.86487174],\n",
       " [0.15230604928774982, 0.08581078, 0.011155791],\n",
       " [0.5599759957520419, 0.66522974, 0.24907425],\n",
       " [0.09326247913897585, 0.2537168, 0.30072156],\n",
       " [0.4576514174364626, 0.053765263, 0.7363187],\n",
       " [0.6774730200450829, 0.8291912, 0.6578249],\n",
       " [0.7002309817409706, 0.7095704, 0.22644451],\n",
       " [0.370948903003442, 0.7314611, 0.49891356],\n",
       " [0.5689447215551842, 0.7691423, 0.22557011],\n",
       " [0.5672767304197011, 0.78038657, 0.856929],\n",
       " [0.8528183504561546, 0.9103381, 0.34203666],\n",
       " [0.6232287743935938, 0.5359011, 0.047476847],\n",
       " [0.2302846821279176, 0.040345922, 0.00290591],\n",
       " [0.31848567921800797, 0.54802096, 0.04907524],\n",
       " [0.02921030753007764, 0.050359447, 0.05386681],\n",
       " [0.7320316812315145, 0.7828219, 0.091635704],\n",
       " [0.3376883982912407, 0.053515382, 0.10243642],\n",
       " [0.8755044576566917, 0.94220835, 0.84166336],\n",
       " [0.6159866738043448, 0.52065456, 0.025107816],\n",
       " [0.2554925598754337, 0.24078445, 0.38745117],\n",
       " [0.3556058199001402, 0.0968856, 0.0068758144],\n",
       " [0.5627284073431585, 0.78801036, 0.20153663],\n",
       " [0.5089837108661895, 0.35880318, 0.06151416],\n",
       " [0.6093158978558667, 0.7856721, 0.8931258],\n",
       " [0.29259156540333603, 0.17929737, 0.20528297],\n",
       " [0.2923616857835035, 0.15182564, 0.7385457],\n",
       " [0.4792749239597859, 0.5883275, 0.3259989],\n",
       " [0.7210466294942277, 0.8430565, 0.09844875],\n",
       " [0.40684914812646755, 0.3048211, 0.041058484],\n",
       " [0.2619975527701741, 0.15998134, 0.21732572],\n",
       " [0.8026649685423807, 0.9188896, 0.13388158],\n",
       " [0.3313701774819671, 0.043740228, 0.3535699],\n",
       " [0.43162283026969367, 0.4831681, 0.21078889],\n",
       " [0.3658632081922057, 0.0682896, 0.028915623],\n",
       " [0.2500655244051657, 0.5837151, 0.110499784],\n",
       " [0.26158086151582793, 0.9285267, 0.37160516],\n",
       " [0.40154415825794415, 0.8249708, 0.52662385],\n",
       " [0.4224040559399147, 0.65716505, 0.268733],\n",
       " [0.16955378821012326, 0.35651782, 0.038089354],\n",
       " [0.7303497672705155, 0.7981213, 0.27576602],\n",
       " [0.3863823584983563, 0.763471, 0.007634468],\n",
       " [0.5056864460500883, 0.0777368, 0.23990574],\n",
       " [0.37154190686649974, 0.014635358, 0.119731866],\n",
       " [0.6617458345077483, 0.9429562, 0.32706583],\n",
       " [0.1595605002365371, 0.06325066, 0.47679344],\n",
       " [0.22970351335346265, 0.078386396, 0.014171699],\n",
       " [0.6704968263781877, 0.48649907, 0.010539922],\n",
       " [0.4286511554485879, 0.7963084, 0.0075426525],\n",
       " [0.3470223883270057, 0.5215586, 0.11320342],\n",
       " [0.11665076978776809, 0.34507516, 0.55661833],\n",
       " [0.7470307983443554, 0.85197437, 0.19990164],\n",
       " [0.5730833279052954, 0.113518916, 0.19607447],\n",
       " [0.24540736555533516, 0.05509307, 0.011356029],\n",
       " [0.3826525978609762, 0.08528891, 0.18568605],\n",
       " [0.3336047708303723, 0.29842186, 0.10446233],\n",
       " [0.23166629060492921, 0.050488267, 0.21057741],\n",
       " [0.8182302272081177, 0.9014152, 0.9639594],\n",
       " [0.3691310232672587, 0.039473064, 0.64331603],\n",
       " [0.6841196660709743, 0.63684505, 0.009276358],\n",
       " [0.5976777315502216, 0.11833312, 0.60199165],\n",
       " [0.2820945059578954, 0.7112308, 0.035394594],\n",
       " [0.6479770234416127, 0.8931486, 0.29457206],\n",
       " [0.317606944302169, 0.6188507, 0.2931499],\n",
       " [0.17163204282696284, 0.881597, 0.089052804],\n",
       " [0.06343474572390602, 0.08070423, 0.279368],\n",
       " [0.17755846898117308, 0.469995, 0.21574944],\n",
       " [0.6019762502396667, 0.91746044, 0.8537676],\n",
       " [0.08774298279111484, 0.07143103, 0.20141359],\n",
       " [0.5851951532286828, 0.40828943, 0.36634874],\n",
       " [0.18921273702271355, 0.083114035, 0.054723363],\n",
       " [0.20100718618079955, 0.3914387, 0.42527014],\n",
       " [0.115508018473295, 0.012475574, 0.009394419],\n",
       " [0.4955083839589529, 0.057204194, 0.27270517],\n",
       " [0.11121220198173769, 0.12804885, 0.036974516],\n",
       " [0.44894691329962044, 0.5118962, 0.032763124],\n",
       " [0.2989000151447311, 0.26789138, 0.17395847],\n",
       " [0.14009446878760212, 0.03328536, 0.06434752],\n",
       " [0.7367878918252116, 0.8889972, 0.7091083],\n",
       " [0.16130970852881754, 0.03709198, 0.043634634],\n",
       " [0.6031658137719915, 0.48622912, 0.8235073],\n",
       " [0.23578379549224832, 0.05246985, 0.038572703],\n",
       " [0.5537175986676309, 0.35521385, 0.21839473],\n",
       " [0.13435674444000684, 0.15872963, 0.03751594],\n",
       " [0.5527678867838314, 0.49547863, 0.21152091],\n",
       " [0.13618114356602382, 0.026372379, 0.09899008],\n",
       " [0.2604239582530458, 0.059604455, 0.56493753],\n",
       " [0.6229581387660834, 0.85779786, 0.8287898],\n",
       " [0.33918792690900107, 0.09266348, 0.13307992],\n",
       " [0.5312142966887392, 0.15842426, 0.34536624],\n",
       " [0.7227023816531041, 0.95942724, 0.76935303],\n",
       " [0.5745933830916384, 0.56518704, 0.17184909],\n",
       " [0.25452305393220825, 0.34238133, 0.10415209],\n",
       " [0.29671177444168595, 0.16341555, 0.31882542],\n",
       " [0.30791419021431027, 0.5509045, 0.11592298],\n",
       " [0.22304348881478048, 0.11309264, 0.38567933],\n",
       " [0.6598497854449789, 0.5824388, 0.23920293],\n",
       " [0.4738511528047672, 0.7236958, 0.4077398],\n",
       " [0.7023351991594696, 0.89574987, 0.16357633],\n",
       " [0.5133205100499584, 0.38182274, 0.528263],\n",
       " [0.6206707024835508, 0.76406413, 0.29825917],\n",
       " [0.10023751324991276, 0.017942332, 0.05905003],\n",
       " [0.4155417801171404, 0.5494916, 0.028618885],\n",
       " [0.6265817833824718, 0.87433577, 0.72465503],\n",
       " [0.5250636791278436, 0.42400995, 0.18232505],\n",
       " [0.60978090882425, 0.88151336, 0.6457413],\n",
       " [0.5637630199405894, 0.12080669, 0.16241439],\n",
       " [0.6475579374149435, 0.10844428, 0.7544043],\n",
       " [0.4674256350109172, 0.07005023, 0.53524834],\n",
       " [0.4058535965038705, 0.47153574, 0.3243849],\n",
       " [0.5108875063277616, 0.47337785, 0.03442287],\n",
       " [0.5444488174645974, 0.13833992, 0.10692018],\n",
       " [0.06159771634655402, 0.014204928, 0.12461748],\n",
       " [0.5459418529917871, 0.7514224, 0.35773453],\n",
       " [0.19174524894186332, 0.09022655, 0.031519573],\n",
       " [0.5692195523044538, 0.5391905, 0.054470975],\n",
       " [0.6167942302135591, 0.9692263, 0.8248691],\n",
       " [0.5542565376975789, 0.68310034, 0.22537932],\n",
       " [0.1682313864322493, 0.076184146, 0.123315826],\n",
       " [0.2654719111074495, 0.14585552, 0.10408717],\n",
       " [0.38942116003439087, 0.14440465, 0.2523953],\n",
       " [0.0681964537226038, 0.018145077, 0.01735755],\n",
       " [0.4087007621738704, 0.07480762, 0.37760955],\n",
       " [0.6411449914859989, 0.58767927, 0.80964226],\n",
       " [0.47402355832731446, 0.9481818, 0.5686106],\n",
       " [0.42566791080670446, 0.5731233, 0.18688434],\n",
       " [0.7050980198365059, 0.6218511, 0.09708818],\n",
       " [0.5179585083443077, 0.34478593, 0.67677647],\n",
       " [0.607706986803712, 0.8957747, 0.8715341],\n",
       " [0.5971614910215461, 0.17991754, 0.35337654],\n",
       " [0.3309547170036428, 0.19734564, 0.07884558],\n",
       " [0.8383884277297459, 0.869407, 0.7722833],\n",
       " [0.14998182305422056, 0.16680196, 0.14290532],\n",
       " [0.2282907454238901, 0.10532722, 0.09461711],\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = compute_sample_weight(class_weight='balanced', y=tr_data[1])\n",
    "# _weights = compute_class_weight(class_weight='balanced', classes=np.unique(tr_dataset[5]), y=tr_dataset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgb_train = lgb.Dataset(np.array(tr_data[0]), np.array(tr_data[1]), weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 15:43:06,546] A new study created in memory with name: no-name-e255f974-cdc2-4153-a0cc-89c52fb534fe\n",
      "feature_fraction, val_score: 0.538217:  14%|#4        | 1/7 [00:00<00:01,  5.61it/s][I 2023-12-02 15:43:06,729] Trial 0 finished with value: 0.5382167252462546 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.5382167252462546.\n",
      "feature_fraction, val_score: 0.538217:  14%|#4        | 1/7 [00:00<00:01,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid binary_logloss: 0.538217 + 0.0155875\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.538217:  29%|##8       | 2/7 [00:00<00:00,  6.46it/s][I 2023-12-02 15:43:06,870] Trial 1 finished with value: 0.5382167252462546 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.5382167252462546.\n",
      "feature_fraction, val_score: 0.532583:  43%|####2     | 3/7 [00:00<00:00,  6.35it/s][I 2023-12-02 15:43:07,028] Trial 2 finished with value: 0.5325832327161952 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.5325832327161952.\n",
      "feature_fraction, val_score: 0.532583:  43%|####2     | 3/7 [00:00<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid binary_logloss: 0.538217 + 0.0155875\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tcv_agg's valid binary_logloss: 0.532583 + 0.0115015\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.532583:  57%|#####7    | 4/7 [00:00<00:00,  7.11it/s][I 2023-12-02 15:43:07,145] Trial 3 finished with value: 0.5382167252462546 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.5325832327161952.\n",
      "feature_fraction, val_score: 0.531465:  71%|#######1  | 5/7 [00:00<00:00,  7.39it/s][I 2023-12-02 15:43:07,269] Trial 4 finished with value: 0.5314645600523165 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.5314645600523165.\n",
      "feature_fraction, val_score: 0.531465:  71%|#######1  | 5/7 [00:00<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid binary_logloss: 0.538217 + 0.0155875\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.531465 + 0.0103997\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.531465:  86%|########5 | 6/7 [00:00<00:00,  7.40it/s][I 2023-12-02 15:43:07,405] Trial 5 finished with value: 0.5325832327161952 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.5314645600523165.\n",
      "feature_fraction, val_score: 0.531465: 100%|##########| 7/7 [00:00<00:00,  7.29it/s][I 2023-12-02 15:43:07,547] Trial 6 finished with value: 0.5382167252462546 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.5314645600523165.\n",
      "feature_fraction, val_score: 0.531465: 100%|##########| 7/7 [00:00<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tcv_agg's valid binary_logloss: 0.532583 + 0.0115015\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid binary_logloss: 0.538217 + 0.0155875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.531465:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.531465:   5%|5         | 1/20 [00:00<00:10,  1.85it/s][I 2023-12-02 15:43:08,091] Trial 7 finished with value: 0.5498499435559694 and parameters: {'num_leaves': 184}. Best is trial 7 with value: 0.5498499435559694.\n",
      "num_leaves, val_score: 0.531465:   5%|5         | 1/20 [00:00<00:10,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tcv_agg's valid binary_logloss: 0.54985 + 0.0125127\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.531465:  10%|#         | 2/20 [00:01<00:09,  1.95it/s][I 2023-12-02 15:43:08,585] Trial 8 finished with value: 0.546039662967277 and parameters: {'num_leaves': 138}. Best is trial 8 with value: 0.546039662967277.\n",
      "num_leaves, val_score: 0.531465:  10%|#         | 2/20 [00:01<00:09,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.54604 + 0.0121456\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.531465:  15%|#5        | 3/20 [00:01<00:08,  2.08it/s][I 2023-12-02 15:43:09,032] Trial 9 finished with value: 0.5447975150702463 and parameters: {'num_leaves': 128}. Best is trial 9 with value: 0.5447975150702463.\n",
      "num_leaves, val_score: 0.529593:  20%|##        | 4/20 [00:01<00:05,  2.89it/s][I 2023-12-02 15:43:09,166] Trial 10 finished with value: 0.5295931121769575 and parameters: {'num_leaves': 16}. Best is trial 10 with value: 0.5295931121769575.\n",
      "num_leaves, val_score: 0.529593:  20%|##        | 4/20 [00:01<00:05,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.544798 + 0.0119838\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tcv_agg's valid binary_logloss: 0.529593 + 0.0115021\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  20%|##        | 4/20 [00:01<00:05,  2.89it/s][I 2023-12-02 15:43:09,245] Trial 11 finished with value: 0.526020426441012 and parameters: {'num_leaves': 4}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  30%|###       | 6/20 [00:01<00:02,  4.91it/s][I 2023-12-02 15:43:09,323] Trial 12 finished with value: 0.526020426441012 and parameters: {'num_leaves': 4}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  30%|###       | 6/20 [00:01<00:02,  4.91it/s][I 2023-12-02 15:43:09,411] Trial 13 finished with value: 0.5278136292140807 and parameters: {'num_leaves': 8}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  35%|###5      | 7/20 [00:01<00:02,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tcv_agg's valid binary_logloss: 0.52602 + 0.0116045\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tcv_agg's valid binary_logloss: 0.52602 + 0.0116045\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tcv_agg's valid binary_logloss: 0.527814 + 0.0125591\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  40%|####      | 8/20 [00:02<00:02,  5.49it/s][I 2023-12-02 15:43:09,631] Trial 14 finished with value: 0.5369582393674693 and parameters: {'num_leaves': 65}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  40%|####      | 8/20 [00:02<00:02,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.536958 + 0.0116771\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  45%|####5     | 9/20 [00:02<00:02,  5.05it/s][I 2023-12-02 15:43:09,880] Trial 15 finished with value: 0.5378204591315817 and parameters: {'num_leaves': 68}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  45%|####5     | 9/20 [00:02<00:02,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.53782 + 0.0118974\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  50%|#####     | 10/20 [00:02<00:02,  4.97it/s][I 2023-12-02 15:43:10,090] Trial 16 finished with value: 0.5364806161900315 and parameters: {'num_leaves': 58}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  50%|#####     | 10/20 [00:02<00:02,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.536481 + 0.0115201\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  55%|#####5    | 11/20 [00:03<00:02,  3.28it/s][I 2023-12-02 15:43:10,684] Trial 17 finished with value: 0.5501185732443608 and parameters: {'num_leaves': 230}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  55%|#####5    | 11/20 [00:03<00:02,  3.28it/s][I 2023-12-02 15:43:10,781] Trial 18 finished with value: 0.5278136292140807 and parameters: {'num_leaves': 8}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  60%|######    | 12/20 [00:03<00:02,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tcv_agg's valid binary_logloss: 0.550119 + 0.0124284\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tcv_agg's valid binary_logloss: 0.527814 + 0.0125591\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  65%|######5   | 13/20 [00:03<00:01,  3.81it/s][I 2023-12-02 15:43:11,097] Trial 19 finished with value: 0.5419176987814581 and parameters: {'num_leaves': 106}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  70%|#######   | 14/20 [00:03<00:01,  4.12it/s][I 2023-12-02 15:43:11,275] Trial 20 finished with value: 0.5336684411599969 and parameters: {'num_leaves': 42}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  70%|#######   | 14/20 [00:03<00:01,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.541918 + 0.0121864\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.533668 + 0.0111057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  75%|#######5  | 15/20 [00:03<00:01,  4.79it/s][I 2023-12-02 15:43:11,382] Trial 21 finished with value: 0.5276352073318434 and parameters: {'num_leaves': 7}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  75%|#######5  | 15/20 [00:03<00:01,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tcv_agg's valid binary_logloss: 0.527635 + 0.0125136\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  80%|########  | 16/20 [00:03<00:00,  5.16it/s][I 2023-12-02 15:43:11,534] Trial 22 finished with value: 0.5326518607078118 and parameters: {'num_leaves': 36}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  80%|########  | 16/20 [00:04<00:00,  5.16it/s][I 2023-12-02 15:43:11,619] Trial 23 finished with value: 0.5262830246092298 and parameters: {'num_leaves': 5}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  85%|########5 | 17/20 [00:04<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.532652 + 0.0107526\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tcv_agg's valid binary_logloss: 0.526283 + 0.0124442\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020:  90%|######### | 18/20 [00:04<00:00,  5.09it/s][I 2023-12-02 15:43:11,936] Trial 24 finished with value: 0.5404831074216792 and parameters: {'num_leaves': 92}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  95%|#########5| 19/20 [00:04<00:00,  5.35it/s][I 2023-12-02 15:43:12,091] Trial 25 finished with value: 0.5334411479890655 and parameters: {'num_leaves': 37}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020:  95%|#########5| 19/20 [00:04<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.540483 + 0.0120828\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.533441 + 0.0113907\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.526020: 100%|##########| 20/20 [00:04<00:00,  5.69it/s][I 2023-12-02 15:43:12,234] Trial 26 finished with value: 0.5323162056804029 and parameters: {'num_leaves': 32}. Best is trial 11 with value: 0.526020426441012.\n",
      "num_leaves, val_score: 0.526020: 100%|##########| 20/20 [00:04<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's valid binary_logloss: 0.532316 + 0.0106605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.526020:   0%|          | 0/10 [00:00<?, ?it/s][I 2023-12-02 15:43:12,321] Trial 27 finished with value: 0.526423894664711 and parameters: {'bagging_fraction': 0.5866112836165361, 'bagging_freq': 7}. Best is trial 27 with value: 0.526423894664711.\n",
      "bagging, val_score: 0.526009:  10%|#         | 1/10 [00:00<00:01,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tcv_agg's valid binary_logloss: 0.526424 + 0.0101736\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid binary_logloss: 0.526009 + 0.0122944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.526009:  20%|##        | 2/10 [00:00<00:00, 10.10it/s][I 2023-12-02 15:43:12,438] Trial 28 finished with value: 0.526009462250512 and parameters: {'bagging_fraction': 0.9967248176731558, 'bagging_freq': 1}. Best is trial 28 with value: 0.526009462250512.\n",
      "bagging, val_score: 0.526009:  20%|##        | 2/10 [00:00<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.525999:  20%|##        | 2/10 [00:00<00:00, 10.10it/s][I 2023-12-02 15:43:12,533] Trial 29 finished with value: 0.5259985348505956 and parameters: {'bagging_fraction': 0.9790131374659086, 'bagging_freq': 1}. Best is trial 29 with value: 0.5259985348505956.\n",
      "bagging, val_score: 0.525999:  30%|###       | 3/10 [00:00<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tcv_agg's valid binary_logloss: 0.525999 + 0.0112236\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid binary_logloss: 0.526048 + 0.0118958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.525999:  40%|####      | 4/10 [00:00<00:00,  9.63it/s][I 2023-12-02 15:43:12,655] Trial 30 finished with value: 0.5260480607996285 and parameters: {'bagging_fraction': 0.981620296914139, 'bagging_freq': 1}. Best is trial 29 with value: 0.5259985348505956.\n",
      "bagging, val_score: 0.525999:  40%|####      | 4/10 [00:00<00:00,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.525919:  50%|#####     | 5/10 [00:00<00:00,  9.32it/s][I 2023-12-02 15:43:12,769] Trial 31 finished with value: 0.5259190118356409 and parameters: {'bagging_fraction': 0.9953340015239459, 'bagging_freq': 1}. Best is trial 31 with value: 0.5259190118356409.\n",
      "bagging, val_score: 0.525919:  50%|#####     | 5/10 [00:00<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tcv_agg's valid binary_logloss: 0.525919 + 0.0121267\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid binary_logloss: 0.525994 + 0.0121695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.525919:  60%|######    | 6/10 [00:00<00:00,  9.22it/s][I 2023-12-02 15:43:12,881] Trial 32 finished with value: 0.5259935572461966 and parameters: {'bagging_fraction': 0.9957215135093769, 'bagging_freq': 1}. Best is trial 31 with value: 0.5259190118356409.\n",
      "bagging, val_score: 0.525919:  60%|######    | 6/10 [00:00<00:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tcv_agg's valid binary_logloss: 0.52602 + 0.0116045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 15:43:12,973] Trial 33 finished with value: 0.526020426441012 and parameters: {'bagging_fraction': 0.9999278030891899, 'bagging_freq': 1}. Best is trial 31 with value: 0.5259190118356409.\n",
      "bagging, val_score: 0.525919:  80%|########  | 8/10 [00:00<00:00,  9.65it/s][I 2023-12-02 15:43:13,077] Trial 34 finished with value: 0.5263809355590644 and parameters: {'bagging_fraction': 0.9978878473134559, 'bagging_freq': 1}. Best is trial 31 with value: 0.5259190118356409.\n",
      "bagging, val_score: 0.525919:  80%|########  | 8/10 [00:00<00:00,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tcv_agg's valid binary_logloss: 0.526381 + 0.0120396\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.525919:  80%|########  | 8/10 [00:00<00:00,  9.65it/s][I 2023-12-02 15:43:13,163] Trial 35 finished with value: 0.5260190900842437 and parameters: {'bagging_fraction': 0.9762724172087298, 'bagging_freq': 1}. Best is trial 31 with value: 0.5259190118356409.\n",
      "bagging, val_score: 0.525919:  90%|######### | 9/10 [00:00<00:00,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tcv_agg's valid binary_logloss: 0.526019 + 0.0112474\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.525919: 100%|##########| 10/10 [00:01<00:00, 10.31it/s][I 2023-12-02 15:43:13,251] Trial 36 finished with value: 0.526086413728416 and parameters: {'bagging_fraction': 0.8585583277894967, 'bagging_freq': 3}. Best is trial 31 with value: 0.5259190118356409.\n",
      "bagging, val_score: 0.525919: 100%|##########| 10/10 [00:01<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tcv_agg's valid binary_logloss: 0.526086 + 0.0108289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.525919:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tcv_agg's valid binary_logloss: 0.525919 + 0.0121267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 15:43:13,348] Trial 37 finished with value: 0.5259190118356409 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.5259190118356409.\n",
      "feature_fraction_stage2, val_score: 0.525919:  33%|###3      | 1/3 [00:00<00:00, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.525919:  67%|######6   | 2/3 [00:00<00:00,  9.35it/s][I 2023-12-02 15:43:13,472] Trial 38 finished with value: 0.5259190118356409 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.5259190118356409.\n",
      "feature_fraction_stage2, val_score: 0.525919:  67%|######6   | 2/3 [00:00<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tcv_agg's valid binary_logloss: 0.525919 + 0.0121267\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.525919:  67%|######6   | 2/3 [00:00<00:00,  9.35it/s][I 2023-12-02 15:43:13,570] Trial 39 finished with value: 0.5259190118356409 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.5259190118356409.\n",
      "feature_fraction_stage2, val_score: 0.525919: 100%|##########| 3/3 [00:00<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tcv_agg's valid binary_logloss: 0.525919 + 0.0121267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525919:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid binary_logloss: 0.526103 + 0.0122727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525919:   5%|5         | 1/20 [00:00<00:01,  9.57it/s][I 2023-12-02 15:43:13,679] Trial 40 finished with value: 0.5261027352493863 and parameters: {'lambda_l1': 1.5970485491539797e-05, 'lambda_l2': 0.24921841518146787}. Best is trial 40 with value: 0.5261027352493863.\n",
      "regularization_factors, val_score: 0.525919:   5%|5         | 1/20 [00:00<00:01,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525644:   5%|5         | 1/20 [00:00<00:01,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tcv_agg's valid binary_logloss: 0.525644 + 0.0114187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525644:  10%|#         | 2/20 [00:00<00:01,  9.26it/s][I 2023-12-02 15:43:13,789] Trial 41 finished with value: 0.5256436826657558 and parameters: {'lambda_l1': 7.059553171719499, 'lambda_l2': 2.696124673469531e-08}. Best is trial 41 with value: 0.5256436826657558.\n",
      "regularization_factors, val_score: 0.525644:  10%|#         | 2/20 [00:00<00:01,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525585:  15%|#5        | 3/20 [00:00<00:01,  8.76it/s][I 2023-12-02 15:43:13,910] Trial 42 finished with value: 0.5255846715849747 and parameters: {'lambda_l1': 8.707071753189707, 'lambda_l2': 1.2098179853066213e-08}. Best is trial 42 with value: 0.5255846715849747.\n",
      "regularization_factors, val_score: 0.525585:  15%|#5        | 3/20 [00:00<00:01,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tcv_agg's valid binary_logloss: 0.525585 + 0.0111851\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525551:  20%|##        | 4/20 [00:00<00:01,  8.54it/s][I 2023-12-02 15:43:14,032] Trial 43 finished with value: 0.5255512018073331 and parameters: {'lambda_l1': 8.007282233491438, 'lambda_l2': 1.1638496042452774e-08}. Best is trial 43 with value: 0.5255512018073331.\n",
      "regularization_factors, val_score: 0.525551:  20%|##        | 4/20 [00:00<00:01,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tcv_agg's valid binary_logloss: 0.525551 + 0.0115832\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525551:  25%|##5       | 5/20 [00:00<00:01,  8.65it/s][I 2023-12-02 15:43:14,147] Trial 44 finished with value: 0.5256924055436764 and parameters: {'lambda_l1': 5.883205298481121, 'lambda_l2': 1.2895138145765834e-08}. Best is trial 43 with value: 0.5255512018073331.\n",
      "regularization_factors, val_score: 0.525551:  25%|##5       | 5/20 [00:00<00:01,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tcv_agg's valid binary_logloss: 0.525692 + 0.0117498\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525551:  30%|###       | 6/20 [00:00<00:01,  8.16it/s][I 2023-12-02 15:43:14,282] Trial 45 finished with value: 0.5256590583655014 and parameters: {'lambda_l1': 8.645090295135251, 'lambda_l2': 1.5428982308520203e-08}. Best is trial 43 with value: 0.5255512018073331.\n",
      "regularization_factors, val_score: 0.525551:  30%|###       | 6/20 [00:00<00:01,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tcv_agg's valid binary_logloss: 0.525659 + 0.0114946\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525534:  35%|###5      | 7/20 [00:00<00:01,  8.01it/s][I 2023-12-02 15:43:14,409] Trial 46 finished with value: 0.5255339723361677 and parameters: {'lambda_l1': 9.408894367955648, 'lambda_l2': 1.2000729510103062e-08}. Best is trial 46 with value: 0.5255339723361677.\n",
      "regularization_factors, val_score: 0.525534:  35%|###5      | 7/20 [00:00<00:01,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tcv_agg's valid binary_logloss: 0.525534 + 0.0115261\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525534:  40%|####      | 8/20 [00:00<00:01,  8.21it/s][I 2023-12-02 15:43:14,527] Trial 47 finished with value: 0.5256462565169258 and parameters: {'lambda_l1': 8.488263103941666, 'lambda_l2': 2.2093801063602435e-08}. Best is trial 46 with value: 0.5255339723361677.\n",
      "regularization_factors, val_score: 0.525534:  40%|####      | 8/20 [00:00<00:01,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tcv_agg's valid binary_logloss: 0.525646 + 0.0112283\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525534:  45%|####5     | 9/20 [00:01<00:01,  8.05it/s][I 2023-12-02 15:43:14,656] Trial 48 finished with value: 0.5257244668753034 and parameters: {'lambda_l1': 5.828515448913657, 'lambda_l2': 1.2408515098427741e-08}. Best is trial 46 with value: 0.5255339723361677.\n",
      "regularization_factors, val_score: 0.525534:  45%|####5     | 9/20 [00:01<00:01,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tcv_agg's valid binary_logloss: 0.525724 + 0.0117793\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525534:  50%|#####     | 10/20 [00:01<00:01,  7.99it/s][I 2023-12-02 15:43:14,784] Trial 49 finished with value: 0.5255988091107232 and parameters: {'lambda_l1': 8.003852935092286, 'lambda_l2': 1.3375694754185519e-08}. Best is trial 46 with value: 0.5255339723361677.\n",
      "regularization_factors, val_score: 0.525534:  50%|#####     | 10/20 [00:01<00:01,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tcv_agg's valid binary_logloss: 0.525599 + 0.0115085\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  55%|#####5    | 11/20 [00:01<00:01,  7.80it/s][I 2023-12-02 15:43:14,918] Trial 50 finished with value: 0.525489915997646 and parameters: {'lambda_l1': 9.437038741213511, 'lambda_l2': 1.1639547844209527e-08}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  55%|#####5    | 11/20 [00:01<00:01,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tcv_agg's valid binary_logloss: 0.52549 + 0.0115399\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  60%|######    | 12/20 [00:01<00:01,  7.98it/s][I 2023-12-02 15:43:15,038] Trial 51 finished with value: 0.5255536140969083 and parameters: {'lambda_l1': 9.211725039550448, 'lambda_l2': 1.0635824126103127e-08}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  60%|######    | 12/20 [00:01<00:01,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tcv_agg's valid binary_logloss: 0.525554 + 0.0115516\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  65%|######5   | 13/20 [00:01<00:00,  7.82it/s][I 2023-12-02 15:43:15,171] Trial 52 finished with value: 0.5255613438677209 and parameters: {'lambda_l1': 9.135707425114017, 'lambda_l2': 1.0881552362301392e-08}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  65%|######5   | 13/20 [00:01<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tcv_agg's valid binary_logloss: 0.525561 + 0.0113741\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  70%|#######   | 14/20 [00:01<00:00,  8.11it/s][I 2023-12-02 15:43:15,285] Trial 53 finished with value: 0.525756348898492 and parameters: {'lambda_l1': 0.1209174348625611, 'lambda_l2': 1.383913298615018e-08}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  70%|#######   | 14/20 [00:01<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tcv_agg's valid binary_logloss: 0.525756 + 0.0121685\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  75%|#######5  | 15/20 [00:01<00:00,  8.53it/s][I 2023-12-02 15:43:15,388] Trial 54 finished with value: 0.525824779717369 and parameters: {'lambda_l1': 0.09788414729464087, 'lambda_l2': 5.47621209646846e-07}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  75%|#######5  | 15/20 [00:01<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid binary_logloss: 0.525825 + 0.0122242\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  80%|########  | 16/20 [00:01<00:00,  8.59it/s][I 2023-12-02 15:43:15,501] Trial 55 finished with value: 0.5259190116841721 and parameters: {'lambda_l1': 1.0025731717055962e-08, 'lambda_l2': 9.037282109519519e-07}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  80%|########  | 16/20 [00:01<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tcv_agg's valid binary_logloss: 0.525919 + 0.0121267\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  85%|########5 | 17/20 [00:02<00:00,  8.70it/s][I 2023-12-02 15:43:15,613] Trial 56 finished with value: 0.5258765903674852 and parameters: {'lambda_l1': 0.471787471525684, 'lambda_l2': 4.87977261076014e-07}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  85%|########5 | 17/20 [00:02<00:00,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid binary_logloss: 0.525877 + 0.0122757\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  90%|######### | 18/20 [00:02<00:00,  8.75it/s][I 2023-12-02 15:43:15,726] Trial 57 finished with value: 0.5260097410947434 and parameters: {'lambda_l1': 0.5750627550046301, 'lambda_l2': 2.3547882055235722e-07}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  90%|######### | 18/20 [00:02<00:00,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tcv_agg's valid binary_logloss: 0.52601 + 0.0120737\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490:  95%|#########5| 19/20 [00:02<00:00,  9.03it/s][I 2023-12-02 15:43:15,828] Trial 58 finished with value: 0.5259280697372888 and parameters: {'lambda_l1': 0.7387687266288117, 'lambda_l2': 1.8604595524072162e-07}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490:  95%|#########5| 19/20 [00:02<00:00,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's valid binary_logloss: 0.525928 + 0.0122945\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.525490: 100%|##########| 20/20 [00:02<00:00,  8.61it/s][I 2023-12-02 15:43:15,958] Trial 59 finished with value: 0.5255343741173604 and parameters: {'lambda_l1': 9.853277723714665, 'lambda_l2': 1.2716941013322163e-07}. Best is trial 50 with value: 0.525489915997646.\n",
      "regularization_factors, val_score: 0.525490: 100%|##########| 20/20 [00:02<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tcv_agg's valid binary_logloss: 0.525534 + 0.0110744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.525490:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.525490:  20%|##        | 1/5 [00:00<00:00,  8.01it/s][I 2023-12-02 15:43:16,089] Trial 60 finished with value: 0.525489915997646 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.525489915997646.\n",
      "min_child_samples, val_score: 0.525490:  20%|##        | 1/5 [00:00<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tcv_agg's valid binary_logloss: 0.52549 + 0.0115399\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.525490:  40%|####      | 2/5 [00:00<00:00,  8.42it/s][I 2023-12-02 15:43:16,204] Trial 61 finished with value: 0.525489915997646 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.525489915997646.\n",
      "min_child_samples, val_score: 0.525490:  40%|####      | 2/5 [00:00<00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tcv_agg's valid binary_logloss: 0.52549 + 0.0115399\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.525490:  60%|######    | 3/5 [00:00<00:00,  8.21it/s][I 2023-12-02 15:43:16,330] Trial 62 finished with value: 0.525489915997646 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.525489915997646.\n",
      "min_child_samples, val_score: 0.525490:  60%|######    | 3/5 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tcv_agg's valid binary_logloss: 0.52549 + 0.0115399\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.525490:  80%|########  | 4/5 [00:00<00:00,  8.14it/s][I 2023-12-02 15:43:16,454] Trial 63 finished with value: 0.525489915997646 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.525489915997646.\n",
      "min_child_samples, val_score: 0.525490:  80%|########  | 4/5 [00:00<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tcv_agg's valid binary_logloss: 0.52549 + 0.0115399\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.525472: 100%|##########| 5/5 [00:00<00:00,  8.09it/s][I 2023-12-02 15:43:16,577] Trial 64 finished with value: 0.5254720652267872 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.5254720652267872.\n",
      "min_child_samples, val_score: 0.525472: 100%|##########| 5/5 [00:00<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tcv_agg's valid binary_logloss: 0.525472 + 0.0114942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity':-1,\n",
    "}\n",
    "tuner_cv = lgb.LightGBMTunerCV(\n",
    "    lgb_params, lgb_train,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True),\n",
    "                lgb.log_evaluation(100)],\n",
    "    return_cvbooster=True,\n",
    "    folds=folds\n",
    ")\n",
    "\n",
    "tuner_cv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5254720652267872\n",
      "Best params:\n",
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 9.437038741213511, 'lambda_l2': 1.1639547844209527e-08, 'num_leaves': 4, 'feature_fraction': 0.4, 'bagging_fraction': 0.9953340015239459, 'bagging_freq': 1, 'min_child_samples': 100}\n",
      "[0.56411557 0.8885075  0.21089981 ... 0.45397972 0.09104037 0.17435259]\n",
      "0.8158902121697358\n",
      "0.6287841213707461\n"
     ]
    }
   ],
   "source": [
    "#openstack logloss 不均衡対策\n",
    "print(f'Best score: {tuner_cv.best_score}')\n",
    "print('Best params:')\n",
    "print(tuner_cv.best_params)\n",
    "model = tuner_cv.get_best_booster()\n",
    "pred = model.predict(np.array(te_data[0]), num_iteration=model.best_iteration)\n",
    "mean_pred = np.mean(pred, axis=0)\n",
    "print(mean_pred)\n",
    "print(roc_auc_score(te_data[1], mean_pred))\n",
    "print(log_loss(te_data[1], mean_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5280279874638432\n",
      "Best params:\n",
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 0.0011915139883967448, 'lambda_l2': 3.4588147191727472e-06, 'num_leaves': 5, 'feature_fraction': 1.0, 'bagging_fraction': 0.7929649221365002, 'bagging_freq': 3, 'min_child_samples': 25}\n",
      "[0.33271095 0.53479266 0.10296248 ... 0.71196917 0.59963328 0.11965684]\n",
      "0.7786629395679638\n",
      "0.5453967647586538\n"
     ]
    }
   ],
   "source": [
    "#qt logloss 不均衡対策\n",
    "print(f'Best score: {tuner_cv.best_score}')\n",
    "print('Best params:')\n",
    "print(tuner_cv.best_params)\n",
    "model = tuner_cv.get_best_booster()\n",
    "pred = model.predict(np.array(te_data[0]), num_iteration=model.best_iteration)\n",
    "mean_pred = np.mean(pred, axis=0)\n",
    "print(mean_pred)\n",
    "print(roc_auc_score(te_data[1], mean_pred))\n",
    "print(log_loss(te_data[1], mean_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
