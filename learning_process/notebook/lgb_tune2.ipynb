{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "project = 'qt'\n",
    "with open('../resource/'+project+'_train.pkl', 'rb') as f_train, open('../resource/'+project+'_test.pkl', 'rb') as f_test:\n",
    "        tr_data = pickle.load(f_train)\n",
    "        te_data = pickle.load(f_test)\n",
    "pred_list = []\n",
    "kinds = ['train', 'test']\n",
    "models = ['lgb', 'code_cnn', 'msg_tf']\n",
    "for kind in kinds:\n",
    "    for model in models:\n",
    "        with open('../pred/'+project+'-'+model+'-'+'random'+'-'+kind+'.pkl', 'rb') as f:\n",
    "            pred_list.append(pickle.load(f))\n",
    "tr_pred = [[pred_list[0][j], pred_list[1][j], pred_list[2][j]] for j in range(len(pred_list[0]))]\n",
    "te_pred = [[pred_list[3][j], pred_list[4][j], pred_list[5][j]] for j in range(len(pred_list[3]))]                \n",
    "tr_data = [tr_pred, tr_data[5]]\n",
    "te_data = [te_pred, te_data[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0769336798319384, 0.06830322, 0.02726451],\n",
       " [0.35020530990483595, 0.84387445, 0.32100973],\n",
       " [0.039051982199775646, 0.10445042, 0.09972893],\n",
       " [0.08588918127386591, 0.35723928, 0.20921192],\n",
       " [0.18240670243503868, 0.4725629, 0.031362668],\n",
       " [0.048284144678094935, 0.07725294, 0.0028972698],\n",
       " [0.011965262425156062, 0.15983382, 0.1898607],\n",
       " [0.29766020138986954, 0.87091726, 0.5815161],\n",
       " [0.11617812835860392, 0.16620982, 0.3495638],\n",
       " [0.3963747591577801, 0.50993395, 0.34185353],\n",
       " [0.02919027206367599, 0.18241285, 0.13078481],\n",
       " [0.02394680522525277, 0.3813507, 0.11021323],\n",
       " [0.033108966024455094, 0.15947708, 0.13534446],\n",
       " [0.39715977717917744, 0.42265528, 0.08573324],\n",
       " [0.01803389074557814, 0.24566294, 0.00466662],\n",
       " [0.417187663762276, 0.70136863, 0.023882268],\n",
       " [0.08351644475190935, 0.6403872, 0.04141613],\n",
       " [0.045914430831285, 0.109618366, 0.5236753],\n",
       " [0.05821287449090139, 0.03001939, 0.4433952],\n",
       " [0.07651216157341487, 0.19342765, 0.34873074],\n",
       " [0.07453128110406308, 0.7826837, 0.64233553],\n",
       " [0.0640991095647722, 0.0697536, 0.021540204],\n",
       " [0.08107265324439462, 0.1861437, 0.25570008],\n",
       " [0.3635815454200507, 0.76621026, 0.24168782],\n",
       " [0.02670973849730225, 0.056843538, 0.09653012],\n",
       " [0.03907688945955445, 0.43398297, 0.026507063],\n",
       " [0.21280774101002126, 0.85840446, 0.18151227],\n",
       " [0.30290355864574375, 0.21622707, 0.62182343],\n",
       " [0.020177942316901943, 0.19750778, 0.036613856],\n",
       " [0.014388020610186635, 0.11730084, 0.121050276],\n",
       " [0.17484256486253075, 0.14210717, 0.08857362],\n",
       " [0.10612063938085764, 0.5898763, 0.110901095],\n",
       " [0.3066904109787146, 0.639246, 0.20465273],\n",
       " [0.11284427738217521, 0.5691385, 0.81176084],\n",
       " [0.4166948838099623, 0.8030292, 0.6709184],\n",
       " [0.07627793760661168, 0.08081077, 0.3780427],\n",
       " [0.07448322920716086, 0.14923152, 0.17633128],\n",
       " [0.014706009062230406, 0.20767893, 0.071094744],\n",
       " [0.4483755479174995, 0.334684, 0.5364597],\n",
       " [0.15318938792252093, 0.25885138, 0.13398549],\n",
       " [0.0649802042767347, 0.25448468, 0.5943052],\n",
       " [0.5662153233480627, 0.70751935, 0.02290597],\n",
       " [0.0557318158851817, 0.06941677, 0.042820342],\n",
       " [0.23334384369900757, 0.69819015, 0.06311649],\n",
       " [0.0952917025926134, 0.6017701, 0.10481202],\n",
       " [0.11894390368156947, 0.81998485, 0.0045059626],\n",
       " [0.1295983640126862, 0.15278456, 0.7482417],\n",
       " [0.08149362736332344, 0.35002398, 0.58981955],\n",
       " [0.0882763631739914, 0.20886579, 0.3187489],\n",
       " [0.08111309018354335, 0.58215487, 0.04114343],\n",
       " [0.10915925374260911, 0.41426063, 0.32873535],\n",
       " [0.04472150511330643, 0.2356164, 0.045065083],\n",
       " [0.1921035232057708, 0.052217524, 0.24012616],\n",
       " [0.09367593416642181, 0.28429288, 0.040899027],\n",
       " [0.7174747537619597, 0.7113954, 0.0571951],\n",
       " [0.1310803423352097, 0.45285362, 0.38721305],\n",
       " [0.5774926717448835, 0.943421, 0.9379595],\n",
       " [0.08813175217723009, 0.22377118, 0.112999156],\n",
       " [0.46238621497434607, 0.4462923, 0.662413],\n",
       " [0.01343162063866231, 0.42469436, 0.4518734],\n",
       " [0.03643831223285603, 0.9082513, 0.02368309],\n",
       " [0.0828183639892353, 0.76021653, 0.39906263],\n",
       " [0.0486516078908776, 0.06315114, 0.09823174],\n",
       " [0.07295454515495549, 0.25417343, 0.32716608],\n",
       " [0.646744563786808, 0.76076615, 0.122959144],\n",
       " [0.01124002809723107, 0.3317712, 0.03980275],\n",
       " [0.15419961029002574, 0.20683463, 0.024553664],\n",
       " [0.43467715788652306, 0.27421877, 0.25891244],\n",
       " [0.10721306533279927, 0.23594905, 0.49642697],\n",
       " [0.09147106620072284, 0.83847123, 0.06063021],\n",
       " [0.2079199217285931, 0.13794403, 0.04544204],\n",
       " [0.1678348542791322, 0.44101685, 0.10514995],\n",
       " [0.40139287851454086, 0.39219385, 0.8091982],\n",
       " [0.07728892600843802, 0.19789901, 0.22898488],\n",
       " [0.7339970973459072, 0.52660763, 0.015917307],\n",
       " [0.07437409274780012, 0.2377119, 0.014162137],\n",
       " [0.31055212076775157, 0.45453626, 0.23991357],\n",
       " [0.10334985580855265, 0.0838545, 0.1918672],\n",
       " [0.056557040624409735, 0.049570326, 0.4676343],\n",
       " [0.016354031927259993, 0.24282947, 0.3814491],\n",
       " [0.1402398988896522, 0.23640403, 0.623395],\n",
       " [0.13567356877159945, 0.12513442, 0.038524956],\n",
       " [0.197231151833438, 0.61843854, 0.64612347],\n",
       " [0.008888344772185726, 0.21023758, 0.24251384],\n",
       " [0.3610165784151984, 0.7750593, 0.21553448],\n",
       " [0.3199341242522744, 0.5259602, 0.19915608],\n",
       " [0.0911218793596726, 0.5957052, 0.19282784],\n",
       " [0.0299282160156133, 0.45366767, 0.04998832],\n",
       " [0.24781216041310866, 0.74036866, 0.11114935],\n",
       " [0.04122981153028217, 0.66464716, 0.23704684],\n",
       " [0.09622568647025445, 0.29299545, 0.055891216],\n",
       " [0.3193906514843476, 0.1857625, 0.023803607],\n",
       " [0.4181252743852062, 0.32488012, 0.20055851],\n",
       " [0.0054223119266082025, 0.15258093, 0.004318541],\n",
       " [0.9588192984971678, 0.7628805, 0.17755905],\n",
       " [0.1500804120650143, 0.3052576, 0.15365867],\n",
       " [0.023393607116747095, 0.058245078, 0.041487258],\n",
       " [0.12473601387773314, 0.083967976, 0.7398937],\n",
       " [0.022431129302076525, 0.05453234, 0.015343109],\n",
       " [0.158266453854705, 0.44904855, 0.019529952],\n",
       " [0.0160469961699048, 0.68328935, 0.033489447],\n",
       " [0.39907087079779, 0.5327476, 0.62571543],\n",
       " [0.06190242897338806, 0.048001252, 0.09590405],\n",
       " [0.18715267371126548, 0.49166122, 0.13771288],\n",
       " [0.15653960514744478, 0.91988975, 0.28562334],\n",
       " [0.051106263074210505, 0.3834274, 0.47241968],\n",
       " [0.5783602499573529, 0.7716159, 0.030078864],\n",
       " [0.0714499841418905, 0.55189705, 0.2492403],\n",
       " [0.2290698662446488, 0.55306476, 0.012637272],\n",
       " [0.02356180457170712, 0.21815544, 0.0056473734],\n",
       " [0.09775719829957212, 0.25925156, 0.31030613],\n",
       " [0.10396515592061727, 0.72538304, 0.8179859],\n",
       " [0.38418210455101603, 0.8948263, 0.04571121],\n",
       " [0.29353194537582733, 0.77833736, 0.1761921],\n",
       " [0.06874767353037668, 0.7570772, 0.06376485],\n",
       " [0.05425554254889943, 0.11795935, 0.086776614],\n",
       " [0.07238753792458338, 0.28396922, 0.08184632],\n",
       " [0.05354729694228355, 0.24568911, 0.007026672],\n",
       " [0.01005221265663814, 0.70338434, 0.59940803],\n",
       " [0.21422100610461983, 0.24738073, 0.056888044],\n",
       " [0.34906200729810793, 0.35720637, 0.31624636],\n",
       " [0.05369602438738456, 0.19045717, 0.039785586],\n",
       " [0.05756814375727777, 0.07935641, 0.009862351],\n",
       " [0.6661070638555555, 0.7707501, 0.01389994],\n",
       " [0.14230751906960362, 0.8393017, 0.09557262],\n",
       " [0.20231221973856664, 0.17666134, 0.486163],\n",
       " [0.017555269109722705, 0.79516304, 0.08912285],\n",
       " [0.1051907376319566, 0.6182876, 0.016893249],\n",
       " [0.04846032615027835, 0.7553121, 0.002720208],\n",
       " [0.13608186589810875, 0.6885305, 0.19277184],\n",
       " [0.4465123711930822, 0.41865525, 0.046492282],\n",
       " [0.006458669951831839, 0.09557164, 0.011917239],\n",
       " [0.04368250289248599, 0.04145225, 0.612966],\n",
       " [0.050809815003448326, 0.109824926, 0.0972842],\n",
       " [0.10063588669338999, 0.2557765, 0.51162416],\n",
       " [0.01641873321956761, 0.24198323, 0.13534813],\n",
       " [0.300672233267322, 0.7748143, 0.35769272],\n",
       " [0.0742638172992084, 0.722533, 0.11041105],\n",
       " [0.17617149297402562, 0.035638824, 0.070059545],\n",
       " [0.031262412243258916, 0.10335228, 0.10446974],\n",
       " [0.046950022493076865, 0.03633732, 0.01941107],\n",
       " [0.10146716689185657, 0.5858808, 0.0135358665],\n",
       " [0.07181711057416708, 0.33037356, 0.09253022],\n",
       " [0.2802663618212458, 0.12499282, 0.7639392],\n",
       " [0.021786260614083442, 0.10982239, 0.018887447],\n",
       " [0.3669808799025316, 0.37001684, 0.44771352],\n",
       " [0.07900546332654627, 0.14124598, 0.030907515],\n",
       " [0.4267739213025949, 0.9340213, 0.58381724],\n",
       " [0.14719069946256166, 0.6569264, 0.20527254],\n",
       " [0.054550740400492966, 0.2921428, 0.04020146],\n",
       " [0.1690300565712092, 0.784153, 0.22244148],\n",
       " [0.31262677627900914, 0.7362397, 0.39539763],\n",
       " [0.047237807966606836, 0.22546367, 0.057232596],\n",
       " [0.022563974180852698, 0.2266281, 0.0643181],\n",
       " [0.07918240207168957, 0.8875717, 0.014266591],\n",
       " [0.053462658732526695, 0.10538331, 0.11684991],\n",
       " [0.2600479172623437, 0.0937027, 0.08075937],\n",
       " [0.16881377195350872, 0.13152346, 0.015121685],\n",
       " [0.2691400796166397, 0.9135441, 0.11014749],\n",
       " [0.2014691608191234, 0.18613617, 0.7551183],\n",
       " [0.07893683697414268, 0.38834465, 0.03933961],\n",
       " [0.6557843533152887, 0.45671225, 0.8538448],\n",
       " [0.019686791085154257, 0.06244562, 0.04770603],\n",
       " [0.10302723988667048, 0.5277092, 0.027305352],\n",
       " [0.03146914336668267, 0.069146626, 0.0053154714],\n",
       " [0.023070580926479695, 0.5322633, 0.023191316],\n",
       " [0.5094695794196623, 0.13166498, 0.39846313],\n",
       " [0.17010773173836508, 0.13756101, 0.054937776],\n",
       " [0.014630660456847255, 0.16896562, 0.015033037],\n",
       " [0.045702501605296514, 0.1215668, 0.012562359],\n",
       " [0.06443155651638273, 0.5929125, 0.4590644],\n",
       " [0.13914881410057425, 0.81872684, 0.25835904],\n",
       " [0.02145471720124039, 0.80820787, 0.090297975],\n",
       " [0.11153238629898199, 0.1923622, 0.10912992],\n",
       " [0.21166952241630826, 0.88432324, 0.74468184],\n",
       " [0.054270594341402405, 0.12871104, 0.080290385],\n",
       " [0.3243865778004036, 0.34805062, 0.05439922],\n",
       " [0.11038992598942786, 0.812314, 0.022517512],\n",
       " [0.09815316987104869, 0.61798483, 0.3353558],\n",
       " [0.04961337040641508, 0.302903, 0.10547843],\n",
       " [0.2497341660440637, 0.80823874, 0.5526876],\n",
       " [0.07869896595583, 0.03181703, 0.023905925],\n",
       " [0.1728852381751363, 0.9285402, 0.43151456],\n",
       " [0.6027482065688792, 0.8509643, 0.34231344],\n",
       " [0.1892641624757348, 0.22870795, 0.12430337],\n",
       " [0.33065425024758716, 0.6076743, 0.009218417],\n",
       " [0.053843400533245454, 0.19564968, 0.5675719],\n",
       " [0.35634496181447817, 0.5695658, 0.6201832],\n",
       " [0.5400038577921186, 0.3249797, 0.12173186],\n",
       " [0.02137785338303727, 0.11980408, 0.0062333317],\n",
       " [0.05004220920210624, 0.07071428, 0.19677766],\n",
       " [0.02222885909841103, 0.14200252, 0.01049071],\n",
       " [0.10583623254898267, 0.5562728, 0.11585047],\n",
       " [0.1677969380354738, 0.32411167, 0.11108791],\n",
       " [0.11832546976048493, 0.72862184, 0.19883637],\n",
       " [0.09278773624408802, 0.07516364, 0.03009319],\n",
       " [0.11026003179948304, 0.10109562, 0.053710613],\n",
       " [0.17943830150872453, 0.06804473, 0.69023955],\n",
       " [0.18326839734225628, 0.29337847, 0.25767016],\n",
       " [0.04722095102109003, 0.28455868, 0.0034397133],\n",
       " [0.5552258153232514, 0.61419064, 0.20727071],\n",
       " [0.06748438157668875, 0.05388884, 0.0047129244],\n",
       " [0.5280899833900226, 0.8999906, 0.62701625],\n",
       " [0.05192291430593091, 0.3756781, 0.27791852],\n",
       " [0.04626223208129497, 0.13862877, 0.050364595],\n",
       " [0.6455002079430143, 0.85795987, 0.67552644],\n",
       " [0.07844639411741598, 0.5017282, 0.0072068432],\n",
       " [0.13363263424923358, 0.1819799, 0.13084038],\n",
       " [0.035899129415816355, 0.23578216, 0.032259375],\n",
       " [0.11269331592077808, 0.1350272, 0.02337748],\n",
       " [0.13142874487724998, 0.67873627, 0.520288],\n",
       " [0.04307143066868432, 0.22235522, 0.3084936],\n",
       " [0.0883210212360479, 0.1890296, 0.11647742],\n",
       " [0.42850656205651727, 0.42185032, 0.03616851],\n",
       " [0.008100499208473973, 0.18234387, 0.013129833],\n",
       " [0.06356041119898524, 0.19055063, 0.0047279205],\n",
       " [0.4473509770988749, 0.67979383, 0.15248737],\n",
       " [0.7175715736674587, 0.6376488, 0.34582096],\n",
       " [0.048917171198214246, 0.10400456, 0.5290857],\n",
       " [0.01631207553486204, 0.23208158, 0.051030513],\n",
       " [0.05361473099623773, 0.12689897, 0.040809125],\n",
       " [0.05345391261035885, 0.26714292, 0.3612495],\n",
       " [0.2606103913422907, 0.21771061, 0.21679826],\n",
       " [0.01794318661143241, 0.6043143, 0.07796616],\n",
       " [0.10936813837063086, 0.3254988, 0.017647143],\n",
       " [0.5439013680010266, 0.8528111, 0.13299595],\n",
       " [0.22576034511028026, 0.120960005, 0.016739074],\n",
       " [0.0124606491655077, 0.06273337, 0.012288366],\n",
       " [0.7081131379291421, 0.8505199, 0.2600158],\n",
       " [0.293304824549304, 0.19460645, 0.15431413],\n",
       " [0.13662871255735223, 0.44776392, 0.07251094],\n",
       " [0.2789048453112735, 0.6130089, 0.12826292],\n",
       " [0.048151820686620286, 0.7147893, 0.06947047],\n",
       " [0.05212404324927733, 0.30669948, 0.029504],\n",
       " [0.07242088741217671, 0.1517449, 0.21751943],\n",
       " [0.025696813995259176, 0.052062497, 0.12121054],\n",
       " [0.8820489661464921, 0.8664973, 0.50248647],\n",
       " [0.053500880207555265, 0.7612726, 0.43446755],\n",
       " [0.018212229557512706, 0.57851934, 0.29489487],\n",
       " [0.019388854490277885, 0.14462666, 0.18112287],\n",
       " [0.11085241856221696, 0.7487737, 0.23643056],\n",
       " [0.18329475905402173, 0.3183338, 0.16851173],\n",
       " [0.07574857557615372, 0.44583392, 0.43743488],\n",
       " [0.750054912739703, 0.3036748, 0.32579827],\n",
       " [0.020971556855714855, 0.8786665, 0.1425086],\n",
       " [0.1536061520152697, 0.43736333, 0.20596354],\n",
       " [0.010551675460878358, 0.22497107, 0.061109304],\n",
       " [0.021389768072659278, 0.42270902, 0.18127874],\n",
       " [0.040162895820849774, 0.4424539, 0.047740016],\n",
       " [0.05776416095894154, 0.561651, 0.06836079],\n",
       " [0.17516715812203126, 0.22298753, 0.3779517],\n",
       " [0.05197919972272861, 0.61065304, 0.45620233],\n",
       " [0.11748746593944312, 0.22174989, 0.50506383],\n",
       " [0.14643295293041708, 0.57482725, 0.3977954],\n",
       " [0.2699468731425668, 0.25263804, 0.28436154],\n",
       " [0.03547131741604241, 0.025867887, 0.02061859],\n",
       " [0.03735654488632433, 0.033337276, 0.06779963],\n",
       " [0.11584869479428053, 0.27333966, 0.09201285],\n",
       " [0.14017967464836228, 0.27252218, 0.072042],\n",
       " [0.03175172010084534, 0.53856796, 0.041388225],\n",
       " [0.3317736450250632, 0.28874254, 0.17314948],\n",
       " [0.061776670620402374, 0.07761903, 0.15240549],\n",
       " [0.6517377359304799, 0.49813187, 0.8852416],\n",
       " [0.0445552421820072, 0.25883687, 0.17539364],\n",
       " [0.19044157483512408, 0.70789593, 0.05020505],\n",
       " [0.1669548222142679, 0.6599915, 0.14436033],\n",
       " [0.23750481754544342, 0.4730736, 0.40392417],\n",
       " [0.1803448358258351, 0.5462544, 0.07631484],\n",
       " [0.08023000745293016, 0.13488391, 0.003800181],\n",
       " [0.024951256803010812, 0.41368106, 0.03923813],\n",
       " [0.1348416294018016, 0.08017832, 0.43043867],\n",
       " [0.2297486052870034, 0.78643435, 0.19883177],\n",
       " [0.050109557514341097, 0.44131187, 0.11451596],\n",
       " [0.436001640391451, 0.5991889, 0.13776663],\n",
       " [0.2948504522717647, 0.957174, 0.6026161],\n",
       " [0.11873338850004994, 0.65264934, 0.22148882],\n",
       " [0.32698901885443543, 0.46758252, 0.24253252],\n",
       " [0.23509332513661746, 0.4552362, 0.298412],\n",
       " [0.032262075966876545, 0.24024463, 0.04422261],\n",
       " [0.6992530645906532, 0.86161536, 0.3024778],\n",
       " [0.09837246276910327, 0.85687745, 0.2879221],\n",
       " [0.5118499680266662, 0.8795979, 0.44510832],\n",
       " [0.08961044322439612, 0.45875236, 0.24049655],\n",
       " [0.127579123057398, 0.25212902, 0.07962756],\n",
       " [0.048753962307974574, 0.9012446, 0.45430458],\n",
       " [0.03127815316415163, 0.077443205, 0.12848648],\n",
       " [0.12556014846205343, 0.3541121, 0.1349535],\n",
       " [0.04137479610955096, 0.12956597, 0.02216079],\n",
       " [0.2645415366593755, 0.66987157, 0.26272428],\n",
       " [0.6424412944818574, 0.8799067, 0.22216247],\n",
       " [0.030544063847460973, 0.10962417, 0.05884555],\n",
       " [0.19801155114437183, 0.63638586, 0.16057608],\n",
       " [0.7183072919509395, 0.78782916, 0.29746938],\n",
       " [0.0515212632901858, 0.1417545, 0.38284767],\n",
       " [0.22461986410349188, 0.1441216, 0.14863817],\n",
       " [0.05508774044313995, 0.03213598, 0.024367737],\n",
       " [0.1996589361361803, 0.12118481, 0.33299166],\n",
       " [0.16965603796937895, 0.09680498, 0.065793596],\n",
       " [0.02936836707282105, 0.14504352, 0.5938015],\n",
       " [0.06837522483020501, 0.6116249, 0.21131767],\n",
       " [0.8537469079288921, 0.7572419, 0.41506222],\n",
       " [0.07671087121839539, 0.22673981, 0.05922429],\n",
       " [0.3269056224689859, 0.81647646, 0.07526669],\n",
       " [0.04492187595354851, 0.18535528, 0.019178657],\n",
       " [0.18423130922356773, 0.529571, 0.12971887],\n",
       " [0.027243107751318406, 0.0341218, 0.008064687],\n",
       " [0.20861995956743995, 0.85924625, 0.1924101],\n",
       " [0.444919800979806, 0.1497823, 0.5534892],\n",
       " [0.09172040563721229, 0.840993, 0.015810383],\n",
       " [0.06588176231570975, 0.7814511, 0.09455656],\n",
       " [0.20228357063536276, 0.27872795, 0.07577236],\n",
       " [0.4409383267425182, 0.87253517, 0.18441407],\n",
       " [0.35000166535394894, 0.25753817, 0.31819177],\n",
       " [0.13481527777386357, 0.7807674, 0.57866186],\n",
       " [0.022078664185006633, 0.1459679, 0.31703508],\n",
       " [0.37749174574607214, 0.84598964, 0.07511188],\n",
       " [0.037496283418434105, 0.59235024, 0.20763859],\n",
       " [0.053625819240461135, 0.27401322, 0.10655923],\n",
       " [0.014010327752440275, 0.12146821, 0.006996937],\n",
       " [0.05817343220001015, 0.1518389, 0.039680522],\n",
       " [0.8120017211598277, 0.8664138, 0.67363566],\n",
       " [0.11692831087942214, 0.050864913, 0.08330068],\n",
       " [0.028005622045078775, 0.20346151, 0.26404938],\n",
       " [0.16584971641886534, 0.6300168, 0.8429402],\n",
       " [0.033947566215233385, 0.163339, 0.56293756],\n",
       " [0.43475528220646464, 0.7262429, 0.50244856],\n",
       " [0.018012248399365598, 0.18331818, 0.2674265],\n",
       " [0.03938269976301429, 0.0824617, 0.009671541],\n",
       " [0.049477629522500365, 0.082683004, 0.14295839],\n",
       " [0.1897132994474262, 0.43618482, 0.067864716],\n",
       " [0.0971554541360755, 0.6908487, 0.1550387],\n",
       " [0.022983588795885072, 0.1699235, 0.0060512694],\n",
       " [0.08298470600066664, 0.3858839, 0.48350656],\n",
       " [0.012725004746559581, 0.08483689, 0.020649977],\n",
       " [0.26945099418503193, 0.78813404, 0.1852252],\n",
       " [0.15208263865722593, 0.8476488, 0.16951087],\n",
       " [0.43629233357602343, 0.8111013, 0.19273518],\n",
       " [0.014028987449914494, 0.08504582, 0.0067472267],\n",
       " [0.08173287730678654, 0.20407231, 0.029260691],\n",
       " [0.0727078365584407, 0.048675425, 0.06973523],\n",
       " [0.04215379622894553, 0.14276317, 0.03912613],\n",
       " [0.2673658447847179, 0.29950336, 0.38933763],\n",
       " [0.025023473154099946, 0.44758606, 0.045914467],\n",
       " [0.032769185743250835, 0.46196148, 0.07278399],\n",
       " [0.5648657184366291, 0.92576617, 0.29480943],\n",
       " [0.0862682741531501, 0.13049349, 0.19212352],\n",
       " [0.0923903500833022, 0.4152199, 0.48459226],\n",
       " [0.03398980250963662, 0.46811277, 0.15894684],\n",
       " [0.02414904091243218, 0.04588725, 0.082162075],\n",
       " [0.3328722105829553, 0.46127495, 0.11187677],\n",
       " [0.14651637983850127, 0.41806343, 0.92986107],\n",
       " [0.23516660681821516, 0.8061849, 0.14724743],\n",
       " [0.10098173617273327, 0.8716529, 0.4078378],\n",
       " [0.11895001559903602, 0.37534842, 0.18290696],\n",
       " [0.047844277101644614, 0.037536483, 0.016450737],\n",
       " [0.5072319321530915, 0.85822344, 0.27450234],\n",
       " [0.04773695765633789, 0.081451684, 0.027274732],\n",
       " [0.11176018780880947, 0.14174263, 0.12795052],\n",
       " [0.21018462374964042, 0.20766309, 0.05639347],\n",
       " [0.14946361673008315, 0.5380981, 0.15327832],\n",
       " [0.1259140470515617, 0.1937327, 0.7562455],\n",
       " [0.07340662546748998, 0.8760281, 0.123999886],\n",
       " [0.06767562127892529, 0.84573436, 0.2257788],\n",
       " [0.07333066886857004, 0.26629695, 0.08273743],\n",
       " [0.29320710448030296, 0.47459313, 0.70562994],\n",
       " [0.208833826705613, 0.054228608, 0.029324241],\n",
       " [0.09220596259274036, 0.48213145, 0.35240003],\n",
       " [0.3300295372313844, 0.335283, 0.24869668],\n",
       " [0.43144016059520074, 0.60648954, 0.35258007],\n",
       " [0.0806842661572523, 0.2299678, 0.48997307],\n",
       " [0.1391028447142474, 0.6435503, 0.046914287],\n",
       " [0.14553598455197422, 0.5972564, 0.22459866],\n",
       " [0.14422126192522644, 0.25897136, 0.015471868],\n",
       " [0.018877406897749475, 0.12897484, 0.066575944],\n",
       " [0.05620878671651962, 0.8576596, 0.031096455],\n",
       " [0.4959635915552363, 0.7050683, 0.20498542],\n",
       " [0.23746120998653789, 0.26712295, 0.098159194],\n",
       " [0.017654706416724685, 0.4233996, 0.015743716],\n",
       " [0.22628165271266992, 0.5071541, 0.14499103],\n",
       " [0.003349414264219371, 0.69902617, 0.0016550944],\n",
       " [0.24513807392269035, 0.38818225, 0.25611576],\n",
       " [0.13600976533157905, 0.1329321, 0.01086319],\n",
       " [0.007388898550620088, 0.117738955, 0.008641473],\n",
       " [0.692091944923084, 0.7705543, 0.42517105],\n",
       " [0.5020140264040834, 0.56500363, 0.5906644],\n",
       " [0.5390750556374079, 0.659196, 0.12198064],\n",
       " [0.02199815682287694, 0.07356139, 0.0658503],\n",
       " [0.30562691661372127, 0.2591818, 0.06967272],\n",
       " [0.07845032355584955, 0.8619927, 0.35030025],\n",
       " [0.5384718999135979, 0.7989586, 0.08973753],\n",
       " [0.13839657447333473, 0.7518985, 0.068088815],\n",
       " [0.2572919822373178, 0.4825553, 0.05002508],\n",
       " [0.005592728681081276, 0.20132835, 0.068418086],\n",
       " [0.054424155775538406, 0.16469678, 0.0052069663],\n",
       " [0.059024270130387045, 0.105081275, 0.10558751],\n",
       " [0.8597840396416053, 0.77681404, 0.5318027],\n",
       " [0.05818107929262559, 0.44860545, 0.760878],\n",
       " [0.052072748014415755, 0.5520407, 0.23926938],\n",
       " [0.06148871339205258, 0.036391836, 0.13934389],\n",
       " [0.03411440514429511, 0.39019427, 0.008478314],\n",
       " [0.16279982093413595, 0.08891315, 0.061584804],\n",
       " [0.05805060811632417, 0.36025876, 0.017361464],\n",
       " [0.5986491764854049, 0.80109113, 0.14334166],\n",
       " [0.4785533475936943, 0.7959116, 0.3905399],\n",
       " [0.08484378960455313, 0.31240517, 0.044578243],\n",
       " [0.06123782529157417, 0.15300407, 0.24545415],\n",
       " [0.016190491421840782, 0.05795023, 0.019090082],\n",
       " [0.1784614894709418, 0.892671, 0.3104255],\n",
       " [0.18001085207918843, 0.2756634, 0.23893322],\n",
       " [0.22004651126510572, 0.28999108, 0.13076076],\n",
       " [0.28588579034892747, 0.577792, 0.36555973],\n",
       " [0.053317699634874476, 0.8243864, 0.6248708],\n",
       " [0.10074320697109453, 0.36953902, 0.38517165],\n",
       " [0.21394331380725487, 0.5753887, 0.055534516],\n",
       " [0.04339747554612126, 0.05187546, 0.03755831],\n",
       " [0.009173748727574848, 0.12348065, 0.005267929],\n",
       " [0.02675824448694992, 0.120332055, 0.052961912],\n",
       " [0.23203072860507015, 0.1826922, 0.16800343],\n",
       " [0.4655461237872805, 0.9183168, 0.6648408],\n",
       " [0.5036462009111418, 0.7898788, 0.8673007],\n",
       " [0.11644655444809286, 0.31950593, 0.0066347173],\n",
       " [0.0901336239698376, 0.3200341, 0.20102915],\n",
       " [0.17663122568477094, 0.7859393, 0.51797104],\n",
       " [0.07154336972283067, 0.5650712, 0.38992342],\n",
       " [0.1694641379468573, 0.09665656, 0.6621018],\n",
       " [0.07014527582549972, 0.22625296, 0.05250846],\n",
       " [0.006261947329869181, 0.17471167, 0.08030839],\n",
       " [0.11997549397255378, 0.31398204, 0.38584307],\n",
       " [0.04145487989115557, 0.0684295, 0.1586923],\n",
       " [0.036973203556378904, 0.12928772, 0.05410914],\n",
       " [0.014577111774850531, 0.08822586, 0.012744444],\n",
       " [0.07329647410602345, 0.3784926, 0.09870495],\n",
       " [0.019489929887106627, 0.30493206, 0.31094396],\n",
       " [0.17472231270749813, 0.7767034, 0.3267462],\n",
       " [0.04420089560020273, 0.041370817, 0.011543559],\n",
       " [0.011691617281257758, 0.077502556, 0.015764195],\n",
       " [0.05629095661370973, 0.32585585, 0.17051911],\n",
       " [0.1714622219687671, 0.79269207, 0.57845306],\n",
       " [0.07853328502259478, 0.13924035, 0.015478269],\n",
       " [0.34607028572135873, 0.5235941, 0.00542993],\n",
       " [0.7421445907947328, 0.10578002, 0.11744605],\n",
       " [0.13803931141193787, 0.17035611, 0.030370738],\n",
       " [0.1725726080867166, 0.79634374, 0.12179854],\n",
       " [0.024788406116439284, 0.23664969, 0.12607051],\n",
       " [0.07409488941744882, 0.2995572, 0.30617273],\n",
       " [0.04367273863863458, 0.06894687, 0.048095122],\n",
       " [0.08992367863002318, 0.29016677, 0.42091262],\n",
       " [0.15365979340412705, 0.44095355, 0.12762429],\n",
       " [0.1252573925450217, 0.101621434, 0.09925864],\n",
       " [0.19145568333280338, 0.3045184, 0.19887613],\n",
       " [0.22864207254341323, 0.76145095, 0.031349078],\n",
       " [0.028838835936025597, 0.48272634, 0.09922045],\n",
       " [0.060164635082330976, 0.09074176, 0.29111812],\n",
       " [0.2388395602919347, 0.46617797, 0.33943027],\n",
       " [0.02607134905422577, 0.06620112, 0.11930675],\n",
       " [0.05066876467415522, 0.11308834, 0.0054729274],\n",
       " [0.8320159596405532, 0.9293872, 0.3515873],\n",
       " [0.230670806282336, 0.2621507, 0.3457532],\n",
       " [0.2634425604621098, 0.69710624, 0.0076661934],\n",
       " [0.017220932265902256, 0.294188, 0.45199737],\n",
       " [0.08189466364236882, 0.65791196, 0.52221495],\n",
       " [0.08626495302611971, 0.07976861, 0.024417445],\n",
       " [0.06829087985028684, 0.16253187, 0.11114741],\n",
       " [0.1580022993178733, 0.8863122, 0.1090294],\n",
       " [0.042568981990189915, 0.21683927, 0.123112075],\n",
       " [0.2686322086073227, 0.2722034, 0.6107828],\n",
       " [0.09200110767883364, 0.5545957, 0.054350156],\n",
       " [0.10684314258540027, 0.49618095, 0.11541197],\n",
       " [0.04186781410118556, 0.15777862, 0.018295847],\n",
       " [0.1664301627094689, 0.04410266, 0.23199081],\n",
       " [0.22422003774118007, 0.2714242, 0.41484502],\n",
       " [0.021011650794895437, 0.23247914, 0.32014912],\n",
       " [0.3548362034325318, 0.83185816, 0.18779622],\n",
       " [0.04654273983593488, 0.3293624, 0.025905963],\n",
       " [0.0491769861413298, 0.072478496, 0.11717103],\n",
       " [0.060319347132754914, 0.8443448, 0.39629194],\n",
       " [0.3785485207570164, 0.24977395, 0.14643554],\n",
       " [0.16721604371799365, 0.3423903, 0.07634582],\n",
       " [0.2359501546505998, 0.40733117, 0.14360417],\n",
       " [0.10953120299797492, 0.8541599, 0.23396222],\n",
       " [0.042035303685255286, 0.20495594, 0.011331557],\n",
       " [0.08098845338133995, 0.16941978, 0.22199741],\n",
       " [0.1477538777969262, 0.60199034, 0.2656223],\n",
       " [0.41336844648951343, 0.899998, 0.7691125],\n",
       " [0.0276398076408051, 0.29306105, 0.02441071],\n",
       " [0.037694822142177696, 0.12637295, 0.06490514],\n",
       " [0.084325248729619, 0.6683301, 0.09646698],\n",
       " [0.06655096293269719, 0.6289461, 0.18451978],\n",
       " [0.056172201288054266, 0.17902596, 0.01568126],\n",
       " [0.5777579749847697, 0.9066585, 0.69416744],\n",
       " [0.2579604228728787, 0.2830579, 0.021530656],\n",
       " [0.16552988165178412, 0.25900006, 0.03094714],\n",
       " [0.12299921308002003, 0.2517253, 0.16323976],\n",
       " [0.06147998420900491, 0.76178485, 0.20938642],\n",
       " [0.18857019178366782, 0.70914227, 0.108653374],\n",
       " [0.01401742806080478, 0.10334592, 0.015692582],\n",
       " [0.022061136466152504, 0.14517531, 0.122619346],\n",
       " [0.021326339743688385, 0.8849114, 0.016004896],\n",
       " [0.3317591962366627, 0.069205925, 0.017379954],\n",
       " [0.06580807378820006, 0.8983372, 0.45609766],\n",
       " [0.024313930900730904, 0.3225308, 0.23993094],\n",
       " [0.25116400227379354, 0.7636188, 0.33140078],\n",
       " [0.2243304795376801, 0.083818644, 0.123625845],\n",
       " [0.03999855142605261, 0.50961053, 0.23150778],\n",
       " [0.4453992998044011, 0.7861661, 0.6747529],\n",
       " [0.7623401685955435, 0.917278, 0.8030726],\n",
       " [0.06464447598394306, 0.6823365, 0.15485391],\n",
       " [0.02465541241165177, 0.19917986, 0.10595831],\n",
       " [0.08261614245029088, 0.221883, 0.07784543],\n",
       " [0.05204406844483387, 0.08628543, 0.08353627],\n",
       " [0.08970596500245659, 0.29950258, 0.010166816],\n",
       " [0.1166419018109355, 0.7000331, 0.03570139],\n",
       " [0.060302553014808254, 0.25715026, 0.0046529407],\n",
       " [0.0513563987801277, 0.2631523, 0.134696],\n",
       " [0.010781114100302953, 0.26374054, 0.2551068],\n",
       " [0.055158157951021046, 0.027818229, 0.16722877],\n",
       " [0.4939059473045668, 0.34185746, 0.3668447],\n",
       " [0.06188667841131697, 0.85530823, 0.06060034],\n",
       " [0.28586059716892837, 0.08132119, 0.03828243],\n",
       " [0.06367643124812405, 0.2203084, 0.13808276],\n",
       " [0.24209304224578596, 0.4083126, 0.15332362],\n",
       " [0.11461252325611886, 0.07640358, 0.19455677],\n",
       " [0.1005155124600984, 0.30598405, 0.18056324],\n",
       " [0.6392848130582103, 0.932228, 0.9229149],\n",
       " [0.07359213843986705, 0.16528356, 0.3222903],\n",
       " [0.009686480613518731, 0.46364355, 0.2917117],\n",
       " [0.7647622245094471, 0.89078265, 0.19484952],\n",
       " [0.08828074989182362, 0.24098006, 0.071661085],\n",
       " [0.049037696872029836, 0.03246346, 0.55271006],\n",
       " [0.0958098842314214, 0.5937779, 0.78834176],\n",
       " [0.6376821628560815, 0.91101164, 0.52109617],\n",
       " [0.0628501855921784, 0.68282247, 0.2762672],\n",
       " [0.12507015635585436, 0.16851008, 0.049451765],\n",
       " [0.14351407994651935, 0.55493677, 0.40879777],\n",
       " [0.03785845918650083, 0.71131504, 0.08551114],\n",
       " [0.6460890905804481, 0.8114822, 0.23446386],\n",
       " [0.34514909704553537, 0.85851145, 0.54395986],\n",
       " [0.011515425795228181, 0.05432094, 0.006278328],\n",
       " [0.11147571813005235, 0.18120496, 0.060468275],\n",
       " [0.08419918830628041, 0.22106043, 0.037631493],\n",
       " [0.16230748666815523, 0.29740041, 0.116942644],\n",
       " [0.5179880675915516, 0.14682238, 0.011148365],\n",
       " [0.036973417127603936, 0.082779095, 0.042576406],\n",
       " [0.14288358945255158, 0.056025904, 0.017397994],\n",
       " [0.02257198833281421, 0.27304888, 0.02386969],\n",
       " [0.012389220482501176, 0.12860002, 0.01498057],\n",
       " [0.08365721774384219, 0.23798056, 0.089941815],\n",
       " [0.27159526017318064, 0.9111296, 0.50446904],\n",
       " [0.03813627667584175, 0.17667294, 0.14763863],\n",
       " [0.5456842274328099, 0.41531494, 0.55114657],\n",
       " [0.02122251421465838, 0.48051396, 0.133658],\n",
       " [0.2404221058583366, 0.7811765, 0.5735508],\n",
       " [0.11193917939184012, 0.08531157, 0.13442211],\n",
       " [0.09792716553989755, 0.2004399, 0.49080423],\n",
       " [0.06416950290268855, 0.598194, 0.1975215],\n",
       " [0.09660301760743097, 0.946722, 0.41579503],\n",
       " [0.1399480567046846, 0.27151477, 0.02196423],\n",
       " [0.1754220835195654, 0.3536193, 0.2148062],\n",
       " [0.4726399606488201, 0.94223577, 0.58889544],\n",
       " [0.5187031920486984, 0.47131932, 0.038703363],\n",
       " [0.020896888451537674, 0.4961108, 0.57100487],\n",
       " [0.1957756847365084, 0.62194395, 0.055533968],\n",
       " [0.1801212621432829, 0.20113438, 0.2629684],\n",
       " [0.013772462026569019, 0.5340078, 0.003367379],\n",
       " [0.21553978946167193, 0.6845854, 0.7490062],\n",
       " [0.27785843848824443, 0.87909764, 0.4437606],\n",
       " [0.26256489664269783, 0.24353603, 0.03623654],\n",
       " [0.04557187753807747, 0.4579162, 0.021314012],\n",
       " [0.31012706601632495, 0.12930115, 0.2836855],\n",
       " [0.050980713706982816, 0.5673506, 0.030202184],\n",
       " [0.12612274264515036, 0.24521376, 0.022469077],\n",
       " [0.09429806129062338, 0.18194154, 0.066805206],\n",
       " [0.11326113285019075, 0.055130728, 0.016921623],\n",
       " [0.25391840129069804, 0.7193974, 0.38777664],\n",
       " [0.7315240002951245, 0.8428567, 0.58472383],\n",
       " [0.12031241470103916, 0.681442, 0.27281588],\n",
       " [0.026422043506486522, 0.10326026, 0.107961774],\n",
       " [0.0771907341595435, 0.83591443, 0.1526906],\n",
       " [0.06694011706339595, 0.3003102, 0.11457555],\n",
       " [0.14876082711014801, 0.08310018, 0.04235781],\n",
       " [0.48241548023002134, 0.40493265, 0.25032628],\n",
       " [0.17301198841856927, 0.93656254, 0.84106094],\n",
       " [0.07614561381158376, 0.605205, 0.71749794],\n",
       " [0.24185010826530284, 0.39901406, 0.8247798],\n",
       " [0.07911223788806197, 0.5292098, 0.0082379365],\n",
       " [0.4215304403804989, 0.38296133, 0.07118983],\n",
       " [0.20688689333193971, 0.6371456, 0.8571678],\n",
       " [0.13223220464176555, 0.7632981, 0.27242562],\n",
       " [0.234843211371307, 0.5082341, 0.02755515],\n",
       " [0.3972022480389354, 0.8208065, 0.028200911],\n",
       " [0.012917864581389368, 0.103965424, 0.006711732],\n",
       " [0.3173662901115144, 0.12382152, 0.42191222],\n",
       " [0.21252431020282259, 0.78073835, 0.32734635],\n",
       " [0.10276462795321753, 0.26529825, 0.02702161],\n",
       " [0.03309677538663592, 0.46077558, 0.19687836],\n",
       " [0.0565259512997102, 0.39219958, 0.02576324],\n",
       " [0.09761321594460208, 0.08010527, 0.043493904],\n",
       " [0.03824860502494809, 0.24283896, 0.25026932],\n",
       " [0.1022771141133636, 0.2346949, 0.58231044],\n",
       " [0.3793939386552163, 0.68771887, 0.73308027],\n",
       " [0.5375362945491647, 0.35091543, 0.067267984],\n",
       " [0.046916994016944664, 0.05605925, 0.16891685],\n",
       " [0.30080230026623234, 0.3247947, 0.37120232],\n",
       " [0.24550832339588713, 0.73662066, 0.16771492],\n",
       " [0.26867354033846064, 0.17392884, 0.11976555],\n",
       " [0.5517928891618501, 0.7752474, 0.27255318],\n",
       " [0.16576671613141747, 0.63643914, 0.05005212],\n",
       " [0.050548426276590445, 0.06074129, 0.14315796],\n",
       " [0.10612156258745657, 0.6478673, 0.021361481],\n",
       " [0.019773401993865562, 0.39813504, 0.31901395],\n",
       " [0.06616298838889825, 0.47168383, 0.067509614],\n",
       " [0.06232150245459353, 0.09393965, 0.027785724],\n",
       " [0.04872861531173323, 0.13314924, 0.18451896],\n",
       " [0.02521693647276033, 0.07369252, 0.03995103],\n",
       " [0.22357404606357553, 0.8411295, 0.7991267],\n",
       " [0.03910588827110434, 0.07794807, 0.026025414],\n",
       " [0.20899692912533874, 0.75737566, 0.27593523],\n",
       " [0.17112088091016778, 0.3426557, 0.039003316],\n",
       " [0.029882916358910397, 0.34831995, 0.0686447],\n",
       " [0.10018220669855407, 0.87261224, 0.016825736],\n",
       " [0.10364799325784313, 0.2847965, 0.22485556],\n",
       " [0.13418655384342806, 0.10828911, 0.08053318],\n",
       " [0.12909353773672202, 0.23701648, 0.20245405],\n",
       " [0.2659056468993067, 0.11601239, 0.065424524],\n",
       " [0.017983486119255244, 0.33673906, 0.08680477],\n",
       " [0.6993811268170831, 0.9246495, 0.87471694],\n",
       " [0.07467094826459113, 0.1673077, 0.2606291],\n",
       " [0.12798841844985698, 0.8216176, 0.44529286],\n",
       " [0.030071337466633766, 0.107685104, 0.027867021],\n",
       " [0.07718075621907743, 0.13913697, 0.31752908],\n",
       " [0.1448922331747946, 0.7416881, 0.33439377],\n",
       " [0.08813313051253654, 0.25322977, 0.035092674],\n",
       " [0.4778946610067649, 0.34600872, 0.2658299],\n",
       " [0.5573440200928143, 0.73194104, 0.051367756],\n",
       " [0.1791855808997817, 0.16076651, 0.058351398],\n",
       " [0.05182691180896395, 0.4692378, 0.2059362],\n",
       " [0.23736308276563015, 0.12852408, 0.05281152],\n",
       " [0.136535447494944, 0.04676365, 0.021469384],\n",
       " [0.7621485772368131, 0.5223612, 0.7422278],\n",
       " [0.08485774358826931, 0.1435971, 0.07126585],\n",
       " [0.23235215239873494, 0.03652127, 0.49029636],\n",
       " [0.49360545590643434, 0.7553606, 0.5626299],\n",
       " [0.03234350776610011, 0.07072529, 0.015407646],\n",
       " [0.26959512581556844, 0.04940939, 0.18308604],\n",
       " [0.289337284293469, 0.6302843, 0.17531107],\n",
       " [0.1837559085813081, 0.7314075, 0.044845533],\n",
       " [0.09173556134930484, 0.0778198, 0.033113945],\n",
       " [0.02799969800738493, 0.068657525, 0.16734341],\n",
       " [0.052348682984182576, 0.074390724, 0.006210205],\n",
       " [0.017080352347836763, 0.103102826, 0.11112794],\n",
       " [0.1505097346546541, 0.047357816, 0.07015739],\n",
       " [0.016091139305902193, 0.091870934, 0.016276773],\n",
       " [0.0434278658130458, 0.20157012, 0.0065992684],\n",
       " [0.06519726151609492, 0.09129868, 0.014423022],\n",
       " [0.13123150486348198, 0.8605958, 0.03974402],\n",
       " [0.1733008194111717, 0.6977834, 0.025783062],\n",
       " [0.036141993432842766, 0.54322594, 0.22766936],\n",
       " [0.29077414814971747, 0.8854018, 0.52687764],\n",
       " [0.39473761410889535, 0.7715663, 0.05837871],\n",
       " [0.43821670176531297, 0.5079867, 0.557928],\n",
       " [0.030297764305848632, 0.21077226, 0.02349809],\n",
       " [0.22245648821744118, 0.42362884, 0.032038495],\n",
       " [0.2823502678262224, 0.2491015, 0.043153018],\n",
       " [0.04647729599650966, 0.48580474, 0.21584556],\n",
       " [0.08743042761787363, 0.6614134, 0.3676638],\n",
       " [0.598886773363536, 0.7307646, 0.03790986],\n",
       " [0.031218900890033412, 0.40233344, 0.5651899],\n",
       " [0.04259117609935933, 0.21407801, 0.12863643],\n",
       " [0.365933088319559, 0.71824574, 0.071718715],\n",
       " [0.3505708077495348, 0.61029977, 0.79401064],\n",
       " [0.2930813905171835, 0.8919706, 0.54621077],\n",
       " [0.0738469318245682, 0.15646042, 0.16932186],\n",
       " [0.8525977594101983, 0.9093432, 0.70256615],\n",
       " [0.0115584735263093, 0.12211834, 0.05922455],\n",
       " [0.11949584043795079, 0.1829524, 0.35392556],\n",
       " [0.016090222399093683, 0.12518606, 0.100485705],\n",
       " [0.30416392925221614, 0.7802019, 0.5248127],\n",
       " [0.44369872772103275, 0.84983146, 0.23311116],\n",
       " [0.3327772062891666, 0.04800127, 0.28334087],\n",
       " [0.3243239114942873, 0.581312, 0.22967307],\n",
       " [0.03609963592786379, 0.3945247, 0.18284518],\n",
       " [0.22096959646240186, 0.55450904, 0.2928197],\n",
       " [0.046799904018500815, 0.0898769, 0.28963366],\n",
       " [0.11489955199825191, 0.93240446, 0.3837334],\n",
       " [0.08817400260825621, 0.16305804, 0.045726612],\n",
       " [0.027374713729536045, 0.24103105, 0.054904647],\n",
       " [0.3221846655925279, 0.47726867, 0.42784795],\n",
       " [0.4620101125136896, 0.63489974, 0.20618872],\n",
       " [0.03175617368350457, 0.08522152, 0.016797692],\n",
       " [0.16541255306944055, 0.09521228, 0.011969921],\n",
       " [0.5939757760887573, 0.4186586, 0.87987584],\n",
       " [0.054514969379066816, 0.8500522, 0.23865579],\n",
       " [0.11047710620222077, 0.060504396, 0.07491091],\n",
       " [0.20386599934306307, 0.7820273, 0.08985671],\n",
       " [0.21003094376462866, 0.324548, 0.019007793],\n",
       " [0.38603581304346196, 0.40103084, 0.048624974],\n",
       " [0.22343845556254865, 0.42156518, 0.093999416],\n",
       " [0.49319047552888795, 0.05577128, 0.45569408],\n",
       " [0.04149657997627875, 0.08954556, 0.282712],\n",
       " [0.3036544584850529, 0.8237674, 0.1137646],\n",
       " [0.11578095472004703, 0.5832558, 0.2301682],\n",
       " [0.07098278198469316, 0.3990527, 0.005985661],\n",
       " [0.061324061130874775, 0.16140142, 0.005245637],\n",
       " [0.5677439756310546, 0.85951626, 0.34829497],\n",
       " [0.03529523659216451, 0.20954826, 0.012746185],\n",
       " [0.0842460831233497, 0.43780315, 0.1616765],\n",
       " [0.15774789624744615, 0.6233616, 0.057306927],\n",
       " [0.13150814961613588, 0.8021679, 0.13508357],\n",
       " [0.06501942753338298, 0.25073275, 0.1307654],\n",
       " [0.017958220027961866, 0.10309251, 0.30580086],\n",
       " [0.0693366702989688, 0.048882715, 0.118191205],\n",
       " [0.10815301355387441, 0.13132522, 0.28813496],\n",
       " [0.1513924327217565, 0.3530676, 0.13903397],\n",
       " [0.18016916897697538, 0.13731167, 0.0083432915],\n",
       " [0.3626949661804741, 0.5121726, 0.53439456],\n",
       " [0.08380535365298797, 0.46140045, 0.08272663],\n",
       " [0.11444800113642194, 0.23069529, 0.36314696],\n",
       " [0.021690985699690083, 0.51762587, 0.086556196],\n",
       " [0.1679340299894255, 0.728432, 0.43866724],\n",
       " [0.016354490973874067, 0.37393743, 0.030758265],\n",
       " [0.0582160507315772, 0.08411641, 0.028370047],\n",
       " [0.30823386420788107, 0.87521076, 0.1692497],\n",
       " [0.10367401736098361, 0.47961584, 0.0767939],\n",
       " [0.03747991863273579, 0.2416412, 0.01746597],\n",
       " [0.06995760769133316, 0.11730486, 0.046134908],\n",
       " [0.3498274520334647, 0.51112455, 0.20335521],\n",
       " [0.2819079801208252, 0.3479834, 0.110228464],\n",
       " [0.12711776724054646, 0.59544986, 0.10773373],\n",
       " [0.10824221317108067, 0.3166304, 0.81433564],\n",
       " [0.051092940228002065, 0.14317195, 0.0090269055],\n",
       " [0.4755150130348291, 0.87541336, 0.45415086],\n",
       " [0.17024123743028105, 0.86333567, 0.13929321],\n",
       " [0.1748997869558171, 0.1744904, 0.77816254],\n",
       " [0.008643739987551283, 0.18103668, 0.029008029],\n",
       " [0.166382996446084, 0.4373398, 0.076345205],\n",
       " [0.3102146325550338, 0.90166706, 0.28312027],\n",
       " [0.19704363540427527, 0.15384431, 0.02319794],\n",
       " [0.5400220172835307, 0.32889596, 0.27715513],\n",
       " [0.03579319424591397, 0.092320174, 0.028899169],\n",
       " [0.05093598080726765, 0.085878335, 0.006219486],\n",
       " [0.04189526493062107, 0.037588242, 0.015883291],\n",
       " [0.17546349668084762, 0.69610924, 0.0971262],\n",
       " [0.008863170424009418, 0.5526015, 0.056364123],\n",
       " [0.16681026274222843, 0.05374722, 0.15328394],\n",
       " [0.6683095616312014, 0.85033935, 0.31041834],\n",
       " [0.10071134276137862, 0.49551576, 0.5568434],\n",
       " [0.061708039981624774, 0.072123945, 0.1308594],\n",
       " [0.13080490889270616, 0.5798902, 0.038927644],\n",
       " [0.07907666405508947, 0.6953512, 0.18115997],\n",
       " [0.2309268522310335, 0.5245262, 0.5593515],\n",
       " [0.020219599179039344, 0.2519593, 0.30468115],\n",
       " [0.11025640370605025, 0.11165783, 0.06576429],\n",
       " [0.027810174630441054, 0.08782294, 0.044609137],\n",
       " [0.7631839481818933, 0.1530905, 0.5244292],\n",
       " [0.1141667116216226, 0.04489884, 0.58846474],\n",
       " [0.008249877534634827, 0.13908449, 0.04339457],\n",
       " [0.016582149954496417, 0.1547834, 0.03781237],\n",
       " [0.7460269686698737, 0.8993657, 0.22138712],\n",
       " [0.26687908066258453, 0.69838524, 0.29565725],\n",
       " [0.10129078100629957, 0.83023685, 0.22922155],\n",
       " [0.07348879311070135, 0.06872616, 0.10569065],\n",
       " [0.08095946192343, 0.11524375, 0.6999828],\n",
       " [0.14306418492806636, 0.59466916, 0.6425049],\n",
       " [0.15481028828212381, 0.06890807, 0.04069094],\n",
       " [0.005040972750252055, 0.071239814, 0.25956392],\n",
       " [0.20319232058807238, 0.38319132, 0.05986195],\n",
       " [0.02314219321751935, 0.22170165, 0.008243061],\n",
       " [0.31190366478748094, 0.887415, 0.10343459],\n",
       " [0.06675958718196438, 0.67489994, 0.09287624],\n",
       " [0.015618512607256392, 0.079332136, 0.079534896],\n",
       " [0.07027530189155462, 0.8432123, 0.11236841],\n",
       " [0.5851477559542289, 0.4642978, 0.172576],\n",
       " [0.0895148308974204, 0.042182643, 0.0057845805],\n",
       " [0.044558796136713895, 0.33342868, 0.13234238],\n",
       " [0.2795985973469782, 0.6441336, 0.59462756],\n",
       " [0.04740131457833186, 0.93975633, 0.0027542505],\n",
       " [0.2830807432962027, 0.9063014, 0.34189358],\n",
       " [0.06940446699910773, 0.18058462, 0.24501207],\n",
       " [0.027132146059749975, 0.34687588, 0.020871563],\n",
       " [0.61731232607144, 0.8458621, 0.6889766],\n",
       " [0.06883156716800704, 0.44808638, 0.029286403],\n",
       " [0.04942983614198993, 0.095618345, 0.040000293],\n",
       " [0.016398485039343633, 0.14118414, 0.014340272],\n",
       " [0.23318938998601388, 0.5900041, 0.114458635],\n",
       " [0.15639964076467902, 0.17046829, 0.12077672],\n",
       " [0.052999642634325425, 0.29933846, 0.412898],\n",
       " [0.2752140815909821, 0.7463385, 0.68986046],\n",
       " [0.08577091178473091, 0.38170764, 0.022054616],\n",
       " [0.02394548440154418, 0.25692797, 0.033959676],\n",
       " [0.6532167012035182, 0.8780345, 0.44489],\n",
       " [0.12209101631575422, 0.8670007, 0.5762733],\n",
       " [0.18631999161464685, 0.75499296, 0.66160244],\n",
       " [0.05173789155235144, 0.16077584, 0.03272428],\n",
       " [0.11036714674198767, 0.23144348, 0.008613366],\n",
       " [0.33591424256756314, 0.5866203, 0.7291232],\n",
       " [0.06893111624513247, 0.3654452, 0.024549669],\n",
       " [0.12753519706347474, 0.7346172, 0.1456531],\n",
       " [0.012824560710782902, 0.171064, 0.0076040085],\n",
       " [0.08490790097641557, 0.21707097, 0.6428679],\n",
       " [0.08699140614312283, 0.0801403, 0.25727123],\n",
       " [0.13438652263946643, 0.86099535, 0.030844778],\n",
       " [0.30051847416902006, 0.57283014, 0.008689522],\n",
       " [0.09247427767512752, 0.27510083, 0.10852918],\n",
       " [0.22460476345818156, 0.047399208, 0.37575683],\n",
       " [0.40853894332542584, 0.17984307, 0.23012893],\n",
       " [0.30782501478311497, 0.2988082, 0.18596068],\n",
       " [0.49472700755568966, 0.60968196, 0.53526735],\n",
       " [0.3274303302129079, 0.053856708, 0.24299966],\n",
       " [0.09726755996656573, 0.39566448, 0.11658692],\n",
       " [0.14314463886307915, 0.10425023, 0.17556149],\n",
       " [0.3351819261160471, 0.7103129, 0.006337324],\n",
       " [0.027764928672721144, 0.23698734, 0.009295708],\n",
       " [0.08085119271209723, 0.216444, 0.06962724],\n",
       " [0.3825626559091096, 0.17857741, 0.41517693],\n",
       " [0.41254213909125176, 0.80747044, 0.14835204],\n",
       " [0.08492999616021758, 0.2962855, 0.02523391],\n",
       " [0.15566585635335545, 0.08414512, 0.2593597],\n",
       " [0.25598639057331113, 0.54427016, 0.50866663],\n",
       " [0.14745166376410468, 0.26377574, 0.2723537],\n",
       " [0.2081158577759616, 0.40030777, 0.14705059],\n",
       " [0.033858025167612195, 0.33514825, 0.060475916],\n",
       " [0.08504476813919742, 0.5381225, 0.26673424],\n",
       " [0.2835891203435772, 0.57232004, 0.26180243],\n",
       " [0.05783311170920138, 0.056910716, 0.07531041],\n",
       " [0.06577641594014284, 0.63617873, 0.45531628],\n",
       " [0.5122689840839354, 0.26722854, 0.8463647],\n",
       " [0.09002295331080615, 0.15208058, 0.73227316],\n",
       " [0.32876938636140984, 0.9254235, 0.076930955],\n",
       " [0.013300807059210289, 0.040593114, 0.13686472],\n",
       " [0.03855185669380033, 0.12925725, 0.18940572],\n",
       " [0.07795370402677176, 0.5318925, 0.73258805],\n",
       " [0.05847860039293435, 0.35455057, 0.047596887],\n",
       " [0.2324522884172819, 0.16090219, 0.04342104],\n",
       " [0.5466516499874968, 0.8871652, 0.38137862],\n",
       " [0.02411547172667526, 0.059888538, 0.042609572],\n",
       " [0.08974834638148213, 0.5299863, 0.1520283],\n",
       " [0.13117991547545352, 0.5952719, 0.3301033],\n",
       " [0.13240150612930623, 0.12622951, 0.1759816],\n",
       " [0.12446891553940423, 0.2751905, 0.04987362],\n",
       " [0.019645686425669683, 0.2329674, 0.06039111],\n",
       " [0.04217349657513607, 0.16427305, 0.65109503],\n",
       " [0.13200866136388434, 0.044295363, 0.20031685],\n",
       " [0.20029608827455977, 0.5255486, 0.052256145],\n",
       " [0.27807727869194965, 0.24033682, 0.0060711373],\n",
       " [0.38585967170776475, 0.22229321, 0.023730744],\n",
       " [0.2077474417393106, 0.1165652, 0.5330962],\n",
       " [0.30641893789482727, 0.86443263, 0.070708156],\n",
       " [0.05941900208443759, 0.4037912, 0.013786797],\n",
       " [0.4629792929295116, 0.39666793, 0.24520527],\n",
       " [0.04512283737526602, 0.21323769, 0.020962616],\n",
       " [0.0191864358297532, 0.116391845, 0.013454946],\n",
       " [0.08052256007600482, 0.19223341, 0.0387598],\n",
       " [0.05852806749439986, 0.17803453, 0.07082343],\n",
       " [0.10960224254940967, 0.38783017, 0.18316087],\n",
       " [0.05947593258687442, 0.322118, 0.14646535],\n",
       " [0.06776851815805648, 0.2906808, 0.11594414],\n",
       " [0.14804543610796977, 0.223371, 0.17099865],\n",
       " [0.1011234889674008, 0.13462353, 0.10268462],\n",
       " [0.3663189701886307, 0.5327151, 0.08846522],\n",
       " [0.0813434053191068, 0.2678051, 0.042399056],\n",
       " [0.01924743515417236, 0.60128593, 0.037129637],\n",
       " [0.24057037002018522, 0.9127558, 0.33687136],\n",
       " [0.04062189766723796, 0.20312092, 0.04476847],\n",
       " [0.19435030527281397, 0.30942163, 0.42181766],\n",
       " [0.05553443572636767, 0.15844071, 0.6729079],\n",
       " [0.05530645097984036, 0.11607814, 0.10257374],\n",
       " [0.016284953809507376, 0.06208603, 0.041010916],\n",
       " [0.061149699863204114, 0.081464075, 0.21652411],\n",
       " [0.16691342602171488, 0.09085326, 0.075554006],\n",
       " [0.18584508055004198, 0.7924623, 0.6443529],\n",
       " [0.7874028468182003, 0.8580561, 0.57196826],\n",
       " [0.110370558983276, 0.30128607, 0.12820068],\n",
       " [0.15224711374538757, 0.37904805, 0.16077605],\n",
       " [0.3339138276226109, 0.088343546, 0.47627592],\n",
       " [0.05111749945529796, 0.08170546, 0.04597562],\n",
       " [0.041673655943230935, 0.14082906, 0.20197818],\n",
       " [0.04859130525721455, 0.09887144, 0.29899302],\n",
       " [0.04821565093399894, 0.032210734, 0.065043345],\n",
       " [0.006423204652067669, 0.19438596, 0.08565833],\n",
       " [0.31280397480955136, 0.2081211, 0.04196516],\n",
       " [0.6824536188285081, 0.74434495, 0.25955322],\n",
       " [0.030895595416209416, 0.28107134, 0.19824304],\n",
       " [0.09217102165002236, 0.5825171, 0.41623628],\n",
       " [0.8470862298717112, 0.8025466, 0.30532214],\n",
       " [0.12594401181889037, 0.4476962, 0.05610341],\n",
       " [0.16700172827915213, 0.79341346, 0.18404256],\n",
       " [0.14593138343731932, 0.41817638, 0.13489982],\n",
       " [0.08707867083324224, 0.10735408, 0.01460083],\n",
       " [0.01193410895862269, 0.3076183, 0.0379743],\n",
       " [0.3090964921398126, 0.3566422, 0.58129656],\n",
       " [0.02618116678868968, 0.1562952, 0.005740196],\n",
       " [0.09227300104350619, 0.18866034, 0.0365475],\n",
       " [0.11387393626535715, 0.60827065, 0.3458625],\n",
       " [0.47049872214104993, 0.9002802, 0.5383456],\n",
       " [0.3669123831506235, 0.19350013, 0.3040032],\n",
       " [0.09603960285921878, 0.12683657, 0.025114737],\n",
       " [0.1352637023493525, 0.14966483, 0.029900908],\n",
       " [0.34770005049837804, 0.09695872, 0.16012013],\n",
       " [0.03537220675936266, 0.19205712, 0.003192278],\n",
       " [0.15126336931371975, 0.07118679, 0.196024],\n",
       " [0.04859748569742, 0.30969453, 0.043402605],\n",
       " [0.09446972577723929, 0.17555742, 0.30011755],\n",
       " [0.0536150574419687, 0.05030051, 0.054719333],\n",
       " [0.2272913648379106, 0.20767634, 0.37854895],\n",
       " [0.10018019691279437, 0.9138737, 0.40405026],\n",
       " [0.029319638911658223, 0.324932, 0.0036368726],\n",
       " [0.009454678559673775, 0.56688875, 0.1954896],\n",
       " [0.09077255451821584, 0.32157242, 0.18688032],\n",
       " [0.4040687820315027, 0.09737795, 0.06266207],\n",
       " [0.021763009868164113, 0.05195326, 0.10211461],\n",
       " [0.22964260695779562, 0.08334165, 0.016104227],\n",
       " [0.3501349557583741, 0.3957488, 0.5827977],\n",
       " [0.036473538302429456, 0.84347785, 0.27030435],\n",
       " [0.5491754977541305, 0.30945343, 0.61118126],\n",
       " [0.0763639904263745, 0.66835, 0.7205751],\n",
       " [0.05337768195548015, 0.5871964, 0.17305285],\n",
       " [0.1833822730427862, 0.09157073, 0.06458341],\n",
       " [0.21090079884465615, 0.16000485, 0.3835704],\n",
       " [0.2428089668511809, 0.23772801, 0.022783624],\n",
       " [0.22827456101416832, 0.2597241, 0.26581454],\n",
       " [0.0032998336516339827, 0.24622072, 0.0017855741],\n",
       " [0.5458225966909127, 0.83931434, 0.58702236],\n",
       " [0.05545996799923213, 0.40832478, 0.25463066],\n",
       " [0.0741697563077481, 0.049946364, 0.16373873],\n",
       " [0.5190091437962133, 0.8442581, 0.49925467],\n",
       " [0.37936924986327303, 0.83494073, 0.119758785],\n",
       " [0.09000792350356951, 0.22023751, 0.06881826],\n",
       " [0.07572312519256653, 0.16394322, 0.21618731],\n",
       " [0.42854566148003687, 0.6355543, 0.058925062],\n",
       " [0.14577513817913912, 0.10305391, 0.05434977],\n",
       " [0.011043392998452108, 0.1670952, 0.023093587],\n",
       " [0.15900470989274446, 0.09723996, 0.04000353],\n",
       " [0.22088269236854519, 0.741722, 0.19175275],\n",
       " [0.03530695139890752, 0.06723214, 0.19025384],\n",
       " [0.4830320151361737, 0.6168061, 0.85314065],\n",
       " [0.04049494143204133, 0.080520615, 0.74640363],\n",
       " [0.03717768389115496, 0.21704935, 0.03542271],\n",
       " [0.4088360540696212, 0.84267426, 0.4754306],\n",
       " [0.6265687701878179, 0.87608004, 0.7796521],\n",
       " [0.027994400611181965, 0.53292745, 0.05722286],\n",
       " [0.29285472066225454, 0.7816892, 0.31889948],\n",
       " [0.040951143144753385, 0.42690936, 0.108338706],\n",
       " [0.030724288799170583, 0.45492435, 0.2582796],\n",
       " [0.23459317644758518, 0.2085872, 0.21890898],\n",
       " [0.16233676769131897, 0.5192879, 0.1372147],\n",
       " [0.11572109739363087, 0.10170886, 0.09843377],\n",
       " [0.019925392012773088, 0.39978123, 0.056126185],\n",
       " [0.070607320335299, 0.7686455, 0.40321937],\n",
       " [0.17739714499564394, 0.53924066, 0.55533296],\n",
       " [0.5453330518685382, 0.9375821, 0.45782775],\n",
       " [0.4565089403528791, 0.12871037, 0.08189107],\n",
       " [0.01675251962637585, 0.2508389, 0.048265845],\n",
       " [0.062225372464250465, 0.250392, 0.16746813],\n",
       " [0.036450719991604374, 0.10386077, 0.02162545],\n",
       " [0.08507102788584756, 0.1284254, 0.12648238],\n",
       " [0.03148276930239965, 0.08097052, 0.027129397],\n",
       " [0.3605537901519366, 0.8748177, 0.7818275],\n",
       " [0.1095569064554488, 0.08194574, 0.11057053],\n",
       " [0.2918226795883623, 0.23616304, 0.10410278],\n",
       " [0.03907241412585821, 0.2732223, 0.10339087],\n",
       " [0.1809041593555032, 0.20790233, 0.07168212],\n",
       " [0.14440270401536795, 0.44947597, 0.19760764],\n",
       " [0.3219407925230997, 0.7625509, 0.18463281],\n",
       " [0.14731816082370724, 0.700819, 0.08686193],\n",
       " [0.4153119146963094, 0.64392823, 0.10002592],\n",
       " [0.06636618475099973, 0.38584766, 0.05061231],\n",
       " [0.25024026885877926, 0.42082357, 0.01469574],\n",
       " [0.013099922894432712, 0.052551623, 0.016590346],\n",
       " [0.8621270445936334, 0.5969431, 0.4979502],\n",
       " [0.051050426404875116, 0.21267267, 0.07912842],\n",
       " [0.060768035993842395, 0.2706127, 0.056243658],\n",
       " [0.44610074752689965, 0.70233685, 0.20325851],\n",
       " [0.43907317113029853, 0.096901596, 0.026776837],\n",
       " [0.14615948279598634, 0.099629045, 0.08510821],\n",
       " [0.519817866558531, 0.7434657, 0.15859427],\n",
       " [0.09533828015313457, 0.30541697, 0.8687165],\n",
       " [0.15432089468784568, 0.2711442, 0.042078003],\n",
       " [0.042543820036805985, 0.7815023, 0.01922453],\n",
       " [0.7028884783504226, 0.6873527, 0.4194398],\n",
       " [0.0751882705241705, 0.5930609, 0.051225077],\n",
       " [0.15482591602353127, 0.2287493, 0.016519964],\n",
       " [0.027329088734312012, 0.2709915, 0.04093455],\n",
       " [0.059303924367917114, 0.5785893, 0.03288634],\n",
       " [0.2645551504407619, 0.20065694, 0.11472404],\n",
       " [0.08755934506063363, 0.3769606, 0.116324626],\n",
       " [0.06850859789345339, 0.047619835, 0.16696964],\n",
       " [0.08699010712525257, 0.58124524, 0.10144482],\n",
       " [0.275032279592196, 0.039998554, 0.05731494],\n",
       " [0.1085230215005274, 0.083923124, 0.0112076895],\n",
       " [0.2962224533801416, 0.35813585, 0.041297168],\n",
       " [0.3017649462519696, 0.5096435, 0.00913095],\n",
       " [0.10015067062399803, 0.1346052, 0.08443088],\n",
       " [0.05490296223956126, 0.12145012, 0.01716944],\n",
       " [0.17858870515503134, 0.7085788, 0.29275954],\n",
       " [0.0930607293482003, 0.7769038, 0.47834444],\n",
       " [0.2788406117474031, 0.6238976, 0.0119074015],\n",
       " [0.12934081431740396, 0.63286775, 0.14986119],\n",
       " [0.021495375461910996, 0.06384736, 0.013692911],\n",
       " [0.006023988352554747, 0.107035935, 0.0053516002],\n",
       " [0.8738212969603342, 0.70378584, 0.8421269],\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = compute_sample_weight(class_weight='balanced', y=tr_data[1])\n",
    "# _weights = compute_class_weight(class_weight='balanced', classes=np.unique(tr_dataset[5]), y=tr_dataset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgb_train = lgb.Dataset(np.array(tr_data[0]), np.array(tr_data[1]), weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 14:19:54,731] A new study created in memory with name: no-name-1f525709-3d78-4f0e-aed6-9430d7d5373f\n",
      "feature_fraction, val_score: 0.811744:  14%|#4        | 1/7 [00:00<00:00,  7.77it/s][I 2023-12-02 14:19:54,873] Trial 0 finished with value: 0.811743583536545 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.811743583536545.\n",
      "feature_fraction, val_score: 0.811744:  14%|#4        | 1/7 [00:00<00:00,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tcv_agg's valid auc: 0.811744 + 0.0124473\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.811744:  29%|##8       | 2/7 [00:00<00:00,  7.90it/s][I 2023-12-02 14:19:55,000] Trial 1 finished with value: 0.811743583536545 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.811743583536545.\n",
      "feature_fraction, val_score: 0.811744:  29%|##8       | 2/7 [00:00<00:00,  7.90it/s][I 2023-12-02 14:19:55,077] Trial 2 finished with value: 0.7986576977214439 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.811743583536545.\n",
      "feature_fraction, val_score: 0.811744:  43%|####2     | 3/7 [00:00<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tcv_agg's valid auc: 0.811744 + 0.0124473\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tcv_agg's valid auc: 0.798658 + 0.014213\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.811973:  57%|#####7    | 4/7 [00:00<00:00,  7.49it/s][I 2023-12-02 14:19:55,274] Trial 3 finished with value: 0.8119734592897189 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.8119734592897189.\n",
      "feature_fraction, val_score: 0.811973:  71%|#######1  | 5/7 [00:00<00:00,  7.29it/s][I 2023-12-02 14:19:55,421] Trial 4 finished with value: 0.811743583536545 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.8119734592897189.\n",
      "feature_fraction, val_score: 0.811973:  71%|#######1  | 5/7 [00:00<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid auc: 0.811973 + 0.0141784\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tcv_agg's valid auc: 0.811744 + 0.0124473\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.811973:  86%|########5 | 6/7 [00:00<00:00,  6.32it/s][I 2023-12-02 14:19:55,626] Trial 5 finished with value: 0.8119734592897189 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.8119734592897189.\n",
      "feature_fraction, val_score: 0.811973: 100%|##########| 7/7 [00:01<00:00,  6.47it/s][I 2023-12-02 14:19:55,773] Trial 6 finished with value: 0.811743583536545 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 0.8119734592897189.\n",
      "feature_fraction, val_score: 0.811973: 100%|##########| 7/7 [00:01<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid auc: 0.811973 + 0.0141784\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tcv_agg's valid auc: 0.811744 + 0.0124473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.811973:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.811973:   5%|5         | 1/20 [00:00<00:05,  3.46it/s][I 2023-12-02 14:19:56,068] Trial 7 finished with value: 0.8015661908955412 and parameters: {'num_leaves': 93}. Best is trial 7 with value: 0.8015661908955412.\n",
      "num_leaves, val_score: 0.811973:   5%|5         | 1/20 [00:00<00:05,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tcv_agg's valid auc: 0.801566 + 0.0168223\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.811973:  10%|#         | 2/20 [00:00<00:06,  2.61it/s][I 2023-12-02 14:19:56,518] Trial 8 finished with value: 0.8000020677514424 and parameters: {'num_leaves': 109}. Best is trial 7 with value: 0.8015661908955412.\n",
      "num_leaves, val_score: 0.811973:  10%|#         | 2/20 [00:00<00:06,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tcv_agg's valid auc: 0.800002 + 0.0160903\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.811973:  15%|#5        | 3/20 [00:01<00:07,  2.24it/s][I 2023-12-02 14:19:57,039] Trial 9 finished with value: 0.7880454058549177 and parameters: {'num_leaves': 220}. Best is trial 7 with value: 0.8015661908955412.\n",
      "num_leaves, val_score: 0.815785:  20%|##        | 4/20 [00:01<00:05,  3.13it/s][I 2023-12-02 14:19:57,162] Trial 10 finished with value: 0.8157850926896042 and parameters: {'num_leaves': 8}. Best is trial 10 with value: 0.8157850926896042.\n",
      "num_leaves, val_score: 0.815785:  20%|##        | 4/20 [00:01<00:05,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tcv_agg's valid auc: 0.788045 + 0.0159288\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tcv_agg's valid auc: 0.815785 + 0.0133616\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816353:  25%|##5       | 5/20 [00:01<00:04,  3.59it/s][I 2023-12-02 14:19:57,368] Trial 11 finished with value: 0.8163529398578591 and parameters: {'num_leaves': 3}. Best is trial 11 with value: 0.8163529398578591.\n",
      "num_leaves, val_score: 0.816353:  30%|###       | 6/20 [00:01<00:03,  4.51it/s][I 2023-12-02 14:19:57,482] Trial 12 finished with value: 0.8157850926896042 and parameters: {'num_leaves': 8}. Best is trial 11 with value: 0.8163529398578591.\n",
      "num_leaves, val_score: 0.816353:  30%|###       | 6/20 [00:01<00:03,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's valid auc: 0.816328 + 0.0115621\n",
      "Early stopping, best iteration is:\n",
      "[97]\tcv_agg's valid auc: 0.816353 + 0.0115869\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tcv_agg's valid auc: 0.815785 + 0.0133616\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  35%|###5      | 7/20 [00:01<00:02,  4.53it/s][I 2023-12-02 14:19:57,697] Trial 13 finished with value: 0.8164596917556428 and parameters: {'num_leaves': 2}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  35%|###5      | 7/20 [00:01<00:02,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's valid auc: 0.81615 + 0.0118416\n",
      "Early stopping, best iteration is:\n",
      "[131]\tcv_agg's valid auc: 0.81646 + 0.0118616\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  40%|####      | 8/20 [00:02<00:02,  4.50it/s][I 2023-12-02 14:19:57,926] Trial 14 finished with value: 0.8164596917556428 and parameters: {'num_leaves': 2}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  40%|####      | 8/20 [00:02<00:02,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's valid auc: 0.81615 + 0.0118416\n",
      "Early stopping, best iteration is:\n",
      "[131]\tcv_agg's valid auc: 0.81646 + 0.0118616\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  45%|####5     | 9/20 [00:02<00:02,  4.43it/s][I 2023-12-02 14:19:58,159] Trial 15 finished with value: 0.8073661577905706 and parameters: {'num_leaves': 64}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  45%|####5     | 9/20 [00:02<00:02,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tcv_agg's valid auc: 0.807366 + 0.0153679\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  50%|#####     | 10/20 [00:02<00:03,  3.07it/s][I 2023-12-02 14:19:58,710] Trial 16 finished with value: 0.7927844369443411 and parameters: {'num_leaves': 199}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  50%|#####     | 10/20 [00:02<00:03,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tcv_agg's valid auc: 0.792784 + 0.0157811\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  55%|#####5    | 11/20 [00:03<00:02,  3.37it/s][I 2023-12-02 14:19:58,939] Trial 17 finished with value: 0.8071907190235585 and parameters: {'num_leaves': 56}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  55%|#####5    | 11/20 [00:03<00:02,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid auc: 0.807191 + 0.0140321\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  60%|######    | 12/20 [00:03<00:03,  2.52it/s][I 2023-12-02 14:19:59,568] Trial 18 finished with value: 0.7953851096143054 and parameters: {'num_leaves': 178}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  60%|######    | 12/20 [00:03<00:03,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tcv_agg's valid auc: 0.795385 + 0.0132963\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  65%|######5   | 13/20 [00:04<00:02,  2.89it/s][I 2023-12-02 14:19:59,795] Trial 19 finished with value: 0.8088345552857064 and parameters: {'num_leaves': 51}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  65%|######5   | 13/20 [00:04<00:02,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tcv_agg's valid auc: 0.808835 + 0.0147853\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  70%|#######   | 14/20 [00:04<00:02,  2.52it/s][I 2023-12-02 14:20:00,313] Trial 20 finished with value: 0.7971175371396737 and parameters: {'num_leaves': 146}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  75%|#######5  | 15/20 [00:04<00:01,  3.14it/s][I 2023-12-02 14:20:00,448] Trial 21 finished with value: 0.8160633693115752 and parameters: {'num_leaves': 6}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  75%|#######5  | 15/20 [00:04<00:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tcv_agg's valid auc: 0.797118 + 0.0152446\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tcv_agg's valid auc: 0.816063 + 0.0118226\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  80%|########  | 16/20 [00:04<00:01,  3.55it/s][I 2023-12-02 14:20:00,643] Trial 22 finished with value: 0.8119734592897189 and parameters: {'num_leaves': 31}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  85%|########5 | 17/20 [00:05<00:00,  4.06it/s][I 2023-12-02 14:20:00,808] Trial 23 finished with value: 0.8114021796303147 and parameters: {'num_leaves': 36}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  85%|########5 | 17/20 [00:05<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid auc: 0.811973 + 0.0141784\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tcv_agg's valid auc: 0.811402 + 0.0141163\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460:  90%|######### | 18/20 [00:05<00:00,  3.76it/s][I 2023-12-02 14:20:01,119] Trial 24 finished with value: 0.8027079822639049 and parameters: {'num_leaves': 82}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  95%|#########5| 19/20 [00:05<00:00,  4.28it/s][I 2023-12-02 14:20:01,277] Trial 25 finished with value: 0.8116748988273533 and parameters: {'num_leaves': 25}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460:  95%|#########5| 19/20 [00:05<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tcv_agg's valid auc: 0.802708 + 0.0168371\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tcv_agg's valid auc: 0.811675 + 0.0142244\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816460: 100%|##########| 20/20 [00:05<00:00,  4.49it/s][I 2023-12-02 14:20:01,474] Trial 26 finished with value: 0.8163529398578591 and parameters: {'num_leaves': 3}. Best is trial 13 with value: 0.8164596917556428.\n",
      "num_leaves, val_score: 0.816460: 100%|##########| 20/20 [00:05<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's valid auc: 0.816328 + 0.0115621\n",
      "Early stopping, best iteration is:\n",
      "[97]\tcv_agg's valid auc: 0.816353 + 0.0115869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tcv_agg's valid auc: 0.815771 + 0.012549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  10%|#         | 1/10 [00:00<00:01,  6.02it/s][I 2023-12-02 14:20:01,651] Trial 27 finished with value: 0.8157710004356359 and parameters: {'bagging_fraction': 0.7754763385895199, 'bagging_freq': 5}. Best is trial 27 with value: 0.8157710004356359.\n",
      "bagging, val_score: 0.816460:  10%|#         | 1/10 [00:00<00:01,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.815724 + 0.0126885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  20%|##        | 2/10 [00:00<00:01,  4.35it/s][I 2023-12-02 14:20:01,926] Trial 28 finished with value: 0.8160703616353662 and parameters: {'bagging_fraction': 0.42969941834220704, 'bagging_freq': 1}. Best is trial 28 with value: 0.8160703616353662.\n",
      "bagging, val_score: 0.816460:  20%|##        | 2/10 [00:00<00:01,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[118]\tcv_agg's valid auc: 0.81607 + 0.0125219\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816181 + 0.0117921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  30%|###       | 3/10 [00:00<00:01,  4.07it/s][I 2023-12-02 14:20:02,190] Trial 29 finished with value: 0.8164565937099952 and parameters: {'bagging_fraction': 0.9979492259363931, 'bagging_freq': 6}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460:  30%|###       | 3/10 [00:00<00:01,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tcv_agg's valid auc: 0.816457 + 0.011801\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816207 + 0.0117087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  40%|####      | 4/10 [00:00<00:01,  4.12it/s][I 2023-12-02 14:20:02,430] Trial 30 finished with value: 0.8164292166274691 and parameters: {'bagging_fraction': 0.9950696018863349, 'bagging_freq': 7}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460:  40%|####      | 4/10 [00:00<00:01,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[133]\tcv_agg's valid auc: 0.816429 + 0.0117042\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816056 + 0.0119249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  50%|#####     | 5/10 [00:01<00:01,  4.01it/s][I 2023-12-02 14:20:02,690] Trial 31 finished with value: 0.8162805595086968 and parameters: {'bagging_fraction': 0.9675003201959101, 'bagging_freq': 7}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460:  50%|#####     | 5/10 [00:01<00:01,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tcv_agg's valid auc: 0.816281 + 0.0118126\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816324 + 0.0117697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  60%|######    | 6/10 [00:01<00:00,  4.22it/s][I 2023-12-02 14:20:02,902] Trial 32 finished with value: 0.8164071074755903 and parameters: {'bagging_fraction': 0.998391092042479, 'bagging_freq': 7}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460:  60%|######    | 6/10 [00:01<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[107]\tcv_agg's valid auc: 0.816407 + 0.0117549\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.81601 + 0.0117685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  70%|#######   | 7/10 [00:01<00:00,  4.00it/s][I 2023-12-02 14:20:03,179] Trial 33 finished with value: 0.8162296733975138 and parameters: {'bagging_fraction': 0.9849729771292778, 'bagging_freq': 5}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460:  70%|#######   | 7/10 [00:01<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tcv_agg's valid auc: 0.81623 + 0.0117727\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.815985 + 0.0122398\n",
      "Early stopping, best iteration is:\n",
      "[97]\tcv_agg's valid auc: 0.816054 + 0.0121404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  80%|########  | 8/10 [00:01<00:00,  4.32it/s][I 2023-12-02 14:20:03,372] Trial 34 finished with value: 0.8160537053123132 and parameters: {'bagging_fraction': 0.8372908882949636, 'bagging_freq': 7}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460:  80%|########  | 8/10 [00:02<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.815522 + 0.012141\n",
      "Early stopping, best iteration is:\n",
      "[132]\tcv_agg's valid auc: 0.816039 + 0.0123133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816460:  90%|######### | 9/10 [00:02<00:00,  4.25it/s][I 2023-12-02 14:20:03,615] Trial 35 finished with value: 0.8160388037463455 and parameters: {'bagging_fraction': 0.8446211476378838, 'bagging_freq': 5}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460: 100%|##########| 10/10 [00:02<00:00,  4.49it/s][I 2023-12-02 14:20:03,810] Trial 36 finished with value: 0.8160381674575433 and parameters: {'bagging_fraction': 0.6610692380681304, 'bagging_freq': 3}. Best is trial 29 with value: 0.8164565937099952.\n",
      "bagging, val_score: 0.816460: 100%|##########| 10/10 [00:02<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.815902 + 0.0118724\n",
      "Early stopping, best iteration is:\n",
      "[92]\tcv_agg's valid auc: 0.816038 + 0.0120862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816460:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816460:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's valid auc: 0.81615 + 0.0118416\n",
      "Early stopping, best iteration is:\n",
      "[131]\tcv_agg's valid auc: 0.81646 + 0.0118616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816460:  33%|###3      | 1/3 [00:00<00:00,  4.76it/s][I 2023-12-02 14:20:04,025] Trial 37 finished with value: 0.8164596917556428 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.8164596917556428.\n",
      "feature_fraction_stage2, val_score: 0.816460:  33%|###3      | 1/3 [00:00<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.81615 + 0.0118416\n",
      "Early stopping, best iteration is:\n",
      "[131]\tcv_agg's valid auc: 0.81646 + 0.0118616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816460:  67%|######6   | 2/3 [00:00<00:00,  4.43it/s][I 2023-12-02 14:20:04,263] Trial 38 finished with value: 0.8164596917556428 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.8164596917556428.\n",
      "feature_fraction_stage2, val_score: 0.816460:  67%|######6   | 2/3 [00:00<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816460:  67%|######6   | 2/3 [00:00<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's valid auc: 0.81615 + 0.0118416\n",
      "Early stopping, best iteration is:\n",
      "[131]\tcv_agg's valid auc: 0.81646 + 0.0118616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816460: 100%|##########| 3/3 [00:00<00:00,  4.37it/s][I 2023-12-02 14:20:04,494] Trial 39 finished with value: 0.8164596917556428 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.8164596917556428.\n",
      "feature_fraction_stage2, val_score: 0.816460: 100%|##########| 3/3 [00:00<00:00,  4.40it/s]\n",
      "regularization_factors, val_score: 0.816460:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.81615 + 0.0118416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816460:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[131]\tcv_agg's valid auc: 0.81646 + 0.0118616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816460:   5%|5         | 1/20 [00:00<00:04,  4.37it/s][I 2023-12-02 14:20:04,728] Trial 40 finished with value: 0.8164596917556428 and parameters: {'lambda_l1': 4.280811824990435e-08, 'lambda_l2': 0.000115547547230329}. Best is trial 40 with value: 0.8164596917556428.\n",
      "regularization_factors, val_score: 0.816460:   5%|5         | 1/20 [00:00<00:04,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816048 + 0.0118562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816469:  10%|#         | 2/20 [00:00<00:04,  4.05it/s][I 2023-12-02 14:20:04,986] Trial 41 finished with value: 0.8164685866061872 and parameters: {'lambda_l1': 6.296081730960976, 'lambda_l2': 7.912950131239758}. Best is trial 41 with value: 0.8164685866061872.\n",
      "regularization_factors, val_score: 0.816469:  10%|#         | 2/20 [00:00<00:04,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tcv_agg's valid auc: 0.816469 + 0.0118038\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816108 + 0.0118965\n",
      "Early stopping, best iteration is:\n",
      "[119]\tcv_agg's valid auc: 0.816308 + 0.0118431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816469:  15%|#5        | 3/20 [00:00<00:03,  4.38it/s][I 2023-12-02 14:20:05,194] Trial 42 finished with value: 0.8163084589373651 and parameters: {'lambda_l1': 5.58268869169478, 'lambda_l2': 7.765051934866736}. Best is trial 41 with value: 0.8164685866061872.\n",
      "regularization_factors, val_score: 0.816469:  15%|#5        | 3/20 [00:00<00:03,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816147 + 0.0119053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816474:  20%|##        | 4/20 [00:00<00:03,  4.23it/s][I 2023-12-02 14:20:05,441] Trial 43 finished with value: 0.816474467903052 and parameters: {'lambda_l1': 4.971413050686477, 'lambda_l2': 4.315325829401123}. Best is trial 43 with value: 0.816474467903052.\n",
      "regularization_factors, val_score: 0.816474:  20%|##        | 4/20 [00:00<00:03,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tcv_agg's valid auc: 0.816474 + 0.0117442\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816136 + 0.0119052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816479:  25%|##5       | 5/20 [00:01<00:03,  4.14it/s][I 2023-12-02 14:20:05,691] Trial 44 finished with value: 0.8164788319065831 and parameters: {'lambda_l1': 3.1972769649659645, 'lambda_l2': 8.91373902004538}. Best is trial 44 with value: 0.8164788319065831.\n",
      "regularization_factors, val_score: 0.816479:  25%|##5       | 5/20 [00:01<00:03,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[156]\tcv_agg's valid auc: 0.816479 + 0.0117505\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816033 + 0.0118233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816479:  30%|###       | 6/20 [00:01<00:03,  3.91it/s][I 2023-12-02 14:20:05,978] Trial 45 finished with value: 0.8163877894016689 and parameters: {'lambda_l1': 8.987660581665905, 'lambda_l2': 9.291399251757792}. Best is trial 44 with value: 0.8164788319065831.\n",
      "regularization_factors, val_score: 0.816479:  30%|###       | 6/20 [00:01<00:03,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[174]\tcv_agg's valid auc: 0.816388 + 0.0117097\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816106 + 0.0118498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816485:  35%|###5      | 7/20 [00:01<00:03,  3.81it/s][I 2023-12-02 14:20:06,251] Trial 46 finished with value: 0.81648502463698 and parameters: {'lambda_l1': 5.55905183715814, 'lambda_l2': 6.597850192968186}. Best is trial 46 with value: 0.81648502463698.\n",
      "regularization_factors, val_score: 0.816485:  35%|###5      | 7/20 [00:01<00:03,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[162]\tcv_agg's valid auc: 0.816485 + 0.0117886\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816091 + 0.0118226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816485:  40%|####      | 8/20 [00:01<00:03,  3.97it/s][I 2023-12-02 14:20:06,482] Trial 47 finished with value: 0.8164235295166844 and parameters: {'lambda_l1': 7.265999504157439, 'lambda_l2': 8.211583427603388}. Best is trial 46 with value: 0.81648502463698.\n",
      "regularization_factors, val_score: 0.816492:  40%|####      | 8/20 [00:02<00:03,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tcv_agg's valid auc: 0.816424 + 0.0117881\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816298 + 0.0118403\n",
      "Early stopping, best iteration is:\n",
      "[120]\tcv_agg's valid auc: 0.816492 + 0.0118424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816492:  45%|####5     | 9/20 [00:02<00:02,  4.20it/s][I 2023-12-02 14:20:06,689] Trial 48 finished with value: 0.8164918277546528 and parameters: {'lambda_l1': 2.9589380882420255, 'lambda_l2': 5.258147892738278}. Best is trial 48 with value: 0.8164918277546528.\n",
      "regularization_factors, val_score: 0.816492:  50%|#####     | 10/20 [00:02<00:02,  4.36it/s][I 2023-12-02 14:20:06,900] Trial 49 finished with value: 0.8163544668075803 and parameters: {'lambda_l1': 4.127507045581567, 'lambda_l2': 6.23596095363659}. Best is trial 48 with value: 0.8164918277546528.\n",
      "regularization_factors, val_score: 0.816492:  50%|#####     | 10/20 [00:02<00:02,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816147 + 0.0118811\n",
      "Early stopping, best iteration is:\n",
      "[121]\tcv_agg's valid auc: 0.816354 + 0.0118242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816524:  50%|#####     | 10/20 [00:02<00:02,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816369 + 0.011811\n",
      "Early stopping, best iteration is:\n",
      "[126]\tcv_agg's valid auc: 0.816524 + 0.0117799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816524:  55%|#####5    | 11/20 [00:02<00:02,  4.43it/s][I 2023-12-02 14:20:07,115] Trial 50 finished with value: 0.8165239042156232 and parameters: {'lambda_l1': 1.1654373000816913, 'lambda_l2': 2.062585894160504}. Best is trial 50 with value: 0.8165239042156232.\n",
      "regularization_factors, val_score: 0.816533:  55%|#####5    | 11/20 [00:02<00:02,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816323 + 0.0118269\n",
      "Early stopping, best iteration is:\n",
      "[129]\tcv_agg's valid auc: 0.816533 + 0.0118295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  60%|######    | 12/20 [00:02<00:01,  4.46it/s][I 2023-12-02 14:20:07,336] Trial 51 finished with value: 0.8165328036699602 and parameters: {'lambda_l1': 1.9317001406011016, 'lambda_l2': 3.094407820496894}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  60%|######    | 12/20 [00:02<00:01,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.81616 + 0.0118792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  65%|######5   | 13/20 [00:03<00:01,  4.28it/s][I 2023-12-02 14:20:07,595] Trial 52 finished with value: 0.8164880253414148 and parameters: {'lambda_l1': 0.44944356864901885, 'lambda_l2': 0.31461965145079995}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  65%|######5   | 13/20 [00:03<00:01,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[148]\tcv_agg's valid auc: 0.816488 + 0.0118232\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816142 + 0.0118416\n",
      "Early stopping, best iteration is:\n",
      "[131]\tcv_agg's valid auc: 0.816444 + 0.0118876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  70%|#######   | 14/20 [00:03<00:01,  4.38it/s][I 2023-12-02 14:20:07,809] Trial 53 finished with value: 0.8164435897914121 and parameters: {'lambda_l1': 0.07480046982662339, 'lambda_l2': 0.11210009004175256}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  70%|#######   | 14/20 [00:03<00:01,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816156 + 0.0118559\n",
      "Early stopping, best iteration is:\n",
      "[129]\tcv_agg's valid auc: 0.816442 + 0.0118834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  75%|#######5  | 15/20 [00:03<00:01,  4.35it/s][I 2023-12-02 14:20:08,043] Trial 54 finished with value: 0.816441699990396 and parameters: {'lambda_l1': 0.18377062132444583, 'lambda_l2': 0.13906533825347042}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  75%|#######5  | 15/20 [00:03<00:01,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816144 + 0.0118569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  80%|########  | 16/20 [00:03<00:00,  4.34it/s][I 2023-12-02 14:20:08,275] Trial 55 finished with value: 0.8164637676486068 and parameters: {'lambda_l1': 0.18006452477325394, 'lambda_l2': 0.10643026267873683}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  80%|########  | 16/20 [00:03<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tcv_agg's valid auc: 0.816464 + 0.011868\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816164 + 0.0118757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  85%|########5 | 17/20 [00:04<00:00,  4.16it/s][I 2023-12-02 14:20:08,539] Trial 56 finished with value: 0.816461708959341 and parameters: {'lambda_l1': 0.3538487175870835, 'lambda_l2': 2.2592981878149705e-08}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  85%|########5 | 17/20 [00:04<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[153]\tcv_agg's valid auc: 0.816462 + 0.0118053\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816166 + 0.0118751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  90%|######### | 18/20 [00:04<00:00,  4.09it/s][I 2023-12-02 14:20:08,792] Trial 57 finished with value: 0.8164802480753 and parameters: {'lambda_l1': 0.2478256714265829, 'lambda_l2': 0.5416299460294494}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  90%|######### | 18/20 [00:04<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[149]\tcv_agg's valid auc: 0.81648 + 0.0118332\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816184 + 0.0118677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533:  95%|#########5| 19/20 [00:04<00:00,  4.07it/s][I 2023-12-02 14:20:09,042] Trial 58 finished with value: 0.8164872402051738 and parameters: {'lambda_l1': 0.2421074570676747, 'lambda_l2': 0.3914267306761446}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533:  95%|#########5| 19/20 [00:04<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[152]\tcv_agg's valid auc: 0.816487 + 0.0118136\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816171 + 0.0118761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816533: 100%|##########| 20/20 [00:04<00:00,  4.16it/s][I 2023-12-02 14:20:09,269] Trial 59 finished with value: 0.8164452692822172 and parameters: {'lambda_l1': 0.006805220499460626, 'lambda_l2': 0.4707565355953241}. Best is trial 51 with value: 0.8165328036699602.\n",
      "regularization_factors, val_score: 0.816533: 100%|##########| 20/20 [00:04<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tcv_agg's valid auc: 0.816445 + 0.011899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.816533:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816323 + 0.0118269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.816533:  20%|##        | 1/5 [00:00<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tcv_agg's valid auc: 0.816533 + 0.0118295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-02 14:20:09,498] Trial 60 finished with value: 0.8165328036699602 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.8165328036699602.\n",
      "min_child_samples, val_score: 0.816533:  20%|##        | 1/5 [00:00<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816323 + 0.0118269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.816533:  20%|##        | 1/5 [00:00<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tcv_agg's valid auc: 0.816533 + 0.0118295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.816533:  40%|####      | 2/5 [00:00<00:00,  4.60it/s][I 2023-12-02 14:20:09,713] Trial 61 finished with value: 0.8165328036699602 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.8165328036699602.\n",
      "min_child_samples, val_score: 0.816533:  40%|####      | 2/5 [00:00<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.81632 + 0.0118292\n",
      "Early stopping, best iteration is:\n",
      "[129]\tcv_agg's valid auc: 0.816518 + 0.0117893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.816533:  60%|######    | 3/5 [00:00<00:00,  4.72it/s][I 2023-12-02 14:20:09,919] Trial 62 finished with value: 0.8165180555032852 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.8165328036699602.\n",
      "min_child_samples, val_score: 0.816533:  60%|######    | 3/5 [00:00<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816323 + 0.0118269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.816533:  80%|########  | 4/5 [00:00<00:00,  4.31it/s][I 2023-12-02 14:20:10,181] Trial 63 finished with value: 0.8165328036699602 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.8165328036699602.\n",
      "min_child_samples, val_score: 0.816533:  80%|########  | 4/5 [00:00<00:00,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tcv_agg's valid auc: 0.816533 + 0.0118295\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tcv_agg's valid auc: 0.816323 + 0.0118269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.816533: 100%|##########| 5/5 [00:01<00:00,  4.28it/s][I 2023-12-02 14:20:10,417] Trial 64 finished with value: 0.8165328036699602 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.8165328036699602.\n",
      "min_child_samples, val_score: 0.816533: 100%|##########| 5/5 [00:01<00:00,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tcv_agg's valid auc: 0.816533 + 0.0118295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "lgb_params = {\n",
    "    'objective':'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbosity':-1,\n",
    "}\n",
    "tuner_cv = lgb.LightGBMTunerCV(\n",
    "    lgb_params, lgb_train,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True),\n",
    "                lgb.log_evaluation(100)],\n",
    "    return_cvbooster=True,\n",
    "    folds=folds\n",
    ")\n",
    "\n",
    "tuner_cv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "booster must be Booster or LGBMModel.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\masak\\workspace\\lab\\thesis_data2\\learning_process\\notebook\\lgb_tune2.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/masak/workspace/lab/thesis_data2/learning_process/notebook/lgb_tune2.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/masak/workspace/lab/thesis_data2/learning_process/notebook/lgb_tune2.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m tuner_cv\u001b[39m.\u001b[39mget_best_booster()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/masak/workspace/lab/thesis_data2/learning_process/notebook/lgb_tune2.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lgb\u001b[39m.\u001b[39;49mplot_importance(model, figsize\u001b[39m=\u001b[39;49m(\u001b[39m8\u001b[39;49m,\u001b[39m4\u001b[39;49m), max_num_features\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, importance_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\masak\\anaconda3\\envs\\test\\lib\\site-packages\\lightgbm\\plotting.py:117\u001b[0m, in \u001b[0;36mplot_importance\u001b[1;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, importance_type, max_num_features, ignore_zero, figsize, dpi, grid, precision, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         importance_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mbooster must be Booster or LGBMModel.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    119\u001b[0m importance \u001b[39m=\u001b[39m booster\u001b[39m.\u001b[39mfeature_importance(importance_type\u001b[39m=\u001b[39mimportance_type)\n\u001b[0;32m    120\u001b[0m feature_name \u001b[39m=\u001b[39m booster\u001b[39m.\u001b[39mfeature_name()\n",
      "\u001b[1;31mTypeError\u001b[0m: booster must be Booster or LGBMModel."
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "model = tuner_cv.get_best_booster()\n",
    "lgb.plot_importance(model, figsize=(8,4), max_num_features=5, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.5246511531353015\n",
      "Best params:\n",
      "{'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 3.5658465377646046e-07, 'lambda_l2': 0.017254549195087253, 'num_leaves': 4, 'feature_fraction': 1.0, 'bagging_fraction': 0.9668243143969556, 'bagging_freq': 1, 'min_child_samples': 25}\n",
      "[0.56519782 0.84614833 0.21456144 ... 0.4854053  0.11443475 0.20948806]\n",
      "0.8188157668992337\n",
      "0.6251302477746175\n"
     ]
    }
   ],
   "source": [
    "#openstack auc \n",
    "print(f'Best score: {tuner_cv.best_score}')\n",
    "print('Best params:')\n",
    "print(tuner_cv.best_params)\n",
    "model = tuner_cv.get_best_booster()\n",
    "pred = model.predict(np.array(te_data[0]), num_iteration=model.best_iteration)\n",
    "mean_pred = np.mean(pred, axis=0)\n",
    "print(mean_pred)\n",
    "print(roc_auc_score(te_data[1], mean_pred))\n",
    "print(log_loss(te_data[1], mean_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8179830922461786\n",
      "Best params:\n",
      "{'objective': 'binary', 'metric': 'auc', 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 0.01754458037831149, 'lambda_l2': 3.297456196622105e-05, 'num_leaves': 2, 'feature_fraction': 1.0, 'bagging_fraction': 0.5258824582300985, 'bagging_freq': 1, 'min_child_samples': 20}\n",
      "[0.68179457 0.85721752 0.18221707 ... 0.50415918 0.1448258  0.17491612]\n",
      "0.817103682946357\n",
      "0.6809611902310441\n"
     ]
    }
   ],
   "source": [
    "#openstack auc \n",
    "print(f'Best score: {tuner_cv.best_score}')\n",
    "print('Best params:')\n",
    "print(tuner_cv.best_params)\n",
    "model = tuner_cv.get_best_booster()\n",
    "pred = model.predict(np.array(te_data[0]), num_iteration=model.best_iteration)\n",
    "mean_pred = np.mean(pred, axis=0)\n",
    "print(mean_pred)\n",
    "print(roc_auc_score(te_data[1], mean_pred))\n",
    "print(log_loss(te_data[1], mean_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8165328036699602\n",
      "Best params:\n",
      "{'objective': 'binary', 'metric': 'auc', 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 1.9317001406011016, 'lambda_l2': 3.094407820496894, 'num_leaves': 2, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20}\n",
      "[0.36960416 0.50902352 0.14799592 ... 0.70303968 0.61321876 0.18555734]\n",
      "0.7655688245292944\n",
      "0.5847515942649286\n"
     ]
    }
   ],
   "source": [
    "#qt auc \n",
    "print(f'Best score: {tuner_cv.best_score}')\n",
    "print('Best params:')\n",
    "print(tuner_cv.best_params)\n",
    "model = tuner_cv.get_best_booster()\n",
    "pred = model.predict(np.array(te_data[0]), num_iteration=model.best_iteration)\n",
    "mean_pred = np.mean(pred, axis=0)\n",
    "print(mean_pred)\n",
    "print(roc_auc_score(te_data[1], mean_pred))\n",
    "print(log_loss(te_data[1], mean_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
