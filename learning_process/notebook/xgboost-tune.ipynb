{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train, tune\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from ray.tune.integration.xgboost import TuneReportCheckpointCallback\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-19 14:37:41</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:17.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.7/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=10<br>Bracket: Iter 8.000: -0.4698844304692809 | Iter 4.000: -0.47710270865872784 | Iter 2.000: -0.4841591065634671 | Iter 1.000: -0.4977473997338687<br>Logical resource usage: 1.0/24 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  alpha</th><th style=\"text-align: right;\">  eta</th><th style=\"text-align: right;\">  lambda</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  eval-logloss</th><th style=\"text-align: right;\">  eval-auc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_commit_b7444_00000</td><td>TERMINATED</td><td>127.0.0.1:41516</td><td style=\"text-align: right;\">  1e-05</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   1e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.793 </td><td style=\"text-align: right;\">      0.498275</td><td style=\"text-align: right;\">  0.684298</td></tr>\n",
       "<tr><td>train_commit_b7444_00001</td><td>TERMINATED</td><td>127.0.0.1:24916</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\"> 100    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6355</td><td style=\"text-align: right;\">      0.499096</td><td style=\"text-align: right;\">  0.654574</td></tr>\n",
       "<tr><td>train_commit_b7444_00002</td><td>TERMINATED</td><td>127.0.0.1:42780</td><td style=\"text-align: right;\">  1e-05</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">   0.1  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         12.7282</td><td style=\"text-align: right;\">      0.46791 </td><td style=\"text-align: right;\">  0.711884</td></tr>\n",
       "<tr><td>train_commit_b7444_00003</td><td>TERMINATED</td><td>127.0.0.1:30852</td><td style=\"text-align: right;\">  1    </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">   1    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.8298</td><td style=\"text-align: right;\">      0.49836 </td><td style=\"text-align: right;\">  0.679953</td></tr>\n",
       "<tr><td>train_commit_b7444_00004</td><td>TERMINATED</td><td>127.0.0.1:22808</td><td style=\"text-align: right;\">100    </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\"> 100    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6301</td><td style=\"text-align: right;\">      0.497219</td><td style=\"text-align: right;\">  0.644176</td></tr>\n",
       "<tr><td>train_commit_b7444_00005</td><td>TERMINATED</td><td>127.0.0.1:29072</td><td style=\"text-align: right;\">  0.1  </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">   1    </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         12.7392</td><td style=\"text-align: right;\">      0.485241</td><td style=\"text-align: right;\">  0.706261</td></tr>\n",
       "<tr><td>train_commit_b7444_00006</td><td>TERMINATED</td><td>127.0.0.1:34128</td><td style=\"text-align: right;\">100    </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">   0.01 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.7415</td><td style=\"text-align: right;\">      0.496166</td><td style=\"text-align: right;\">  0.654848</td></tr>\n",
       "<tr><td>train_commit_b7444_00007</td><td>TERMINATED</td><td>127.0.0.1:40092</td><td style=\"text-align: right;\">  1    </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   1    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.8867</td><td style=\"text-align: right;\">      0.499063</td><td style=\"text-align: right;\">  0.679953</td></tr>\n",
       "<tr><td>train_commit_b7444_00008</td><td>TERMINATED</td><td>127.0.0.1:40496</td><td style=\"text-align: right;\">  1e-05</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">   0.1  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         11.1195</td><td style=\"text-align: right;\">      0.46791 </td><td style=\"text-align: right;\">  0.711884</td></tr>\n",
       "<tr><td>train_commit_b7444_00009</td><td>TERMINATED</td><td>127.0.0.1:42196</td><td style=\"text-align: right;\">100    </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">   1    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.1122</td><td style=\"text-align: right;\">      0.499109</td><td style=\"text-align: right;\">  0.654848</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_commit pid=40496)\u001b[0m [14:37:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "\u001b[36m(train_commit pid=40496)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/masak/ray_results/train_commit_2023-11-19_14-37-23/train_commit_b7444_00008_8_alpha=0.0000,eta=0.1000,lambda=0.1000_2023-11-19_14-37-23/checkpoint_000000)\n",
      "2023-11-19 14:37:39,958\tWARNING util.py:202 -- The `callbacks.on_trial_result` operation took 0.574 s, which may be a performance bottleneck.\n",
      "2023-11-19 14:37:40,061\tWARNING util.py:202 -- The `process_trial_result` operation took 0.831 s, which may be a performance bottleneck.\n",
      "2023-11-19 14:37:40,063\tWARNING util.py:202 -- Processing trial results took 0.833 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-11-19 14:37:40,064\tWARNING util.py:202 -- The `process_trial_result` operation took 0.927 s, which may be a performance bottleneck.\n",
      "2023-11-19 14:37:41,210\tINFO tune.py:1047 -- Total run time: 17.45 seconds (17.27 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['eval-logloss', 'eval-auc', 'timestamp', 'checkpoint_dir_name', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'experiment_tag'])\n",
      "Best model parameters: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.85, 'eta': 0.1, 'colsample_bytree': 0.7, 'gamma': 0.06, 'alpha': 1e-05, 'lambda': 0.1}\n",
      "Best model logloss: 0.4679\n",
      "Best model total auc: 0.7119\n",
      "Test data auc 0.7580\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.tune.integration.xgboost import TuneReportCheckpointCallback\n",
    "\n",
    "\n",
    "def train_commit(config: dict):\n",
    "\n",
    "    with open('C:/Users/masak/workspace/lab/thesis_data2/learning_process/resource/openstack_train.pkl', 'rb') as f_train:\n",
    "        tr_dataset = pickle.load(f_train)\n",
    "    \n",
    "    va_period_list = [3]\n",
    "    for va_period in va_period_list:\n",
    "        tr_index = [index for index, value in enumerate(tr_dataset[1]) if value != va_period]\n",
    "        va_index = [index for index, value in enumerate(tr_dataset[1]) if value == va_period]\n",
    "        tr_x = [tr_dataset[4][i] for i in tr_index]\n",
    "        tr_y = [tr_dataset[5][i] for i in tr_index]\n",
    "        va_x = [tr_dataset[4][i] for i in va_index]\n",
    "        va_y = [tr_dataset[5][i] for i in va_index]\n",
    "    \n",
    "    # Build input matrices for XGBoost\n",
    "    train_set = xgb.DMatrix(tr_x, label=tr_y)\n",
    "    valid_set = xgb.DMatrix(va_x, label=va_y)\n",
    "    # Train the classifier, using the Tune callback\n",
    "    xgb.train(\n",
    "        config,\n",
    "        train_set,\n",
    "        evals=[(valid_set, \"eval\")],\n",
    "        verbose_eval=False,\n",
    "        callbacks=[TuneReportCheckpointCallback(filename=\"model.xgb\")],\n",
    "    )\n",
    "\n",
    "\n",
    "def get_best_model_checkpoint(results):\n",
    "    best_bst = xgb.Booster()\n",
    "    best_result = results.get_best_result()\n",
    "\n",
    "    with best_result.checkpoint.as_directory() as best_checkpoint_dir:\n",
    "        best_bst.load_model(os.path.join(best_checkpoint_dir, \"model.xgb\"))\n",
    "    print(best_result.metrics.keys())\n",
    "    auc = best_result.metrics[\"eval-auc\"]\n",
    "    print(f\"Best model parameters: {best_result.config}\")\n",
    "    print(f'Best model logloss: {best_result.metrics[\"eval-logloss\"]:.4f}')\n",
    "    print(f\"Best model total auc: {auc:.4f}\")\n",
    "    return best_bst\n",
    "\n",
    "\n",
    "def tune_xgboost(test=False):\n",
    "    # search_space = {\n",
    "    #     # You can mix constants with search space objects.\n",
    "    #     \"objective\": \"binary:logistic\",\n",
    "    #     \"eval_metric\": [\"logloss\", \"auc\"],\n",
    "    #     \"max_depth\": tune.randint(1, 9),\n",
    "    #     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "    #     \"subsample\": tune.uniform(0.5, 1.0),\n",
    "    #     \"eta\": tune.loguniform(1e-4, 1e-1),\n",
    "    # }\n",
    "    # search_space = {\n",
    "    #     \"objective\": \"binary:logistic\",\n",
    "    #     \"eval_metric\": [\"logloss\", \"auc\"],\n",
    "    #     \"max_depth\": tune.randint(3,9),\n",
    "    #     \"min_child_weight\" : tune.loguniform(0.1, 10),\n",
    "    #     \"subsample\" : tune.quniform(0.6, 0.95, 0.05),\n",
    "    #     \"eta\" : 0.1,\n",
    "    #     \"colsample_bytree\": tune.quniform(0.6, 0.95, 0.05),\n",
    "    #     \"gamma\" : tune.loguniform(1e-8, 1.0),\n",
    "    #     \"alpha\":0.0,\n",
    "    #     \"lambda\":1.0\n",
    "    # }\n",
    "    search_space = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"auc\"],\n",
    "        \"max_depth\": 8,\n",
    "        \"min_child_weight\" : 5,\n",
    "        \"subsample\" : 0.85,\n",
    "        \"eta\":tune.choice([0.1, 0.01, 0.001]),\n",
    "        \"colsample_bytree\": 0.7,\n",
    "        \"gamma\" : 0.06,\n",
    "        \"alpha\":tune.choice([1e-5, 1e-2, 0.1, 1, 100]),\n",
    "        \"lambda\":tune.choice([1e-5, 1e-2, 0.1, 1, 100])\n",
    "    }\n",
    "    # This will enable aggressive early stopping of bad trials.\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=10, grace_period=1, reduction_factor=2  # 10 training iterations\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        train_commit,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"eval-logloss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=1 if test else 10,\n",
    "        ),\n",
    "        param_space=search_space,\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "\n",
    "    return results\n",
    "\n",
    "results = tune_xgboost()\n",
    "\n",
    "# Load the best model checkpoint.\n",
    "best_bst = get_best_model_checkpoint(results)\n",
    "\n",
    "with open('../resource/openstack_test.pkl', 'rb') as f_test:\n",
    "    te_dataset = pickle.load(f_test)\n",
    "\n",
    "\n",
    "test = xgb.DMatrix(np.array(te_dataset[4]))\n",
    "\n",
    "# You could now do further predictions with\n",
    "pred = best_bst.predict(test)\n",
    "\n",
    "print(f'Test data auc {roc_auc_score(np.array(te_dataset[5]), pred):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
