{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "from pygments import lex\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.lexers import CppLexer\n",
    "from pygments.lexers import JavaLexer\n",
    "from pygments.lexers import CLexer\n",
    "from spiral import ronin\n",
    "from pygments.token import Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stopwords(list):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    tmp_list = [w for w in list if w not in stopset]\n",
    "    return tmp_list\n",
    "\n",
    "def stem_word(list):\n",
    "    stemmer  = stem.PorterStemmer()\n",
    "    tmp_list = [stemmer.stem(w) for w in list]\n",
    "    return tmp_list\n",
    "\n",
    "def tokenize_msg(text):\n",
    "    tmp_list = nltk.word_tokenize(text)\n",
    "    return tmp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token.Name.Builtin print\n",
      "Token.Punctuation (\n",
      "Token.Literal.String.Single '\n",
      "Token.Literal.String.Single Hello, world!\n",
      "Token.Literal.String.Single '\n",
      "Token.Punctuation )\n",
      "Token.Text.Whitespace \n",
      "\n",
      "['print', '(', '<literal>', '<literal>', '<literal>', ')']\n"
     ]
    }
   ],
   "source": [
    "#python\n",
    "# code = \"from torchtext.legacy import data\"\n",
    "code = \"print('Hello, world!')\"\n",
    "# code = \"a=2\"\n",
    "#cpp\n",
    "# code = '#include <private/qfilesystementry_p.h>'\n",
    "# code = \"return QGuiApplication::primaryScreen()->handle()->grabWindow(window, x, y, w, h);\"\n",
    "tokens = list(lex(code, PythonLexer()))\n",
    "# tokens = list(lex(code, CppLexer()))\n",
    "# tokens = list(lex(code, JavaLexer()))\n",
    "# tokens = list(lex(code, CLexer()))\n",
    "code_list = []\n",
    "for token in tokens:\n",
    "    print(token[0],token[1])\n",
    "    if token[0] in Token.Literal: \n",
    "        code_list.append('<literal>')\n",
    "    elif token[0] in Token.Name:\n",
    "        code_list.extend(['<num>' if tmp.isnumeric() else tmp.strip().lower() for tmp in ronin.split(token[1])])\n",
    "    elif token[0] in Token.Comment:\n",
    "        code_list.extend([ '<num>' if tmp.isnumeric() else tmp.strip().lower() for tmp in tokenize_msg(token[1]) for tmp in ronin.split(tmp)])\n",
    "    elif token[0] in Token.Text:\n",
    "        continue\n",
    "    else:\n",
    "        code_list.append(token[1].strip().lower())\n",
    "        \n",
    "print(code_list)\n",
    "\n",
    "# print(tokenize_msg(code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
