{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "project = 'openstack'\n",
    "is_its = 'in_its'\n",
    "with open('../resource/'+project+'_train.pkl', 'rb') as f_train, open('../resource/'+project+'_test.pkl', 'rb') as f_test:\n",
    "        tr_data = pickle.load(f_train)\n",
    "        te_data = pickle.load(f_test)\n",
    "pred_list = []\n",
    "kinds = ['train', 'test']\n",
    "models = ['lgb', 'code_cnn', 'msg_tf']\n",
    "for kind in kinds:\n",
    "    for model in models:\n",
    "        with open('../pred/'+is_its+'/'+project+'-'+model+'-'+'random'+'-'+kind+'.pkl', 'rb') as f:\n",
    "            pred_list.append(pickle.load(f))\n",
    "tr_pred = [[pred_list[0][j], pred_list[1][j], pred_list[2][j]] for j in range(len(pred_list[0]))]\n",
    "te_pred = [[pred_list[3][j], pred_list[4][j], pred_list[5][j]] for j in range(len(pred_list[3]))]                \n",
    "tr_data = [tr_pred, tr_data[5]]\n",
    "te_data = [te_pred, te_data[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "project = 'openstack'\n",
    "is_its = 'no_its'\n",
    "with open('../resource/'+project+'_train.pkl', 'rb') as f_train, open('../resource/'+project+'_test.pkl', 'rb') as f_test:\n",
    "        tr_data2 = pickle.load(f_train)\n",
    "        te_data2 = pickle.load(f_test)\n",
    "pred_list2 = []\n",
    "kinds = ['train', 'test']\n",
    "models = ['lgb', 'code_cnn', 'msg_tf']\n",
    "for kind in kinds:\n",
    "    for model in models:\n",
    "        with open('../pred/'+is_its+'/'+project+'-'+model+'-'+'random'+'-'+kind+'.pkl', 'rb') as f:\n",
    "            pred_list2.append(pickle.load(f))\n",
    "tr_pred = [[pred_list2[0][j], pred_list2[1][j], pred_list2[2][j]] for j in range(len(pred_list2[0]))]\n",
    "te_pred = [[pred_list2[3][j], pred_list2[4][j], pred_list2[5][j]] for j in range(len(pred_list2[3]))]                \n",
    "tr_data2 = [tr_pred, tr_data2[5]]\n",
    "te_data2 = [te_pred, te_data2[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "project = 'qt'\n",
    "is_its = 'in_its'\n",
    "with open('../resource/'+project+'_train.pkl', 'rb') as f_train, open('../resource/'+project+'_test.pkl', 'rb') as f_test:\n",
    "        tr_data3 = pickle.load(f_train)\n",
    "        te_data3 = pickle.load(f_test)\n",
    "pred_list3 = []\n",
    "kinds = ['train', 'test']\n",
    "models = ['lgb', 'code_cnn', 'msg_tf']\n",
    "for kind in kinds:\n",
    "    for model in models:\n",
    "        with open('../pred/'+is_its+'/'+project+'-'+model+'-'+'random'+'-'+kind+'.pkl', 'rb') as f:\n",
    "            pred_list3.append(pickle.load(f))\n",
    "tr_pred = [[pred_list3[0][j], pred_list3[1][j], pred_list3[2][j]] for j in range(len(pred_list3[0]))]\n",
    "te_pred = [[pred_list3[3][j], pred_list3[4][j], pred_list3[5][j]] for j in range(len(pred_list3[3]))]                \n",
    "tr_data3 = [tr_pred, tr_data3[5]]\n",
    "te_data3 = [te_pred, te_data3[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "project = 'qt'\n",
    "is_its = 'no_its'\n",
    "with open('../resource/'+project+'_train.pkl', 'rb') as f_train, open('../resource/'+project+'_test.pkl', 'rb') as f_test:\n",
    "        tr_data4 = pickle.load(f_train)\n",
    "        te_data4 = pickle.load(f_test)\n",
    "pred_list4 = []\n",
    "kinds = ['train', 'test']\n",
    "models = ['lgb', 'code_cnn', 'msg_tf']\n",
    "for kind in kinds:\n",
    "    for model in models:\n",
    "        with open('../pred/'+is_its+'/'+project+'-'+model+'-'+'random'+'-'+kind+'.pkl', 'rb') as f:\n",
    "            pred_list4.append(pickle.load(f))\n",
    "tr_pred = [[pred_list4[0][j], pred_list4[1][j], pred_list4[2][j]] for j in range(len(pred_list4[0]))]\n",
    "te_pred = [[pred_list4[3][j], pred_list4[4][j], pred_list4[5][j]] for j in range(len(pred_list4[3]))]                \n",
    "tr_data4 = [tr_pred, tr_data4[5]]\n",
    "te_data4 = [te_pred, te_data4[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_weight = 0.313\n",
    "code_weight = 0.436\n",
    "msg_weight = 0.251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc:0.803\n",
      "test loss:0.430\n",
      "test auc:0.814\n",
      "test loss:0.479\n"
     ]
    }
   ],
   "source": [
    "#openstack valid\n",
    "# #code + metrics\n",
    "# lgb_weight2 = lgb_weight / sum([lgb_weight, code_weight])\n",
    "# code_weight2 = code_weight / sum([lgb_weight, code_weight])\n",
    "# weighted_average = lgb_weight2 * pred_list[0] + code_weight2 * pred_list[1]\n",
    "# print(f'test auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(tr_data[1], weighted_average):.3f}')\n",
    "# #in_its_msg + metrics\n",
    "# lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "# msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "# weighted_average = lgb_weight2 * pred_list[0] + msg_weight2 * pred_list[2]\n",
    "# print(f'test auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(tr_data[1], weighted_average):.3f}')\n",
    "#in_its_msg + code\n",
    "code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "weighted_average = code_weight2 * pred_list[1] + msg_weight2 * pred_list[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data[1], weighted_average):.3f}')\n",
    "#ensemble(in_its_msg)\n",
    "weighted_average = lgb_weight * pred_list[0] + code_weight * pred_list[1] + msg_weight * pred_list[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data[1], weighted_average):.3f}')\n",
    "# #no_its_msg + metrics\n",
    "# lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "# msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "# weighted_average = lgb_weight2 * pred_list[0] + msg_weight2 * pred_list2[2]\n",
    "# print(f'test auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(tr_data[1], weighted_average):.3f}')\n",
    "# #no_its_msg + code\n",
    "# code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "# msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "# weighted_average = code_weight2 * pred_list[1] + msg_weight2 * pred_list2[2]\n",
    "# print(f'test auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(tr_data[1], weighted_average):.3f}')\n",
    "# #ensemble(no_its_msg)\n",
    "# weighted_average = lgb_weight * pred_list[0] + code_weight * pred_list[1] + msg_weight * pred_list2[2]\n",
    "# print(f'test auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(tr_data[1], weighted_average):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc:0.803\n",
      "test loss:0.521\n",
      "test auc:0.823\n",
      "test loss:0.537\n",
      "test auc:0.803\n",
      "test loss:0.545\n",
      "test auc:0.823\n",
      "test loss:0.548\n"
     ]
    }
   ],
   "source": [
    "#openstack test\n",
    "# #code + metrics\n",
    "# lgb_weight2 = lgb_weight / sum([lgb_weight, code_weight])\n",
    "# code_weight2 = code_weight / sum([lgb_weight, code_weight])\n",
    "# weighted_average = lgb_weight2 * pred_list[3] + code_weight2 * pred_list[4]\n",
    "# print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(te_data[1], weighted_average):.3f}')\n",
    "# #in_its_msg + metrics\n",
    "# lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "# msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "# weighted_average = lgb_weight2 * pred_list[3] + msg_weight2 * pred_list[5]\n",
    "# print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(te_data[1], weighted_average):.3f}')\n",
    "#in_its_msg + code\n",
    "code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "weighted_average = code_weight2 * pred_list[4] + msg_weight2 * pred_list[5]\n",
    "print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data[1], weighted_average):.3f}')\n",
    "#ensemble(in_its_msg)\n",
    "weighted_average = lgb_weight * pred_list[3] + code_weight * pred_list[4] + msg_weight * pred_list[5]\n",
    "print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data[1], weighted_average):.3f}')\n",
    "# #no_its_msg + metrics\n",
    "# lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "# msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "# weighted_average = lgb_weight2 * pred_list[3] + msg_weight2 * pred_list2[5]\n",
    "# print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average):.3f}')\n",
    "# print(f'test loss:{log_loss(te_data[1], weighted_average):.3f}')\n",
    "#no_its_msg + code\n",
    "code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "weighted_average = code_weight2 * pred_list[4] + msg_weight2 * pred_list2[5]\n",
    "print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data[1], weighted_average):.3f}')\n",
    "#ensemble(no_its_msg)\n",
    "weighted_average = lgb_weight * pred_list[3] + code_weight * pred_list[4] + msg_weight * pred_list2[5]\n",
    "print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data[1], weighted_average):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc:0.812\n",
      "test loss:0.505\n",
      "test auc:0.785\n",
      "test loss:0.462\n",
      "test auc:0.804\n",
      "test loss:0.502\n",
      "test auc:0.815\n",
      "test loss:0.484\n",
      "test auc:0.783\n",
      "test loss:0.444\n",
      "test auc:0.804\n",
      "test loss:0.483\n",
      "test auc:0.815\n",
      "test loss:0.473\n"
     ]
    }
   ],
   "source": [
    "#qt valid\n",
    "#code + metrics\n",
    "lgb_weight2 = lgb_weight / sum([lgb_weight, code_weight])\n",
    "code_weight2 = code_weight / sum([lgb_weight, code_weight])\n",
    "weighted_average = lgb_weight2 * pred_list3[0] + code_weight2 * pred_list3[1]\n",
    "print(f'test auc:{roc_auc_score(tr_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data3[1], weighted_average):.3f}')\n",
    "#in_its_msg + metrics\n",
    "lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "weighted_average = lgb_weight2 * pred_list3[0] + msg_weight2 * pred_list3[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data3[1], weighted_average):.3f}')\n",
    "#in_its_msg + code\n",
    "code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "weighted_average = code_weight2 * pred_list3[1] + msg_weight2 * pred_list3[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data3[1], weighted_average):.3f}')\n",
    "#ensemble(in_its_msg)\n",
    "weighted_average = lgb_weight * pred_list3[0] + code_weight * pred_list3[1] + msg_weight * pred_list3[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data3[1], weighted_average):.3f}')\n",
    "#no_its_msg + metrics\n",
    "lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "weighted_average = lgb_weight2 * pred_list3[0] + msg_weight2 * pred_list4[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data3[1], weighted_average):.3f}')\n",
    "#no_its_msg + code\n",
    "code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "weighted_average = code_weight2 * pred_list3[1] + msg_weight2 * pred_list4[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data3[1], weighted_average):.3f}')\n",
    "#ensemble(no_its_msg)\n",
    "weighted_average = lgb_weight * pred_list3[0] + code_weight * pred_list3[1] + msg_weight * pred_list4[2]\n",
    "print(f'test auc:{roc_auc_score(tr_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(tr_data3[1], weighted_average):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc:0.790\n",
      "test loss:0.534\n",
      "test auc:0.769\n",
      "test loss:0.397\n",
      "test auc:0.729\n",
      "test loss:0.497\n",
      "test auc:0.775\n",
      "test loss:0.472\n",
      "test auc:0.790\n",
      "test loss:0.353\n",
      "test auc:0.740\n",
      "test loss:0.454\n",
      "test auc:0.783\n",
      "test loss:0.443\n"
     ]
    }
   ],
   "source": [
    "#qt\n",
    "#code + metrics\n",
    "lgb_weight2 = lgb_weight / sum([lgb_weight, code_weight])\n",
    "code_weight2 = code_weight / sum([lgb_weight, code_weight])\n",
    "weighted_average = lgb_weight2 * pred_list3[3] + code_weight2 * pred_list3[4]\n",
    "print(f'test auc:{roc_auc_score(te_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data3[1], weighted_average):.3f}')\n",
    "\n",
    "#in_its_msg + metrics\n",
    "lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "weighted_average = lgb_weight2 * pred_list3[3] + msg_weight2 * pred_list3[5]\n",
    "print(f'test auc:{roc_auc_score(te_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data3[1], weighted_average):.3f}')\n",
    "\n",
    "#in_its_msg + code\n",
    "code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "weighted_average = code_weight2 * pred_list3[4] + msg_weight2 * pred_list3[5]\n",
    "print(f'test auc:{roc_auc_score(te_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data3[1], weighted_average):.3f}')\n",
    "\n",
    "#ensemble(in_its_msg)\n",
    "weighted_average = lgb_weight * pred_list3[3] + code_weight * pred_list3[4] + msg_weight * pred_list3[5]\n",
    "print(f'test auc:{roc_auc_score(te_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data3[1], weighted_average):.3f}')\n",
    "\n",
    "#no_its_msg + metrics\n",
    "lgb_weight2 = lgb_weight / sum([lgb_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([lgb_weight, msg_weight])\n",
    "weighted_average = lgb_weight2 * pred_list3[3] + msg_weight2 * pred_list4[5]\n",
    "print(f'test auc:{roc_auc_score(te_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data3[1], weighted_average):.3f}')\n",
    "\n",
    "#no_its_msg + code\n",
    "code_weight2 = code_weight / sum([code_weight, msg_weight])\n",
    "msg_weight2 = msg_weight / sum([code_weight, msg_weight])\n",
    "weighted_average = code_weight2 * pred_list3[4] + msg_weight2 * pred_list4[5]\n",
    "print(f'test auc:{roc_auc_score(te_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data3[1], weighted_average):.3f}')\n",
    "\n",
    "#ensemble(no_its_msg)\n",
    "weighted_average = lgb_weight * pred_list3[3] + code_weight * pred_list3[4] + msg_weight * pred_list4[5]\n",
    "print(f'test auc:{roc_auc_score(te_data3[1] ,weighted_average):.3f}')\n",
    "print(f'test loss:{log_loss(te_data3[1], weighted_average):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qt no_its\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\masak\\workspace\\lab\\thesis_data2\\learning_process\\notebook\\optimize.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/masak/workspace/lab/thesis_data2/learning_process/notebook/optimize.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(project, is_its)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/masak/workspace/lab/thesis_data2/learning_process/notebook/optimize.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m weight \u001b[39min\u001b[39;00m weights:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/masak/workspace/lab/thesis_data2/learning_process/notebook/optimize.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     weighted_average \u001b[39m=\u001b[39m weight[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m pred_list[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m weight[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m pred_list[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m weight[\u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m pred_list[\u001b[39m2\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/masak/workspace/lab/thesis_data2/learning_process/notebook/optimize.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     weighted_average2 \u001b[39m=\u001b[39m weight[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m pred_list[\u001b[39m3\u001b[39m] \u001b[39m+\u001b[39m weight[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m pred_list[\u001b[39m4\u001b[39m] \u001b[39m+\u001b[39m weight[\u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m pred_list[\u001b[39m5\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "print(project, is_its)\n",
    "for weight in weights:\n",
    "    weighted_average = weight[0] * pred_list[0] + weight[1] * pred_list[1] + weight[2] * pred_list[2]\n",
    "    weighted_average2 = weight[0] * pred_list[3] + weight[1] * pred_list[4] + weight[2] * pred_list[5]\n",
    "    print(weight)\n",
    "    print(f'train auc:{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "    print(f'train loss:{log_loss(tr_data[1], weighted_average):.3f}')\n",
    "    print(f'test auc:{roc_auc_score(te_data[1] ,weighted_average2):.3f}')\n",
    "    print(f'test loss:{log_loss(te_data[1], weighted_average2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n",
      "0.462\n"
     ]
    }
   ],
   "source": [
    "weighted_average = 0.4 * pred_list[0] + 0.45 * pred_list[1] + 0.15 * pred_list[2]\n",
    "print(f'{roc_auc_score(tr_data[1] ,weighted_average):.3f}')\n",
    "print(f'{log_loss(tr_data[1], weighted_average):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821\n",
      "0.534\n"
     ]
    }
   ],
   "source": [
    "weighted_average2 = 0.4 * pred_list[3] + 0.45 * pred_list[4] + 0.15 * pred_list[5]\n",
    "print(f'{roc_auc_score(te_data[1] ,weighted_average2):.3f}')\n",
    "print(f'{log_loss(te_data[1], weighted_average2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.362 0.296 0.341\n",
      "0.498 0.332 0.170\n"
     ]
    }
   ],
   "source": [
    "#Qt std\n",
    "import numpy as np\n",
    "std = np.array([1/0.008771, 1/0.010731, 1/0.009309])\n",
    "norm_std = std / np.sum(std)\n",
    "print(f'{norm_std[0]:.3f} {norm_std[1]:.3f} {norm_std[2]:.3f}')\n",
    "\n",
    "std2 = np.array([1/0.020657, 1/0.030968, 1/0.060467])\n",
    "norm_std2 = std2 / np.sum(std2)\n",
    "print(f'{norm_std2[0]:.3f} {norm_std2[1]:.3f} {norm_std2[2]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.456 0.305 0.239\n",
      "0.766 0.081 0.154\n"
     ]
    }
   ],
   "source": [
    "# OpenStack std\n",
    "import numpy as np\n",
    "std = np.array([1/0.008330, 1/0.012456, 1/0.015932])\n",
    "norm_std = std / np.sum(std)\n",
    "print(f'{norm_std[0]:.3f} {norm_std[1]:.3f} {norm_std[2]:.3f}')\n",
    "\n",
    "std2 = np.array([1/0.006839, 1/0.064984, 1/0.034017])\n",
    "norm_std2 = std2 / np.sum(std2)\n",
    "print(f'{norm_std2[0]:.3f} {norm_std2[1]:.3f} {norm_std2[2]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44700000000000006, 0.38499999999999995, 0.16833333333333333]\n",
      "metrics:0.447,code:0.385,msg:0.168\n"
     ]
    }
   ],
   "source": [
    "#Qt weighted_ratio\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "metrics_weight = [0.425, 0.383,0.533]\n",
    "code_weight = [0.486, 0.313, 0.356]\n",
    "msg_weight = [0.089, 0.305, 0.111]\n",
    "weights = [np.mean(metrics_weight), np.mean(code_weight), np.mean(msg_weight)]\n",
    "# weights = [stats.hmean(metrics_weight), stats.hmean(code_weight), stats.hmean(msg_weight)]\n",
    "print(weights)\n",
    "normalize = weights / sum(weights)\n",
    "print(f'metrics:{normalize[0]:.3f},code:{normalize[1]:.3f},msg:{normalize[2]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.574, 0.248, 0.17833333333333334]\n",
      "metrics:0.574,code:0.248,msg:0.178\n"
     ]
    }
   ],
   "source": [
    "#OpenStack weighted_ratio\n",
    "import numpy as np\n",
    "metrics_weight = [0.500, 0.456, 0.766]\n",
    "code_weight = [0.358,0.305,0.081]\n",
    "msg_weight = [0.142,0.239,0.154]\n",
    "weights = [np.mean(metrics_weight), np.mean(code_weight), np.mean(msg_weight)]\n",
    "# weights = [stats.hmean(metrics_weight), stats.hmean(code_weight), stats.hmean(msg_weight)]\n",
    "print(weights)\n",
    "normalize = weights / sum(weights)\n",
    "print(f'metrics:{normalize[0]:.3f},code:{normalize[1]:.3f},msg:{normalize[2]:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
